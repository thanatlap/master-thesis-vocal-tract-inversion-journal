{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech + Phonetic AAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil \n",
    "import argparse\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Reshape, GRU, InputLayer, AlphaDropout, Activation, BatchNormalization, Dropout, Flatten, Dense, Bidirectional, LSTM, Conv1D, SpatialDropout1D, Concatenate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preprocessing data\n",
    "def delete_params(params):\n",
    "    '''\n",
    "    This function remove JX, WC, TRX, TRY, and MS1,2,3 paramter\n",
    "    '''\n",
    "    DEL_PARAMS_LIST = [2,8,15,16,21,22,23]\n",
    "    return np.delete(params,DEL_PARAMS_LIST , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "\n",
    "    # load data from preprocess pipeline\n",
    "    dataset = np.load(join('../data/d_dataset_p1/prep_data_13','training_subsets.npz'))\n",
    "    X_train =dataset['X_train']\n",
    "    y_train= dataset['y_train']\n",
    "    z_train= dataset['z_train']\n",
    "    X_val = dataset['X_val']\n",
    "    y_val = dataset['y_val']\n",
    "    z_val = dataset['z_val']\n",
    "    X_test = dataset['X_test']\n",
    "    y_test = dataset['y_test']\n",
    "    z_test = dataset['z_test']\n",
    "    \n",
    "    y_train = delete_params(y_train)\n",
    "    y_val = delete_params(y_val)\n",
    "    y_test = delete_params(y_test)\n",
    "\n",
    "    print('Train features and labels %s %s'%(str(X_train.shape),str(y_train.shape)))\n",
    "    print('Validating features and labels %s %s'%(str(X_val.shape),str(y_val.shape)))\n",
    "    print('Test features and labels %s %s'%(str(X_test.shape),str(y_test.shape)))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (98746, 24, 39) (98746, 17)\n",
      "Validating features and labels (12094, 24, 39) (12094, 17)\n",
      "Test features and labels (12092, 24, 39) (12092, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E', 'Q', 'e', '@', 'M', 'U', '9', '&', '7', 'a', 'E:', 'i', 'o', 'A', 'V', '2', 'O', 'u', 'y'}\n"
     ]
    }
   ],
   "source": [
    "print(set(z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (98746, 24, 39) (98746, 17) (98746,)\n",
      "Validating features and labels (12094, 24, 39) (12094, 17) (12094,)\n",
      "Test features and labels (12092, 24, 39) (12092, 17) (12092,)\n"
     ]
    }
   ],
   "source": [
    "print('Train features and labels {} {} {}'.format(str(X_train.shape),str(y_train.shape),str(z_train.shape)))\n",
    "print('Validating features and labels {} {} {}'.format(str(X_val.shape),str(y_val.shape),str(z_val.shape)))\n",
    "print('Test features and labels {} {} {}'.format(str(X_test.shape),str(y_test.shape),str(z_test.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_oe=z_train.reshape(-1,1)\n",
    "z_val_oe=z_val.reshape(-1,1)\n",
    "z_test_oe=z_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(z_train_oe)\n",
    "\n",
    "z_train_oe = enc.transform(z_train_oe).toarray()\n",
    "z_test_oe = enc.transform(z_test_oe).toarray()\n",
    "z_val_oe = enc.transform(z_val_oe).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98746, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train_oe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12094, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_val_oe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train_oe[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "def init_bilstm(unit=128, bi_layer_num=3, drop_rate=0.2):\n",
    "\n",
    "    def bilstm(input_shape_1,input_shape_2):\n",
    "        \n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        # feature extraction layers\n",
    "        x = input_x\n",
    "        for i in range(bi_layer_num-1):\n",
    "            x = Bidirectional(pLSTM(unit))(x)\n",
    "            if drop_rate: \n",
    "                x = SpatialDropout1D(rate=drop_rate)(x)\n",
    "        # output layers\n",
    "        x = Bidirectional(pLSTM(unit*2, return_sequences=False))(x)\n",
    "        if drop_rate: \n",
    "            x = Dropout(rate=drop_rate)(x)\n",
    "        x = pDense(1024, activation='relu')(x)\n",
    "        outputs_param = pDense(N_OUTPUTS, activation='linear')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=input_x, outputs=outputs_param)\n",
    "        # model.summary()\n",
    "        return model\n",
    "    return bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_bilstm()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 24, 39)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 24, 256)           172032    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 24, 256)           394240    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               1050624   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                17425     \n",
      "=================================================================\n",
      "Total params: 2,159,633\n",
      "Trainable params: 2,159,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred), axis = 0) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true, axis = 0)), axis = 0) \n",
    "    return K.mean(1 - (SS_res/SS_tot), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98746 samples, validate on 12094 samples\n",
      "Epoch 1/30\n",
      "98746/98746 [==============================] - 36s 368us/sample - loss: 0.0734 - rmse: 0.2469 - R2: 0.6812 - val_loss: 0.0404 - val_rmse: 0.1809 - val_R2: 0.8270\n",
      "Epoch 2/30\n",
      "98746/98746 [==============================] - 21s 216us/sample - loss: 0.0477 - rmse: 0.1954 - R2: 0.7945 - val_loss: 0.0362 - val_rmse: 0.1705 - val_R2: 0.8449\n",
      "Epoch 3/30\n",
      "98746/98746 [==============================] - 21s 215us/sample - loss: 0.0415 - rmse: 0.1815 - R2: 0.8215 - val_loss: 0.0343 - val_rmse: 0.1622 - val_R2: 0.8542\n",
      "Epoch 4/30\n",
      "98746/98746 [==============================] - 21s 214us/sample - loss: 0.0377 - rmse: 0.1729 - R2: 0.8375 - val_loss: 0.0349 - val_rmse: 0.1619 - val_R2: 0.8497\n",
      "Epoch 5/30\n",
      "98746/98746 [==============================] - 21s 215us/sample - loss: 0.0350 - rmse: 0.1669 - R2: 0.8489 - val_loss: 0.0347 - val_rmse: 0.1608 - val_R2: 0.8521\n",
      "Epoch 6/30\n",
      "98746/98746 [==============================] - 21s 214us/sample - loss: 0.0330 - rmse: 0.1622 - R2: 0.8577 - val_loss: 0.0327 - val_rmse: 0.1566 - val_R2: 0.8598\n",
      "Epoch 7/30\n",
      "98746/98746 [==============================] - 21s 215us/sample - loss: 0.0314 - rmse: 0.1587 - R2: 0.8642 - val_loss: 0.0346 - val_rmse: 0.1576 - val_R2: 0.8526\n",
      "Epoch 8/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0301 - rmse: 0.1556 - R2: 0.8697 - val_loss: 0.0326 - val_rmse: 0.1552 - val_R2: 0.8603\n",
      "Epoch 9/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0290 - rmse: 0.1529 - R2: 0.8744 - val_loss: 0.0326 - val_rmse: 0.1540 - val_R2: 0.8609\n",
      "Epoch 10/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0278 - rmse: 0.1502 - R2: 0.8795 - val_loss: 0.0329 - val_rmse: 0.1526 - val_R2: 0.8597\n",
      "Epoch 11/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0266 - rmse: 0.1475 - R2: 0.8843 - val_loss: 0.0307 - val_rmse: 0.1495 - val_R2: 0.8686\n",
      "Epoch 12/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0259 - rmse: 0.1456 - R2: 0.8876 - val_loss: 0.0324 - val_rmse: 0.1520 - val_R2: 0.8621\n",
      "Epoch 13/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0254 - rmse: 0.1443 - R2: 0.8899 - val_loss: 0.0335 - val_rmse: 0.1539 - val_R2: 0.8574\n",
      "Epoch 14/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0246 - rmse: 0.1426 - R2: 0.8930 - val_loss: 0.0337 - val_rmse: 0.1533 - val_R2: 0.8562\n",
      "Epoch 15/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0238 - rmse: 0.1404 - R2: 0.8965 - val_loss: 0.0316 - val_rmse: 0.1502 - val_R2: 0.8652\n",
      "Epoch 16/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0233 - rmse: 0.1392 - R2: 0.8987 - val_loss: 0.0342 - val_rmse: 0.1534 - val_R2: 0.8539\n",
      "Epoch 17/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0230 - rmse: 0.1384 - R2: 0.8998 - val_loss: 0.0321 - val_rmse: 0.1501 - val_R2: 0.8625\n",
      "Epoch 18/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0228 - rmse: 0.1377 - R2: 0.9010 - val_loss: 0.0332 - val_rmse: 0.1519 - val_R2: 0.8579\n",
      "Epoch 19/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0221 - rmse: 0.1363 - R2: 0.9035 - val_loss: 0.0313 - val_rmse: 0.1489 - val_R2: 0.8656\n",
      "Epoch 20/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0217 - rmse: 0.1351 - R2: 0.9055 - val_loss: 0.0331 - val_rmse: 0.1510 - val_R2: 0.8595\n",
      "Epoch 21/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0215 - rmse: 0.1344 - R2: 0.9064 - val_loss: 0.0332 - val_rmse: 0.1507 - val_R2: 0.8578\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_baseline.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.032602244376239105, 0.14959863, 0.8500039]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(actual,pred, axis=1):\n",
    "    # Compute RMSE by row (axis=1) result in rmse of each data\n",
    "    # Compute RMSE by column (axis=0) result in rmse of each label\n",
    "    return np.sqrt((np.square(actual - pred)).mean(axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15738225 0.13672984 0.14865203 0.19487172 0.16036555 0.21226606\n",
      " 0.25415587 0.10173931 0.1306819  0.24195167 0.13813107 0.1652471\n",
      " 0.17270515 0.26993943 0.18364394 0.15410301 0.15102673]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Model + Phonetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "def init_bilstm_pho(unit=128, bi_layer_num=3, drop_rate=0.2):\n",
    "\n",
    "    def bilstm(input_shape_1,input_shape_2):\n",
    "        \n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        # feature extraction layers\n",
    "        x = input_x\n",
    "        z = input_x\n",
    "        for i in range(bi_layer_num-1):\n",
    "            x = Bidirectional(pLSTM(unit))(x)\n",
    "            if drop_rate: \n",
    "                x = SpatialDropout1D(rate=drop_rate)(x)\n",
    "        # output layers\n",
    "        x = Bidirectional(pLSTM(unit*2, return_sequences=False))(x)\n",
    "        if drop_rate: \n",
    "            x = Dropout(rate=drop_rate)(x)\n",
    "                \n",
    "        for i in range(bi_layer_num-2):\n",
    "            z = Bidirectional(pLSTM(unit))(z)\n",
    "            if drop_rate: \n",
    "                z = SpatialDropout1D(rate=drop_rate)(z)\n",
    "        z = Bidirectional(pLSTM(unit*2, return_sequences=False))(z)\n",
    "        if drop_rate: \n",
    "            z = Dropout(rate=drop_rate)(z)\n",
    "        z = pDense(100, activation='relu')(z)\n",
    "        outputs_pho = pDense(19, activation='softmax', name='pho')(x)\n",
    "        \n",
    "        x = Concatenate()([x,z])\n",
    "        x = pDense(512, activation='relu')(x)\n",
    "        outputs_param = pDense(N_OUTPUTS, activation='linear', name='param')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=input_x, outputs=[outputs_param, outputs_pho])\n",
    "        # model.summary()\n",
    "        return model\n",
    "    return bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho = init_bilstm_pho()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 256)      172032      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 24, 256)      0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 24, 256)      172032      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 24, 256)      394240      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 24, 256)      0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 24, 256)      0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 512)          1050624     spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 512)          1050624     spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          51300       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 612)          0           dropout_1[0][0]                  \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          313856      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "param (Dense)                   (None, 17)           8721        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pho (Dense)                     (None, 19)           9747        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,223,176\n",
      "Trainable params: 3,223,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pho.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"param\": \"mse\",\n",
    "    \"pho\": tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "}\n",
    "lossWeights = {\"param\": 1.0, \"pho\": 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"param\": [rmse, R2],\n",
    "    \"pho\": \"accuracy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho.compile(optimizer='adam',loss=losses, loss_weights=lossWeights, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='param_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98746 samples, validate on 12094 samples\n",
      "Epoch 1/30\n",
      "98746/98746 - 54s - loss: 2.3965 - param_loss: 0.0713 - pho_loss: 2.3251 - param_rmse: 0.2419 - param_R2: 0.6899 - pho_accuracy: 0.7161 - val_loss: 2.2395 - val_param_loss: 0.0432 - val_pho_loss: 2.1963 - val_param_rmse: 0.1845 - val_param_R2: 0.8155 - val_pho_accuracy: 0.8358\n",
      "Epoch 2/30\n",
      "98746/98746 - 32s - loss: 2.2864 - param_loss: 0.0470 - pho_loss: 2.2394 - param_rmse: 0.1938 - param_R2: 0.7974 - pho_accuracy: 0.7928 - val_loss: 2.2200 - val_param_loss: 0.0391 - val_pho_loss: 2.1806 - val_param_rmse: 0.1743 - val_param_R2: 0.8325 - val_pho_accuracy: 0.8508\n",
      "Epoch 3/30\n",
      "98746/98746 - 32s - loss: 2.2617 - param_loss: 0.0411 - pho_loss: 2.2205 - param_rmse: 0.1814 - param_R2: 0.8224 - pho_accuracy: 0.8113 - val_loss: 2.2225 - val_param_loss: 0.0378 - val_pho_loss: 2.1845 - val_param_rmse: 0.1686 - val_param_R2: 0.8387 - val_pho_accuracy: 0.8463\n",
      "Epoch 4/30\n",
      "98746/98746 - 32s - loss: 2.2534 - param_loss: 0.0379 - pho_loss: 2.2155 - param_rmse: 0.1742 - param_R2: 0.8360 - pho_accuracy: 0.8159 - val_loss: 2.2068 - val_param_loss: 0.0376 - val_pho_loss: 2.1694 - val_param_rmse: 0.1683 - val_param_R2: 0.8397 - val_pho_accuracy: 0.8617\n",
      "Epoch 5/30\n",
      "98746/98746 - 32s - loss: 2.2420 - param_loss: 0.0350 - pho_loss: 2.2069 - param_rmse: 0.1678 - param_R2: 0.8482 - pho_accuracy: 0.8244 - val_loss: 2.1991 - val_param_loss: 0.0359 - val_pho_loss: 2.1632 - val_param_rmse: 0.1643 - val_param_R2: 0.8459 - val_pho_accuracy: 0.8679\n",
      "Epoch 6/30\n",
      "98746/98746 - 32s - loss: 2.2315 - param_loss: 0.0329 - pho_loss: 2.1987 - param_rmse: 0.1630 - param_R2: 0.8573 - pho_accuracy: 0.8331 - val_loss: 2.1984 - val_param_loss: 0.0353 - val_pho_loss: 2.1630 - val_param_rmse: 0.1624 - val_param_R2: 0.8492 - val_pho_accuracy: 0.8680\n",
      "Epoch 7/30\n",
      "98746/98746 - 32s - loss: 2.2261 - param_loss: 0.0312 - pho_loss: 2.1949 - param_rmse: 0.1592 - param_R2: 0.8649 - pho_accuracy: 0.8367 - val_loss: 2.1949 - val_param_loss: 0.0344 - val_pho_loss: 2.1605 - val_param_rmse: 0.1597 - val_param_R2: 0.8526 - val_pho_accuracy: 0.8699\n",
      "Epoch 8/30\n",
      "98746/98746 - 32s - loss: 2.2220 - param_loss: 0.0301 - pho_loss: 2.1919 - param_rmse: 0.1565 - param_R2: 0.8694 - pho_accuracy: 0.8391 - val_loss: 2.2073 - val_param_loss: 0.0341 - val_pho_loss: 2.1731 - val_param_rmse: 0.1581 - val_param_R2: 0.8547 - val_pho_accuracy: 0.8576\n",
      "Epoch 9/30\n",
      "98746/98746 - 32s - loss: 2.2154 - param_loss: 0.0289 - pho_loss: 2.1865 - param_rmse: 0.1539 - param_R2: 0.8742 - pho_accuracy: 0.8444 - val_loss: 2.1822 - val_param_loss: 0.0330 - val_pho_loss: 2.1492 - val_param_rmse: 0.1569 - val_param_R2: 0.8583 - val_pho_accuracy: 0.8822\n",
      "Epoch 10/30\n",
      "98746/98746 - 32s - loss: 2.2151 - param_loss: 0.0278 - pho_loss: 2.1872 - param_rmse: 0.1513 - param_R2: 0.8791 - pho_accuracy: 0.8441 - val_loss: 2.1867 - val_param_loss: 0.0351 - val_pho_loss: 2.1515 - val_param_rmse: 0.1589 - val_param_R2: 0.8508 - val_pho_accuracy: 0.8792\n",
      "Epoch 11/30\n",
      "98746/98746 - 32s - loss: 2.2085 - param_loss: 0.0270 - pho_loss: 2.1815 - param_rmse: 0.1492 - param_R2: 0.8824 - pho_accuracy: 0.8496 - val_loss: 2.2014 - val_param_loss: 0.0348 - val_pho_loss: 2.1667 - val_param_rmse: 0.1585 - val_param_R2: 0.8511 - val_pho_accuracy: 0.8647\n",
      "Epoch 12/30\n",
      "98746/98746 - 32s - loss: 2.2081 - param_loss: 0.0263 - pho_loss: 2.1818 - param_rmse: 0.1477 - param_R2: 0.8853 - pho_accuracy: 0.8492 - val_loss: 2.1882 - val_param_loss: 0.0339 - val_pho_loss: 2.1542 - val_param_rmse: 0.1569 - val_param_R2: 0.8552 - val_pho_accuracy: 0.8768\n",
      "Epoch 13/30\n",
      "98746/98746 - 32s - loss: 2.2071 - param_loss: 0.0255 - pho_loss: 2.1817 - param_rmse: 0.1459 - param_R2: 0.8888 - pho_accuracy: 0.8495 - val_loss: 2.1869 - val_param_loss: 0.0354 - val_pho_loss: 2.1516 - val_param_rmse: 0.1580 - val_param_R2: 0.8493 - val_pho_accuracy: 0.8788\n",
      "Epoch 14/30\n",
      "98746/98746 - 32s - loss: 2.2043 - param_loss: 0.0248 - pho_loss: 2.1795 - param_rmse: 0.1442 - param_R2: 0.8919 - pho_accuracy: 0.8514 - val_loss: 2.1895 - val_param_loss: 0.0333 - val_pho_loss: 2.1563 - val_param_rmse: 0.1543 - val_param_R2: 0.8576 - val_pho_accuracy: 0.8748\n",
      "Epoch 15/30\n",
      "98746/98746 - 32s - loss: 2.2003 - param_loss: 0.0244 - pho_loss: 2.1759 - param_rmse: 0.1433 - param_R2: 0.8935 - pho_accuracy: 0.8550 - val_loss: 2.1762 - val_param_loss: 0.0352 - val_pho_loss: 2.1411 - val_param_rmse: 0.1572 - val_param_R2: 0.8508 - val_pho_accuracy: 0.8902\n",
      "Epoch 16/30\n",
      "98746/98746 - 32s - loss: 2.1983 - param_loss: 0.0238 - pho_loss: 2.1745 - param_rmse: 0.1418 - param_R2: 0.8961 - pho_accuracy: 0.8568 - val_loss: 2.1876 - val_param_loss: 0.0346 - val_pho_loss: 2.1531 - val_param_rmse: 0.1564 - val_param_R2: 0.8531 - val_pho_accuracy: 0.8775\n",
      "Epoch 17/30\n",
      "98746/98746 - 32s - loss: 2.1951 - param_loss: 0.0233 - pho_loss: 2.1718 - param_rmse: 0.1407 - param_R2: 0.8980 - pho_accuracy: 0.8592 - val_loss: 2.1827 - val_param_loss: 0.0337 - val_pho_loss: 2.1492 - val_param_rmse: 0.1542 - val_param_R2: 0.8560 - val_pho_accuracy: 0.8822\n",
      "Epoch 18/30\n",
      "98746/98746 - 32s - loss: 2.1961 - param_loss: 0.0230 - pho_loss: 2.1731 - param_rmse: 0.1399 - param_R2: 0.8994 - pho_accuracy: 0.8582 - val_loss: 2.1838 - val_param_loss: 0.0349 - val_pho_loss: 2.1493 - val_param_rmse: 0.1557 - val_param_R2: 0.8516 - val_pho_accuracy: 0.8819\n",
      "Epoch 19/30\n",
      "98746/98746 - 32s - loss: 2.2000 - param_loss: 0.0229 - pho_loss: 2.1771 - param_rmse: 0.1395 - param_R2: 0.9000 - pho_accuracy: 0.8538 - val_loss: 2.1915 - val_param_loss: 0.0356 - val_pho_loss: 2.1560 - val_param_rmse: 0.1570 - val_param_R2: 0.8491 - val_pho_accuracy: 0.8756\n",
      "Epoch 20/30\n",
      "98746/98746 - 32s - loss: 2.1930 - param_loss: 0.0224 - pho_loss: 2.1707 - param_rmse: 0.1383 - param_R2: 0.9021 - pho_accuracy: 0.8602 - val_loss: 2.2064 - val_param_loss: 0.0342 - val_pho_loss: 2.1722 - val_param_rmse: 0.1555 - val_param_R2: 0.8542 - val_pho_accuracy: 0.8589\n",
      "Epoch 21/30\n",
      "98746/98746 - 32s - loss: 2.1896 - param_loss: 0.0220 - pho_loss: 2.1677 - param_rmse: 0.1373 - param_R2: 0.9038 - pho_accuracy: 0.8635 - val_loss: 2.1900 - val_param_loss: 0.0346 - val_pho_loss: 2.1553 - val_param_rmse: 0.1559 - val_param_R2: 0.8529 - val_pho_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "98746/98746 - 32s - loss: 2.1882 - param_loss: 0.0219 - pho_loss: 2.1663 - param_rmse: 0.1370 - param_R2: 0.9041 - pho_accuracy: 0.8647 - val_loss: 2.1802 - val_param_loss: 0.0338 - val_pho_loss: 2.1463 - val_param_rmse: 0.1537 - val_param_R2: 0.8561 - val_pho_accuracy: 0.8847\n",
      "Epoch 23/30\n",
      "98746/98746 - 32s - loss: 2.1866 - param_loss: 0.0214 - pho_loss: 2.1652 - param_rmse: 0.1358 - param_R2: 0.9062 - pho_accuracy: 0.8657 - val_loss: 2.1831 - val_param_loss: 0.0337 - val_pho_loss: 2.1494 - val_param_rmse: 0.1537 - val_param_R2: 0.8561 - val_pho_accuracy: 0.8818\n",
      "Epoch 24/30\n",
      "98746/98746 - 32s - loss: 2.1889 - param_loss: 0.0211 - pho_loss: 2.1678 - param_rmse: 0.1352 - param_R2: 0.9076 - pho_accuracy: 0.8633 - val_loss: 2.1869 - val_param_loss: 0.0351 - val_pho_loss: 2.1519 - val_param_rmse: 0.1553 - val_param_R2: 0.8510 - val_pho_accuracy: 0.8788\n",
      "Epoch 25/30\n",
      "98746/98746 - 32s - loss: 2.1867 - param_loss: 0.0211 - pho_loss: 2.1657 - param_rmse: 0.1348 - param_R2: 0.9077 - pho_accuracy: 0.8652 - val_loss: 2.1761 - val_param_loss: 0.0344 - val_pho_loss: 2.1421 - val_param_rmse: 0.1551 - val_param_R2: 0.8535 - val_pho_accuracy: 0.8897\n",
      "Epoch 26/30\n",
      "98746/98746 - 32s - loss: 2.1820 - param_loss: 0.0206 - pho_loss: 2.1614 - param_rmse: 0.1337 - param_R2: 0.9098 - pho_accuracy: 0.8697 - val_loss: 2.1857 - val_param_loss: 0.0331 - val_pho_loss: 2.1530 - val_param_rmse: 0.1530 - val_param_R2: 0.8577 - val_pho_accuracy: 0.8786\n",
      "Epoch 27/30\n",
      "98746/98746 - 32s - loss: 2.1859 - param_loss: 0.0207 - pho_loss: 2.1653 - param_rmse: 0.1338 - param_R2: 0.9095 - pho_accuracy: 0.8658 - val_loss: 2.1737 - val_param_loss: 0.0320 - val_pho_loss: 2.1420 - val_param_rmse: 0.1507 - val_param_R2: 0.8636 - val_pho_accuracy: 0.8893\n",
      "Epoch 28/30\n",
      "98746/98746 - 33s - loss: 2.1842 - param_loss: 0.0205 - pho_loss: 2.1637 - param_rmse: 0.1334 - param_R2: 0.9101 - pho_accuracy: 0.8672 - val_loss: 2.1855 - val_param_loss: 0.0334 - val_pho_loss: 2.1524 - val_param_rmse: 0.1526 - val_param_R2: 0.8576 - val_pho_accuracy: 0.8791\n",
      "Epoch 29/30\n",
      "98746/98746 - 33s - loss: 2.1804 - param_loss: 0.0199 - pho_loss: 2.1604 - param_rmse: 0.1319 - param_R2: 0.9128 - pho_accuracy: 0.8704 - val_loss: 2.1958 - val_param_loss: 0.0345 - val_pho_loss: 2.1613 - val_param_rmse: 0.1540 - val_param_R2: 0.8531 - val_pho_accuracy: 0.8693\n",
      "Epoch 30/30\n",
      "98746/98746 - 32s - loss: 2.1821 - param_loss: 0.0198 - pho_loss: 2.1622 - param_rmse: 0.1316 - param_R2: 0.9131 - pho_accuracy: 0.8688 - val_loss: 2.1781 - val_param_loss: 0.0349 - val_pho_loss: 2.1434 - val_param_rmse: 0.1547 - val_param_R2: 0.8509 - val_pho_accuracy: 0.8872\n"
     ]
    }
   ],
   "source": [
    "history = model_pho.fit(X_train,{\"param\": y_train, \"pho\": z_train_oe},\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_data=(X_val,{\"param\": y_val, \"pho\": z_val_oe}),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho.save('model_baseline_pho.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, label):\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    label = enc.inverse_transform(label)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(label, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pho_pred = model_pho.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16499175 0.13846306 0.15626041 0.20971853 0.16883098 0.22409996\n",
      " 0.26204728 0.10337965 0.13968868 0.25097486 0.14635381 0.16778201\n",
      " 0.18071192 0.27521861 0.18504289 0.15457323 0.15504013]\n"
     ]
    }
   ],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[608   0   1  15   0   0   0   0   0   6  13   1   5  37   0   0   0   0\n",
      "    0]\n",
      " [  0 668   0   1   0   0   0   0   2   0   0   1   0   0   0   0   0   2\n",
      "   13]\n",
      " [  6   1 365   4   0   3   0   0   5  80   8  14  67  11   0   0   2   0\n",
      "    0]\n",
      " [ 14   0   0 622   0   0   2   0   6   0   5   6   4   0   0   0   0   0\n",
      "    0]\n",
      " [  1   0   0  12 595   0  31   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0 550   0   0   0   0  13   0  19  20   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   1  12   0 614  36   0   0   1   0   0   1   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   1  17 600   0   0   0   0   0   0   7   0   0   0\n",
      "    0]\n",
      " [  0   1  18   4   0   0   0   0 598   0   0  29   0   0   0   0   0   0\n",
      "    0]\n",
      " [  5   0  18   2   0   1   0   0   3 562   7  11  47   1   0   0   8   0\n",
      "    0]\n",
      " [ 16   0   1   3   0  44   2   0   0   1 546   0  10  10   0   0   0   0\n",
      "    0]\n",
      " [  5   1  16   0   0   0   0   0  54   5   0 537   0   0   0   0   5  24\n",
      "    0]\n",
      " [  1   1   8   3   0  24   1   0   2 109   6   1 448   6   0   0   0   0\n",
      "    0]\n",
      " [ 10   0   1   4   0  18   3   0   0   0   8   0  19 617   0   0   0   0\n",
      "    0]\n",
      " [  0   1   0   0   0   0   0  15   0   0   0   0   0   0 604   4   0   0\n",
      "    2]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  45 555   0   0\n",
      "   16]\n",
      " [  0   2  13   0   0   0   0   0   0   7   0  14   0   0   0   0 521  43\n",
      "    0]\n",
      " [  0   1   4   0   0   0   0   0   3   0   0  12   0   0   0   0  12 587\n",
      "    0]\n",
      " [  0  42   1   0   0   0   0   0   0   0   0   0   0   0   2   3   0   1\n",
      "  566]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           &       0.91      0.89      0.90       686\n",
      "           2       0.93      0.97      0.95       687\n",
      "           7       0.82      0.64      0.72       566\n",
      "           9       0.93      0.94      0.94       659\n",
      "           @       0.98      0.93      0.95       640\n",
      "           A       0.86      0.91      0.88       602\n",
      "           E       0.92      0.92      0.92       665\n",
      "          E:       0.92      0.96      0.94       625\n",
      "           M       0.89      0.92      0.90       650\n",
      "           O       0.73      0.85      0.78       665\n",
      "           Q       0.90      0.86      0.88       633\n",
      "           U       0.86      0.83      0.84       647\n",
      "           V       0.72      0.73      0.73       610\n",
      "           a       0.88      0.91      0.89       680\n",
      "           e       0.92      0.96      0.94       626\n",
      "           i       0.99      0.90      0.94       617\n",
      "           o       0.95      0.87      0.91       600\n",
      "           u       0.89      0.95      0.92       619\n",
      "           y       0.95      0.92      0.93       615\n",
      "\n",
      "    accuracy                           0.89     12092\n",
      "   macro avg       0.89      0.89      0.89     12092\n",
      "weighted avg       0.89      0.89      0.89     12092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_pho_pred, z_test_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
