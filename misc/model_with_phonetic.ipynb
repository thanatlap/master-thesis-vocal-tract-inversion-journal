{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech + Phonetic AAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil \n",
    "import argparse\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Reshape, GRU, InputLayer, AlphaDropout, Activation, BatchNormalization, Dropout, Flatten, Dense, Bidirectional, LSTM, Conv1D, SpatialDropout1D, Concatenate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred), axis = 0) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true, axis = 0)), axis = 0) \n",
    "    return K.mean(1 - (SS_res/SS_tot), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preprocessing data\n",
    "def delete_params(params):\n",
    "    '''\n",
    "    This function remove JX, WC, TRX, TRY, and MS1,2,3 paramter\n",
    "    '''\n",
    "    DEL_PARAMS_LIST = [2,8,15,16,21,22,23]\n",
    "    return np.delete(params,DEL_PARAMS_LIST , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(actual,pred, axis=1):\n",
    "    # Compute RMSE by row (axis=1) result in rmse of each data\n",
    "    # Compute RMSE by column (axis=0) result in rmse of each label\n",
    "    return np.sqrt((np.square(actual - pred)).mean(axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, label):\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    label = enc.inverse_transform(label)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(label, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(label, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "\n",
    "    # load data from preprocess pipeline\n",
    "    dataset = np.load(join('../data/d_dataset_p1/prep_data_13','training_subsets.npz'))\n",
    "    X_train =dataset['X_train']\n",
    "    y_train= dataset['y_train']\n",
    "    z_train= dataset['z_train']\n",
    "    X_val = dataset['X_val']\n",
    "    y_val = dataset['y_val']\n",
    "    z_val = dataset['z_val']\n",
    "    X_test = dataset['X_test']\n",
    "    y_test = dataset['y_test']\n",
    "    z_test = dataset['z_test']\n",
    "    \n",
    "    y_train = delete_params(y_train)\n",
    "    y_val = delete_params(y_val)\n",
    "    y_test = delete_params(y_test)\n",
    "\n",
    "    print('Train features and labels %s %s'%(str(X_train.shape),str(y_train.shape)))\n",
    "    print('Validating features and labels %s %s'%(str(X_val.shape),str(y_val.shape)))\n",
    "    print('Test features and labels %s %s'%(str(X_test.shape),str(y_test.shape)))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (98746, 24, 39) (98746, 17)\n",
      "Validating features and labels (12094, 24, 39) (12094, 17)\n",
      "Test features and labels (12092, 24, 39) (12092, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'&', 'M', 'Q', 'u', 'A', 'o', 'U', 'E:', 'E', 'O', '2', 'V', 'e', 'i', 'y', '9', '7', '@', 'a'}\n"
     ]
    }
   ],
   "source": [
    "print(set(z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (98746, 24, 39) (98746, 17) (98746,)\n",
      "Validating features and labels (12094, 24, 39) (12094, 17) (12094,)\n",
      "Test features and labels (12092, 24, 39) (12092, 17) (12092,)\n"
     ]
    }
   ],
   "source": [
    "print('Train features and labels {} {} {}'.format(str(X_train.shape),str(y_train.shape),str(z_train.shape)))\n",
    "print('Validating features and labels {} {} {}'.format(str(X_val.shape),str(y_val.shape),str(z_val.shape)))\n",
    "print('Test features and labels {} {} {}'.format(str(X_test.shape),str(y_test.shape),str(z_test.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_oe=z_train.reshape(-1,1)\n",
    "z_val_oe=z_val.reshape(-1,1)\n",
    "z_test_oe=z_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(z_train_oe)\n",
    "\n",
    "z_train_oe = enc.transform(z_train_oe).toarray()\n",
    "z_test_oe = enc.transform(z_test_oe).toarray()\n",
    "z_val_oe = enc.transform(z_val_oe).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98746, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train_oe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12094, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_val_oe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train_oe[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "def init_bilstm(unit=128, bi_layer_num=3, drop_rate=0.2):\n",
    "\n",
    "    def bilstm(input_shape_1,input_shape_2):\n",
    "        \n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        # feature extraction layers\n",
    "        x = input_x\n",
    "        for i in range(bi_layer_num-1):\n",
    "            x = Bidirectional(pLSTM(unit))(x)\n",
    "            if drop_rate: \n",
    "                x = SpatialDropout1D(rate=drop_rate)(x)\n",
    "        # output layers\n",
    "        x = Bidirectional(pLSTM(unit*2, return_sequences=False))(x)\n",
    "        if drop_rate: \n",
    "            x = Dropout(rate=drop_rate)(x)\n",
    "        x = pDense(1024, activation='relu')(x)\n",
    "        outputs_param = pDense(N_OUTPUTS, activation='linear')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=input_x, outputs=outputs_param)\n",
    "        # model.summary()\n",
    "        return model\n",
    "    return bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_bilstm()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 24, 39)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 24, 256)           172032    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 24, 256)           394240    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               1050624   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                17425     \n",
      "=================================================================\n",
      "Total params: 2,159,633\n",
      "Trainable params: 2,159,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98746 samples, validate on 12094 samples\n",
      "Epoch 1/30\n",
      "98746/98746 [==============================] - 36s 368us/sample - loss: 0.0734 - rmse: 0.2469 - R2: 0.6812 - val_loss: 0.0404 - val_rmse: 0.1809 - val_R2: 0.8270\n",
      "Epoch 2/30\n",
      "98746/98746 [==============================] - 21s 216us/sample - loss: 0.0477 - rmse: 0.1954 - R2: 0.7945 - val_loss: 0.0362 - val_rmse: 0.1705 - val_R2: 0.8449\n",
      "Epoch 3/30\n",
      "98746/98746 [==============================] - 21s 215us/sample - loss: 0.0415 - rmse: 0.1815 - R2: 0.8215 - val_loss: 0.0343 - val_rmse: 0.1622 - val_R2: 0.8542\n",
      "Epoch 4/30\n",
      "98746/98746 [==============================] - 21s 214us/sample - loss: 0.0377 - rmse: 0.1729 - R2: 0.8375 - val_loss: 0.0349 - val_rmse: 0.1619 - val_R2: 0.8497\n",
      "Epoch 5/30\n",
      "98746/98746 [==============================] - 21s 215us/sample - loss: 0.0350 - rmse: 0.1669 - R2: 0.8489 - val_loss: 0.0347 - val_rmse: 0.1608 - val_R2: 0.8521\n",
      "Epoch 6/30\n",
      "98746/98746 [==============================] - 21s 214us/sample - loss: 0.0330 - rmse: 0.1622 - R2: 0.8577 - val_loss: 0.0327 - val_rmse: 0.1566 - val_R2: 0.8598\n",
      "Epoch 7/30\n",
      "98746/98746 [==============================] - 21s 215us/sample - loss: 0.0314 - rmse: 0.1587 - R2: 0.8642 - val_loss: 0.0346 - val_rmse: 0.1576 - val_R2: 0.8526\n",
      "Epoch 8/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0301 - rmse: 0.1556 - R2: 0.8697 - val_loss: 0.0326 - val_rmse: 0.1552 - val_R2: 0.8603\n",
      "Epoch 9/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0290 - rmse: 0.1529 - R2: 0.8744 - val_loss: 0.0326 - val_rmse: 0.1540 - val_R2: 0.8609\n",
      "Epoch 10/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0278 - rmse: 0.1502 - R2: 0.8795 - val_loss: 0.0329 - val_rmse: 0.1526 - val_R2: 0.8597\n",
      "Epoch 11/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0266 - rmse: 0.1475 - R2: 0.8843 - val_loss: 0.0307 - val_rmse: 0.1495 - val_R2: 0.8686\n",
      "Epoch 12/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0259 - rmse: 0.1456 - R2: 0.8876 - val_loss: 0.0324 - val_rmse: 0.1520 - val_R2: 0.8621\n",
      "Epoch 13/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0254 - rmse: 0.1443 - R2: 0.8899 - val_loss: 0.0335 - val_rmse: 0.1539 - val_R2: 0.8574\n",
      "Epoch 14/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0246 - rmse: 0.1426 - R2: 0.8930 - val_loss: 0.0337 - val_rmse: 0.1533 - val_R2: 0.8562\n",
      "Epoch 15/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0238 - rmse: 0.1404 - R2: 0.8965 - val_loss: 0.0316 - val_rmse: 0.1502 - val_R2: 0.8652\n",
      "Epoch 16/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0233 - rmse: 0.1392 - R2: 0.8987 - val_loss: 0.0342 - val_rmse: 0.1534 - val_R2: 0.8539\n",
      "Epoch 17/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0230 - rmse: 0.1384 - R2: 0.8998 - val_loss: 0.0321 - val_rmse: 0.1501 - val_R2: 0.8625\n",
      "Epoch 18/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0228 - rmse: 0.1377 - R2: 0.9010 - val_loss: 0.0332 - val_rmse: 0.1519 - val_R2: 0.8579\n",
      "Epoch 19/30\n",
      "98746/98746 [==============================] - 21s 213us/sample - loss: 0.0221 - rmse: 0.1363 - R2: 0.9035 - val_loss: 0.0313 - val_rmse: 0.1489 - val_R2: 0.8656\n",
      "Epoch 20/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0217 - rmse: 0.1351 - R2: 0.9055 - val_loss: 0.0331 - val_rmse: 0.1510 - val_R2: 0.8595\n",
      "Epoch 21/30\n",
      "98746/98746 [==============================] - 21s 212us/sample - loss: 0.0215 - rmse: 0.1344 - R2: 0.9064 - val_loss: 0.0332 - val_rmse: 0.1507 - val_R2: 0.8578\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_baseline.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.032602244376239105, 0.14959863, 0.8500039]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15738225 0.13672984 0.14865203 0.19487172 0.16036555 0.21226606\n",
      " 0.25415587 0.10173931 0.1306819  0.24195167 0.13813107 0.1652471\n",
      " 0.17270515 0.26993943 0.18364394 0.15410301 0.15102673]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Model + Phonetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "def init_bilstm_pho(unit=128, bi_layer_num=3, drop_rate=0.2):\n",
    "\n",
    "    def bilstm(input_shape_1,input_shape_2):\n",
    "        \n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        # feature extraction layers\n",
    "        x = input_x\n",
    "        z = input_x\n",
    "        for i in range(bi_layer_num-1):\n",
    "            x = Bidirectional(pLSTM(unit))(x)\n",
    "            if drop_rate: \n",
    "                x = SpatialDropout1D(rate=drop_rate)(x)\n",
    "        # output layers\n",
    "        x = Bidirectional(pLSTM(unit*2, return_sequences=False))(x)\n",
    "        if drop_rate: \n",
    "            x = Dropout(rate=drop_rate)(x)\n",
    "                \n",
    "        for i in range(bi_layer_num-2):\n",
    "            z = Bidirectional(pLSTM(unit))(z)\n",
    "            if drop_rate: \n",
    "                z = SpatialDropout1D(rate=drop_rate)(z)\n",
    "        z = Bidirectional(pLSTM(unit*2, return_sequences=False))(z)\n",
    "        if drop_rate: \n",
    "            z = Dropout(rate=drop_rate)(z)\n",
    "        z = pDense(100, activation='relu')(z)\n",
    "        outputs_pho = pDense(19, activation='softmax', name='pho')(x)\n",
    "        \n",
    "        x = Concatenate()([x,z])\n",
    "        x = pDense(512, activation='relu')(x)\n",
    "        outputs_param = pDense(N_OUTPUTS, activation='linear', name='param')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=input_x, outputs=[outputs_param, outputs_pho])\n",
    "        # model.summary()\n",
    "        return model\n",
    "    return bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho = init_bilstm_pho()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 256)      172032      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 24, 256)      0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 24, 256)      172032      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 24, 256)      394240      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 24, 256)      0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 24, 256)      0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 512)          1050624     spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 512)          1050624     spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          51300       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 612)          0           dropout_1[0][0]                  \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          313856      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "param (Dense)                   (None, 17)           8721        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pho (Dense)                     (None, 19)           9747        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,223,176\n",
      "Trainable params: 3,223,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pho.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"param\": \"mse\",\n",
    "    \"pho\": tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "}\n",
    "lossWeights = {\"param\": 1.0, \"pho\": 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"param\": [rmse, R2],\n",
    "    \"pho\": \"accuracy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho.compile(optimizer='adam',loss=losses, loss_weights=lossWeights, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='param_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98746 samples, validate on 12094 samples\n",
      "Epoch 1/30\n",
      "98746/98746 - 54s - loss: 2.3965 - param_loss: 0.0713 - pho_loss: 2.3251 - param_rmse: 0.2419 - param_R2: 0.6899 - pho_accuracy: 0.7161 - val_loss: 2.2395 - val_param_loss: 0.0432 - val_pho_loss: 2.1963 - val_param_rmse: 0.1845 - val_param_R2: 0.8155 - val_pho_accuracy: 0.8358\n",
      "Epoch 2/30\n",
      "98746/98746 - 32s - loss: 2.2864 - param_loss: 0.0470 - pho_loss: 2.2394 - param_rmse: 0.1938 - param_R2: 0.7974 - pho_accuracy: 0.7928 - val_loss: 2.2200 - val_param_loss: 0.0391 - val_pho_loss: 2.1806 - val_param_rmse: 0.1743 - val_param_R2: 0.8325 - val_pho_accuracy: 0.8508\n",
      "Epoch 3/30\n",
      "98746/98746 - 32s - loss: 2.2617 - param_loss: 0.0411 - pho_loss: 2.2205 - param_rmse: 0.1814 - param_R2: 0.8224 - pho_accuracy: 0.8113 - val_loss: 2.2225 - val_param_loss: 0.0378 - val_pho_loss: 2.1845 - val_param_rmse: 0.1686 - val_param_R2: 0.8387 - val_pho_accuracy: 0.8463\n",
      "Epoch 4/30\n",
      "98746/98746 - 32s - loss: 2.2534 - param_loss: 0.0379 - pho_loss: 2.2155 - param_rmse: 0.1742 - param_R2: 0.8360 - pho_accuracy: 0.8159 - val_loss: 2.2068 - val_param_loss: 0.0376 - val_pho_loss: 2.1694 - val_param_rmse: 0.1683 - val_param_R2: 0.8397 - val_pho_accuracy: 0.8617\n",
      "Epoch 5/30\n",
      "98746/98746 - 32s - loss: 2.2420 - param_loss: 0.0350 - pho_loss: 2.2069 - param_rmse: 0.1678 - param_R2: 0.8482 - pho_accuracy: 0.8244 - val_loss: 2.1991 - val_param_loss: 0.0359 - val_pho_loss: 2.1632 - val_param_rmse: 0.1643 - val_param_R2: 0.8459 - val_pho_accuracy: 0.8679\n",
      "Epoch 6/30\n",
      "98746/98746 - 32s - loss: 2.2315 - param_loss: 0.0329 - pho_loss: 2.1987 - param_rmse: 0.1630 - param_R2: 0.8573 - pho_accuracy: 0.8331 - val_loss: 2.1984 - val_param_loss: 0.0353 - val_pho_loss: 2.1630 - val_param_rmse: 0.1624 - val_param_R2: 0.8492 - val_pho_accuracy: 0.8680\n",
      "Epoch 7/30\n",
      "98746/98746 - 32s - loss: 2.2261 - param_loss: 0.0312 - pho_loss: 2.1949 - param_rmse: 0.1592 - param_R2: 0.8649 - pho_accuracy: 0.8367 - val_loss: 2.1949 - val_param_loss: 0.0344 - val_pho_loss: 2.1605 - val_param_rmse: 0.1597 - val_param_R2: 0.8526 - val_pho_accuracy: 0.8699\n",
      "Epoch 8/30\n",
      "98746/98746 - 32s - loss: 2.2220 - param_loss: 0.0301 - pho_loss: 2.1919 - param_rmse: 0.1565 - param_R2: 0.8694 - pho_accuracy: 0.8391 - val_loss: 2.2073 - val_param_loss: 0.0341 - val_pho_loss: 2.1731 - val_param_rmse: 0.1581 - val_param_R2: 0.8547 - val_pho_accuracy: 0.8576\n",
      "Epoch 9/30\n",
      "98746/98746 - 32s - loss: 2.2154 - param_loss: 0.0289 - pho_loss: 2.1865 - param_rmse: 0.1539 - param_R2: 0.8742 - pho_accuracy: 0.8444 - val_loss: 2.1822 - val_param_loss: 0.0330 - val_pho_loss: 2.1492 - val_param_rmse: 0.1569 - val_param_R2: 0.8583 - val_pho_accuracy: 0.8822\n",
      "Epoch 10/30\n",
      "98746/98746 - 32s - loss: 2.2151 - param_loss: 0.0278 - pho_loss: 2.1872 - param_rmse: 0.1513 - param_R2: 0.8791 - pho_accuracy: 0.8441 - val_loss: 2.1867 - val_param_loss: 0.0351 - val_pho_loss: 2.1515 - val_param_rmse: 0.1589 - val_param_R2: 0.8508 - val_pho_accuracy: 0.8792\n",
      "Epoch 11/30\n",
      "98746/98746 - 32s - loss: 2.2085 - param_loss: 0.0270 - pho_loss: 2.1815 - param_rmse: 0.1492 - param_R2: 0.8824 - pho_accuracy: 0.8496 - val_loss: 2.2014 - val_param_loss: 0.0348 - val_pho_loss: 2.1667 - val_param_rmse: 0.1585 - val_param_R2: 0.8511 - val_pho_accuracy: 0.8647\n",
      "Epoch 12/30\n",
      "98746/98746 - 32s - loss: 2.2081 - param_loss: 0.0263 - pho_loss: 2.1818 - param_rmse: 0.1477 - param_R2: 0.8853 - pho_accuracy: 0.8492 - val_loss: 2.1882 - val_param_loss: 0.0339 - val_pho_loss: 2.1542 - val_param_rmse: 0.1569 - val_param_R2: 0.8552 - val_pho_accuracy: 0.8768\n",
      "Epoch 13/30\n",
      "98746/98746 - 32s - loss: 2.2071 - param_loss: 0.0255 - pho_loss: 2.1817 - param_rmse: 0.1459 - param_R2: 0.8888 - pho_accuracy: 0.8495 - val_loss: 2.1869 - val_param_loss: 0.0354 - val_pho_loss: 2.1516 - val_param_rmse: 0.1580 - val_param_R2: 0.8493 - val_pho_accuracy: 0.8788\n",
      "Epoch 14/30\n",
      "98746/98746 - 32s - loss: 2.2043 - param_loss: 0.0248 - pho_loss: 2.1795 - param_rmse: 0.1442 - param_R2: 0.8919 - pho_accuracy: 0.8514 - val_loss: 2.1895 - val_param_loss: 0.0333 - val_pho_loss: 2.1563 - val_param_rmse: 0.1543 - val_param_R2: 0.8576 - val_pho_accuracy: 0.8748\n",
      "Epoch 15/30\n",
      "98746/98746 - 32s - loss: 2.2003 - param_loss: 0.0244 - pho_loss: 2.1759 - param_rmse: 0.1433 - param_R2: 0.8935 - pho_accuracy: 0.8550 - val_loss: 2.1762 - val_param_loss: 0.0352 - val_pho_loss: 2.1411 - val_param_rmse: 0.1572 - val_param_R2: 0.8508 - val_pho_accuracy: 0.8902\n",
      "Epoch 16/30\n",
      "98746/98746 - 32s - loss: 2.1983 - param_loss: 0.0238 - pho_loss: 2.1745 - param_rmse: 0.1418 - param_R2: 0.8961 - pho_accuracy: 0.8568 - val_loss: 2.1876 - val_param_loss: 0.0346 - val_pho_loss: 2.1531 - val_param_rmse: 0.1564 - val_param_R2: 0.8531 - val_pho_accuracy: 0.8775\n",
      "Epoch 17/30\n",
      "98746/98746 - 32s - loss: 2.1951 - param_loss: 0.0233 - pho_loss: 2.1718 - param_rmse: 0.1407 - param_R2: 0.8980 - pho_accuracy: 0.8592 - val_loss: 2.1827 - val_param_loss: 0.0337 - val_pho_loss: 2.1492 - val_param_rmse: 0.1542 - val_param_R2: 0.8560 - val_pho_accuracy: 0.8822\n",
      "Epoch 18/30\n",
      "98746/98746 - 32s - loss: 2.1961 - param_loss: 0.0230 - pho_loss: 2.1731 - param_rmse: 0.1399 - param_R2: 0.8994 - pho_accuracy: 0.8582 - val_loss: 2.1838 - val_param_loss: 0.0349 - val_pho_loss: 2.1493 - val_param_rmse: 0.1557 - val_param_R2: 0.8516 - val_pho_accuracy: 0.8819\n",
      "Epoch 19/30\n",
      "98746/98746 - 32s - loss: 2.2000 - param_loss: 0.0229 - pho_loss: 2.1771 - param_rmse: 0.1395 - param_R2: 0.9000 - pho_accuracy: 0.8538 - val_loss: 2.1915 - val_param_loss: 0.0356 - val_pho_loss: 2.1560 - val_param_rmse: 0.1570 - val_param_R2: 0.8491 - val_pho_accuracy: 0.8756\n",
      "Epoch 20/30\n",
      "98746/98746 - 32s - loss: 2.1930 - param_loss: 0.0224 - pho_loss: 2.1707 - param_rmse: 0.1383 - param_R2: 0.9021 - pho_accuracy: 0.8602 - val_loss: 2.2064 - val_param_loss: 0.0342 - val_pho_loss: 2.1722 - val_param_rmse: 0.1555 - val_param_R2: 0.8542 - val_pho_accuracy: 0.8589\n",
      "Epoch 21/30\n",
      "98746/98746 - 32s - loss: 2.1896 - param_loss: 0.0220 - pho_loss: 2.1677 - param_rmse: 0.1373 - param_R2: 0.9038 - pho_accuracy: 0.8635 - val_loss: 2.1900 - val_param_loss: 0.0346 - val_pho_loss: 2.1553 - val_param_rmse: 0.1559 - val_param_R2: 0.8529 - val_pho_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "98746/98746 - 32s - loss: 2.1882 - param_loss: 0.0219 - pho_loss: 2.1663 - param_rmse: 0.1370 - param_R2: 0.9041 - pho_accuracy: 0.8647 - val_loss: 2.1802 - val_param_loss: 0.0338 - val_pho_loss: 2.1463 - val_param_rmse: 0.1537 - val_param_R2: 0.8561 - val_pho_accuracy: 0.8847\n",
      "Epoch 23/30\n",
      "98746/98746 - 32s - loss: 2.1866 - param_loss: 0.0214 - pho_loss: 2.1652 - param_rmse: 0.1358 - param_R2: 0.9062 - pho_accuracy: 0.8657 - val_loss: 2.1831 - val_param_loss: 0.0337 - val_pho_loss: 2.1494 - val_param_rmse: 0.1537 - val_param_R2: 0.8561 - val_pho_accuracy: 0.8818\n",
      "Epoch 24/30\n",
      "98746/98746 - 32s - loss: 2.1889 - param_loss: 0.0211 - pho_loss: 2.1678 - param_rmse: 0.1352 - param_R2: 0.9076 - pho_accuracy: 0.8633 - val_loss: 2.1869 - val_param_loss: 0.0351 - val_pho_loss: 2.1519 - val_param_rmse: 0.1553 - val_param_R2: 0.8510 - val_pho_accuracy: 0.8788\n",
      "Epoch 25/30\n",
      "98746/98746 - 32s - loss: 2.1867 - param_loss: 0.0211 - pho_loss: 2.1657 - param_rmse: 0.1348 - param_R2: 0.9077 - pho_accuracy: 0.8652 - val_loss: 2.1761 - val_param_loss: 0.0344 - val_pho_loss: 2.1421 - val_param_rmse: 0.1551 - val_param_R2: 0.8535 - val_pho_accuracy: 0.8897\n",
      "Epoch 26/30\n",
      "98746/98746 - 32s - loss: 2.1820 - param_loss: 0.0206 - pho_loss: 2.1614 - param_rmse: 0.1337 - param_R2: 0.9098 - pho_accuracy: 0.8697 - val_loss: 2.1857 - val_param_loss: 0.0331 - val_pho_loss: 2.1530 - val_param_rmse: 0.1530 - val_param_R2: 0.8577 - val_pho_accuracy: 0.8786\n",
      "Epoch 27/30\n",
      "98746/98746 - 32s - loss: 2.1859 - param_loss: 0.0207 - pho_loss: 2.1653 - param_rmse: 0.1338 - param_R2: 0.9095 - pho_accuracy: 0.8658 - val_loss: 2.1737 - val_param_loss: 0.0320 - val_pho_loss: 2.1420 - val_param_rmse: 0.1507 - val_param_R2: 0.8636 - val_pho_accuracy: 0.8893\n",
      "Epoch 28/30\n",
      "98746/98746 - 33s - loss: 2.1842 - param_loss: 0.0205 - pho_loss: 2.1637 - param_rmse: 0.1334 - param_R2: 0.9101 - pho_accuracy: 0.8672 - val_loss: 2.1855 - val_param_loss: 0.0334 - val_pho_loss: 2.1524 - val_param_rmse: 0.1526 - val_param_R2: 0.8576 - val_pho_accuracy: 0.8791\n",
      "Epoch 29/30\n",
      "98746/98746 - 33s - loss: 2.1804 - param_loss: 0.0199 - pho_loss: 2.1604 - param_rmse: 0.1319 - param_R2: 0.9128 - pho_accuracy: 0.8704 - val_loss: 2.1958 - val_param_loss: 0.0345 - val_pho_loss: 2.1613 - val_param_rmse: 0.1540 - val_param_R2: 0.8531 - val_pho_accuracy: 0.8693\n",
      "Epoch 30/30\n",
      "98746/98746 - 32s - loss: 2.1821 - param_loss: 0.0198 - pho_loss: 2.1622 - param_rmse: 0.1316 - param_R2: 0.9131 - pho_accuracy: 0.8688 - val_loss: 2.1781 - val_param_loss: 0.0349 - val_pho_loss: 2.1434 - val_param_rmse: 0.1547 - val_param_R2: 0.8509 - val_pho_accuracy: 0.8872\n"
     ]
    }
   ],
   "source": [
    "history = model_pho.fit(X_train,{\"param\": y_train, \"pho\": z_train_oe},\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_data=(X_val,{\"param\": y_val, \"pho\": z_val_oe}),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho.save('model_baseline_pho.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pho_pred = model_pho.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16499175 0.13846306 0.15626041 0.20971853 0.16883098 0.22409996\n",
      " 0.26204728 0.10337965 0.13968868 0.25097486 0.14635381 0.16778201\n",
      " 0.18071192 0.27521861 0.18504289 0.15457323 0.15504013]\n"
     ]
    }
   ],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[608   0   1  15   0   0   0   0   0   6  13   1   5  37   0   0   0   0\n",
      "    0]\n",
      " [  0 668   0   1   0   0   0   0   2   0   0   1   0   0   0   0   0   2\n",
      "   13]\n",
      " [  6   1 365   4   0   3   0   0   5  80   8  14  67  11   0   0   2   0\n",
      "    0]\n",
      " [ 14   0   0 622   0   0   2   0   6   0   5   6   4   0   0   0   0   0\n",
      "    0]\n",
      " [  1   0   0  12 595   0  31   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0 550   0   0   0   0  13   0  19  20   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   1  12   0 614  36   0   0   1   0   0   1   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   1  17 600   0   0   0   0   0   0   7   0   0   0\n",
      "    0]\n",
      " [  0   1  18   4   0   0   0   0 598   0   0  29   0   0   0   0   0   0\n",
      "    0]\n",
      " [  5   0  18   2   0   1   0   0   3 562   7  11  47   1   0   0   8   0\n",
      "    0]\n",
      " [ 16   0   1   3   0  44   2   0   0   1 546   0  10  10   0   0   0   0\n",
      "    0]\n",
      " [  5   1  16   0   0   0   0   0  54   5   0 537   0   0   0   0   5  24\n",
      "    0]\n",
      " [  1   1   8   3   0  24   1   0   2 109   6   1 448   6   0   0   0   0\n",
      "    0]\n",
      " [ 10   0   1   4   0  18   3   0   0   0   8   0  19 617   0   0   0   0\n",
      "    0]\n",
      " [  0   1   0   0   0   0   0  15   0   0   0   0   0   0 604   4   0   0\n",
      "    2]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  45 555   0   0\n",
      "   16]\n",
      " [  0   2  13   0   0   0   0   0   0   7   0  14   0   0   0   0 521  43\n",
      "    0]\n",
      " [  0   1   4   0   0   0   0   0   3   0   0  12   0   0   0   0  12 587\n",
      "    0]\n",
      " [  0  42   1   0   0   0   0   0   0   0   0   0   0   0   2   3   0   1\n",
      "  566]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           &       0.91      0.89      0.90       686\n",
      "           2       0.93      0.97      0.95       687\n",
      "           7       0.82      0.64      0.72       566\n",
      "           9       0.93      0.94      0.94       659\n",
      "           @       0.98      0.93      0.95       640\n",
      "           A       0.86      0.91      0.88       602\n",
      "           E       0.92      0.92      0.92       665\n",
      "          E:       0.92      0.96      0.94       625\n",
      "           M       0.89      0.92      0.90       650\n",
      "           O       0.73      0.85      0.78       665\n",
      "           Q       0.90      0.86      0.88       633\n",
      "           U       0.86      0.83      0.84       647\n",
      "           V       0.72      0.73      0.73       610\n",
      "           a       0.88      0.91      0.89       680\n",
      "           e       0.92      0.96      0.94       626\n",
      "           i       0.99      0.90      0.94       617\n",
      "           o       0.95      0.87      0.91       600\n",
      "           u       0.89      0.95      0.92       619\n",
      "           y       0.95      0.92      0.93       615\n",
      "\n",
      "    accuracy                           0.89     12092\n",
      "   macro avg       0.89      0.89      0.89     12092\n",
      "weighted avg       0.89      0.89      0.89     12092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_pho_pred, z_test_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "def init_embeded_pho(unit=128, drop_rate=0.2):\n",
    "    \n",
    "    def embeded(input_shape_1,input_shape_2):\n",
    "        inputs = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        x = pLSTM(100)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        outputs = pDense(19, activation='softmax')(x)\n",
    "        return keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return embeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 24, 39)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 24, 100)           56000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 19)                45619     \n",
      "=================================================================\n",
      "Total params: 101,619\n",
      "Trainable params: 101,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = init_embeded_pho()(24, 39)\n",
    "embedded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98746 samples, validate on 12094 samples\n",
      "Epoch 1/40\n",
      "98746/98746 [==============================] - 8s 84us/sample - loss: 2.3045 - accuracy: 0.7462 - val_loss: 2.1890 - val_accuracy: 0.8470\n",
      "Epoch 2/40\n",
      "98746/98746 [==============================] - 4s 44us/sample - loss: 2.2040 - accuracy: 0.8339 - val_loss: 2.1681 - val_accuracy: 0.8666\n",
      "Epoch 3/40\n",
      "98746/98746 [==============================] - 4s 42us/sample - loss: 2.1777 - accuracy: 0.8586 - val_loss: 2.1533 - val_accuracy: 0.8815\n",
      "Epoch 4/40\n",
      "98746/98746 [==============================] - 4s 43us/sample - loss: 2.1606 - accuracy: 0.8749 - val_loss: 2.1503 - val_accuracy: 0.8843\n",
      "Epoch 5/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.1477 - accuracy: 0.8875 - val_loss: 2.1458 - val_accuracy: 0.8892\n",
      "Epoch 6/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.1392 - accuracy: 0.8956 - val_loss: 2.1405 - val_accuracy: 0.8929\n",
      "Epoch 7/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.1320 - accuracy: 0.9028 - val_loss: 2.1513 - val_accuracy: 0.8811\n",
      "Epoch 8/40\n",
      "98746/98746 [==============================] - 4s 42us/sample - loss: 2.1266 - accuracy: 0.9075 - val_loss: 2.1435 - val_accuracy: 0.8884\n",
      "Epoch 9/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.1203 - accuracy: 0.9142 - val_loss: 2.1375 - val_accuracy: 0.8961\n",
      "Epoch 10/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.1170 - accuracy: 0.9167 - val_loss: 2.1356 - val_accuracy: 0.8970\n",
      "Epoch 11/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.1124 - accuracy: 0.9214 - val_loss: 2.1352 - val_accuracy: 0.8978\n",
      "Epoch 12/40\n",
      "98746/98746 [==============================] - 4s 42us/sample - loss: 2.1109 - accuracy: 0.9232 - val_loss: 2.1457 - val_accuracy: 0.8866\n",
      "Epoch 13/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.1060 - accuracy: 0.9274 - val_loss: 2.1427 - val_accuracy: 0.8895\n",
      "Epoch 14/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.1048 - accuracy: 0.9286 - val_loss: 2.1369 - val_accuracy: 0.8955\n",
      "Epoch 15/40\n",
      "98746/98746 [==============================] - 4s 42us/sample - loss: 2.1021 - accuracy: 0.9313 - val_loss: 2.1366 - val_accuracy: 0.8958\n",
      "Epoch 16/40\n",
      "98746/98746 [==============================] - 4s 42us/sample - loss: 2.1000 - accuracy: 0.9334 - val_loss: 2.1392 - val_accuracy: 0.8916\n",
      "Epoch 17/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0976 - accuracy: 0.9357 - val_loss: 2.1377 - val_accuracy: 0.8934\n",
      "Epoch 18/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0959 - accuracy: 0.9371 - val_loss: 2.1359 - val_accuracy: 0.8969\n",
      "Epoch 19/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0950 - accuracy: 0.9380 - val_loss: 2.1328 - val_accuracy: 0.8990\n",
      "Epoch 20/40\n",
      "98746/98746 [==============================] - 4s 42us/sample - loss: 2.0918 - accuracy: 0.9412 - val_loss: 2.1358 - val_accuracy: 0.8966\n",
      "Epoch 21/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0907 - accuracy: 0.9422 - val_loss: 2.1388 - val_accuracy: 0.8924\n",
      "Epoch 22/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0907 - accuracy: 0.9423 - val_loss: 2.1420 - val_accuracy: 0.8889\n",
      "Epoch 23/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0886 - accuracy: 0.9442 - val_loss: 2.1375 - val_accuracy: 0.8941\n",
      "Epoch 24/40\n",
      "98746/98746 [==============================] - 4s 42us/sample - loss: 2.0881 - accuracy: 0.9447 - val_loss: 2.1365 - val_accuracy: 0.8950\n",
      "Epoch 25/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0861 - accuracy: 0.9466 - val_loss: 2.1397 - val_accuracy: 0.8925\n",
      "Epoch 26/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0850 - accuracy: 0.9475 - val_loss: 2.1355 - val_accuracy: 0.8966\n",
      "Epoch 27/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0841 - accuracy: 0.9485 - val_loss: 2.1369 - val_accuracy: 0.8949\n",
      "Epoch 28/40\n",
      "98746/98746 [==============================] - 4s 42us/sample - loss: 2.0826 - accuracy: 0.9501 - val_loss: 2.1341 - val_accuracy: 0.8972\n",
      "Epoch 29/40\n",
      "98746/98746 [==============================] - 4s 41us/sample - loss: 2.0822 - accuracy: 0.9505 - val_loss: 2.1381 - val_accuracy: 0.8925\n",
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = embedded.fit(X_train,z_train_oe,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,z_val_oe),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.save('embedded.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[618   1   1  13   0   0   1   0   0   3  25   0   8  16   0   0   0   0\n",
      "    0]\n",
      " [  0 662   0   1   0   2   0   0   1   0   0   1   0   0   0   0   0   3\n",
      "   17]\n",
      " [  3   1 364   1   0   4   0   0   8  60   7  13  97   3   0   0   5   0\n",
      "    0]\n",
      " [ 15   1   0 610   1   0   2   0  12   0   3   0  12   3   0   0   0   0\n",
      "    0]\n",
      " [  4   0   0  12 577   0  46   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0 566   0   0   0   0  21   0   8   7   0   0   0   0\n",
      "    0]\n",
      " [  1   0   0  12   6   0 624  17   0   0   2   0   0   3   0   0   0   0\n",
      "    0]\n",
      " [  0   0   0   0   0   3  51 567   0   0   0   0   0   0   3   0   0   0\n",
      "    1]\n",
      " [  0   2   3   1   0   0   0   0 618   1   0  17   0   0   0   0   1   5\n",
      "    2]\n",
      " [  3   0   9   0   0   2   0   0   2 576   9   7  47   0   0   0  10   0\n",
      "    0]\n",
      " [  9   0   0   3   0  14   2   0   0   3 594   0   6   2   0   0   0   0\n",
      "    0]\n",
      " [  0   1   7   3   0   0   0   0  72   7   0 535   2   0   0   0   7  13\n",
      "    0]\n",
      " [  1   0   6   2   0  22   1   0   1  76  21   1 473   5   0   0   1   0\n",
      "    0]\n",
      " [ 10   0   0   4   0  30   1   0   0   1   6   0  22 606   0   0   0   0\n",
      "    0]\n",
      " [  0   1   0   0   0   0   0  14   0   0   0   0   0   0 602   9   0   0\n",
      "    0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  36 572   0   0\n",
      "    8]\n",
      " [  1   1   3   0   0   0   0   0   0  13   0   8   0   0   1   0 535  38\n",
      "    0]\n",
      " [  0   2   0   0   0   0   0   0   4   0   0  11   0   0   1   0   8 592\n",
      "    1]\n",
      " [  0  43   0   0   0   1   0   0   0   0   0   0   0   0   1   3   0   2\n",
      "  565]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           &       0.93      0.90      0.91       686\n",
      "           2       0.92      0.96      0.94       687\n",
      "           7       0.93      0.64      0.76       566\n",
      "           9       0.92      0.93      0.92       659\n",
      "           @       0.99      0.90      0.94       640\n",
      "           A       0.88      0.94      0.91       602\n",
      "           E       0.86      0.94      0.90       665\n",
      "          E:       0.95      0.91      0.93       625\n",
      "           M       0.86      0.95      0.90       650\n",
      "           O       0.78      0.87      0.82       665\n",
      "           Q       0.86      0.94      0.90       633\n",
      "           U       0.90      0.83      0.86       647\n",
      "           V       0.70      0.78      0.74       610\n",
      "           a       0.94      0.89      0.91       680\n",
      "           e       0.93      0.96      0.95       626\n",
      "           i       0.98      0.93      0.95       617\n",
      "           o       0.94      0.89      0.92       600\n",
      "           u       0.91      0.96      0.93       619\n",
      "           y       0.95      0.92      0.93       615\n",
      "\n",
      "    accuracy                           0.90     12092\n",
      "   macro avg       0.90      0.90      0.90     12092\n",
      "weighted avg       0.90      0.90      0.90     12092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = embedded.predict(X_test)\n",
    "evaluate_model(y_pred, z_test_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = tf.keras.models.load_model('embedded.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 24, 100)           56000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2400)              0         \n",
      "=================================================================\n",
      "Total params: 56,000\n",
      "Trainable params: 56,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "for layer in embedded.layers[:-1]:\n",
    "    model.add(layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12092, 2400)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'O'), (1, '2'), (2, 'U'), (3, 'o'), (4, '@'), (5, '9'), (6, 'u'), (7, 'E'), (8, '2'), (9, '2'), (10, 'A'), (11, '@'), (12, 'y'), (13, 'i'), (14, 'E'), (15, 'Q'), (16, 'u'), (17, 'o'), (18, '7'), (19, 'E:'), (20, '9'), (21, 'E:'), (22, '&'), (23, 'V'), (24, 'E:'), (25, 'o'), (26, '7'), (27, 'a'), (28, '2'), (29, 'i')]\n"
     ]
    }
   ],
   "source": [
    "print([(idx, item) for idx, item in enumerate(z_test.tolist()[:30])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(idx, idx2):\n",
    "    sim = 1 - cosine(y_pred[idx], y_pred[idx2])\n",
    "    if sim > 0.40:\n",
    "        print('{} {}: {}'.format(z_test[idx], z_test[idx2],sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O O: 1.0\n",
      "2 2: 1.0\n",
      "2 2: 0.5821772217750549\n",
      "U U: 1.0\n",
      "o o: 1.0\n",
      "@ @: 1.0\n",
      "9 9: 1.0\n",
      "9 9: 0.6471675634384155\n",
      "u u: 1.0\n",
      "E E: 1.0\n",
      "E E: 0.6792986392974854\n",
      "2 2: 0.5821772217750549\n",
      "2 2: 1.0\n",
      "2 2: 1.0\n",
      "A A: 1.0\n",
      "@ @: 1.0\n",
      "y y: 1.0\n",
      "i i: 1.0\n",
      "i E:: 0.43088242411613464\n",
      "i i: 0.4158954620361328\n",
      "E E: 0.6792986392974854\n",
      "E E: 1.0\n",
      "Q Q: 1.0\n",
      "u u: 1.0\n",
      "o o: 1.0\n",
      "7 7: 1.0\n",
      "7 7: 0.4666718542575836\n",
      "E: E:: 1.0\n",
      "E: E:: 0.4112861156463623\n",
      "E: E:: 0.5355876088142395\n",
      "9 9: 0.6471675634384155\n",
      "9 9: 1.0\n",
      "E: E:: 0.4112861156463623\n",
      "E: E:: 1.0\n",
      "E: E:: 0.4070873558521271\n",
      "& &: 1.0\n",
      "V V: 1.0\n",
      "E: i: 0.43088242411613464\n",
      "E: E:: 0.5355876088142395\n",
      "E: E:: 0.4070873558521271\n",
      "E: E:: 1.0\n",
      "o o: 1.0\n",
      "7 7: 0.4666718542575836\n",
      "7 7: 1.0\n",
      "a a: 1.0\n",
      "2 2: 1.0\n",
      "i i: 0.4158954620361328\n",
      "i i: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    for j in range(30):\n",
    "        cosine_sim(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "def init_bilstm(unit=128, bi_layer_num=3, drop_rate=0.2):\n",
    "\n",
    "    def bilstm(input_shape_1,input_shape_2):\n",
    "        \n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        # feature extraction layers\n",
    "        x = input_x\n",
    "        for i in range(bi_layer_num-1):\n",
    "            x = Bidirectional(pLSTM(unit))(x)\n",
    "            if drop_rate: \n",
    "                x = SpatialDropout1D(rate=drop_rate)(x)\n",
    "        # output layers\n",
    "        x = Bidirectional(pLSTM(unit, return_sequences=False))(x)\n",
    "        if drop_rate: \n",
    "            x = Dropout(rate=drop_rate)(x)\n",
    "        outputs_param = pDense(N_OUTPUTS, activation='linear')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=input_x, outputs=outputs_param)\n",
    "        # model.summary()\n",
    "        return model\n",
    "    return bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 24, 39)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 24, 256)           172032    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 24, 256)           394240    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                4369      \n",
      "=================================================================\n",
      "Total params: 964,881\n",
      "Trainable params: 964,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_bilstm()(24, 39)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98746 samples, validate on 12094 samples\n",
      "Epoch 1/30\n",
      "98746/98746 [==============================] - 29s 291us/sample - loss: 0.0784 - rmse: 0.2571 - R2: 0.6587 - val_loss: 0.0436 - val_rmse: 0.1841 - val_R2: 0.8149\n",
      "Epoch 2/30\n",
      "98746/98746 [==============================] - 16s 163us/sample - loss: 0.0498 - rmse: 0.2014 - R2: 0.7853 - val_loss: 0.0382 - val_rmse: 0.1709 - val_R2: 0.8370\n",
      "Epoch 3/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0434 - rmse: 0.1873 - R2: 0.8127 - val_loss: 0.0349 - val_rmse: 0.1629 - val_R2: 0.8511\n",
      "Epoch 4/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0398 - rmse: 0.1794 - R2: 0.8281 - val_loss: 0.0375 - val_rmse: 0.1656 - val_R2: 0.8401\n",
      "Epoch 5/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0374 - rmse: 0.1739 - R2: 0.8385 - val_loss: 0.0403 - val_rmse: 0.1689 - val_R2: 0.8309\n",
      "Epoch 6/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0355 - rmse: 0.1696 - R2: 0.8466 - val_loss: 0.0356 - val_rmse: 0.1609 - val_R2: 0.8490\n",
      "Epoch 7/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0339 - rmse: 0.1660 - R2: 0.8533 - val_loss: 0.0351 - val_rmse: 0.1583 - val_R2: 0.8507\n",
      "Epoch 8/30\n",
      "98746/98746 [==============================] - 16s 163us/sample - loss: 0.0327 - rmse: 0.1633 - R2: 0.8585 - val_loss: 0.0355 - val_rmse: 0.1598 - val_R2: 0.8491\n",
      "Epoch 9/30\n",
      "98746/98746 [==============================] - 16s 163us/sample - loss: 0.0316 - rmse: 0.1609 - R2: 0.8631 - val_loss: 0.0343 - val_rmse: 0.1573 - val_R2: 0.8537\n",
      "Epoch 10/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0304 - rmse: 0.1583 - R2: 0.8680 - val_loss: 0.0344 - val_rmse: 0.1566 - val_R2: 0.8533\n",
      "Epoch 11/30\n",
      "98746/98746 [==============================] - 16s 162us/sample - loss: 0.0294 - rmse: 0.1560 - R2: 0.8721 - val_loss: 0.0341 - val_rmse: 0.1556 - val_R2: 0.8549\n",
      "Epoch 12/30\n",
      "98746/98746 [==============================] - 16s 162us/sample - loss: 0.0286 - rmse: 0.1543 - R2: 0.8758 - val_loss: 0.0355 - val_rmse: 0.1576 - val_R2: 0.8491\n",
      "Epoch 13/30\n",
      "98746/98746 [==============================] - 16s 162us/sample - loss: 0.0279 - rmse: 0.1527 - R2: 0.8784 - val_loss: 0.0359 - val_rmse: 0.1577 - val_R2: 0.8461\n",
      "Epoch 14/30\n",
      "98746/98746 [==============================] - 16s 162us/sample - loss: 0.0277 - rmse: 0.1519 - R2: 0.8796 - val_loss: 0.0340 - val_rmse: 0.1553 - val_R2: 0.8544\n",
      "Epoch 15/30\n",
      "98746/98746 [==============================] - 16s 161us/sample - loss: 0.0272 - rmse: 0.1507 - R2: 0.8817 - val_loss: 0.0332 - val_rmse: 0.1527 - val_R2: 0.8585\n",
      "Epoch 16/30\n",
      "98746/98746 [==============================] - 16s 161us/sample - loss: 0.0263 - rmse: 0.1489 - R2: 0.8854 - val_loss: 0.0336 - val_rmse: 0.1537 - val_R2: 0.8570\n",
      "Epoch 17/30\n",
      "98746/98746 [==============================] - 16s 161us/sample - loss: 0.0259 - rmse: 0.1479 - R2: 0.8870 - val_loss: 0.0328 - val_rmse: 0.1520 - val_R2: 0.8600\n",
      "Epoch 18/30\n",
      "98746/98746 [==============================] - 16s 162us/sample - loss: 0.0253 - rmse: 0.1466 - R2: 0.8894 - val_loss: 0.0331 - val_rmse: 0.1516 - val_R2: 0.8590\n",
      "Epoch 19/30\n",
      "98746/98746 [==============================] - 16s 161us/sample - loss: 0.0253 - rmse: 0.1464 - R2: 0.8895 - val_loss: 0.0333 - val_rmse: 0.1519 - val_R2: 0.8581\n",
      "Epoch 20/30\n",
      "98746/98746 [==============================] - 16s 162us/sample - loss: 0.0248 - rmse: 0.1455 - R2: 0.8915 - val_loss: 0.0333 - val_rmse: 0.1517 - val_R2: 0.8580\n",
      "Epoch 21/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0246 - rmse: 0.1448 - R2: 0.8926 - val_loss: 0.0324 - val_rmse: 0.1499 - val_R2: 0.8615\n",
      "Epoch 22/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0239 - rmse: 0.1432 - R2: 0.8956 - val_loss: 0.0321 - val_rmse: 0.1504 - val_R2: 0.8625\n",
      "Epoch 23/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0239 - rmse: 0.1431 - R2: 0.8954 - val_loss: 0.0349 - val_rmse: 0.1541 - val_R2: 0.8513\n",
      "Epoch 24/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0236 - rmse: 0.1424 - R2: 0.8967 - val_loss: 0.0323 - val_rmse: 0.1496 - val_R2: 0.8616\n",
      "Epoch 25/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0233 - rmse: 0.1417 - R2: 0.8981 - val_loss: 0.0327 - val_rmse: 0.1500 - val_R2: 0.8610\n",
      "Epoch 26/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0231 - rmse: 0.1411 - R2: 0.8991 - val_loss: 0.0328 - val_rmse: 0.1510 - val_R2: 0.8596\n",
      "Epoch 27/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0228 - rmse: 0.1405 - R2: 0.9001 - val_loss: 0.0332 - val_rmse: 0.1511 - val_R2: 0.8581\n",
      "Epoch 28/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0227 - rmse: 0.1402 - R2: 0.9008 - val_loss: 0.0345 - val_rmse: 0.1526 - val_R2: 0.8540\n",
      "Epoch 29/30\n",
      "98746/98746 [==============================] - 16s 164us/sample - loss: 0.0224 - rmse: 0.1394 - R2: 0.9017 - val_loss: 0.0336 - val_rmse: 0.1516 - val_R2: 0.8563\n",
      "Epoch 30/30\n",
      "98746/98746 [==============================] - 16s 166us/sample - loss: 0.0224 - rmse: 0.1392 - R2: 0.9021 - val_loss: 0.0326 - val_rmse: 0.1493 - val_R2: 0.8606\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_baseline_2.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03239709647693383, 0.1489216, 0.8514758]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1568435  0.1333071  0.14723637 0.20025707 0.16252713 0.21058316\n",
      " 0.25390446 0.09769458 0.13031462 0.24590375 0.13846071 0.16655805\n",
      " 0.16988616 0.26658766 0.17800331 0.15121139 0.15160024]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 24, 100)           56000     \n",
      "=================================================================\n",
      "Total params: 56,000\n",
      "Trainable params: 0\n",
      "Non-trainable params: 56,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "embedded = tf.keras.models.load_model('embedded.hdf5')\n",
    "\n",
    "embedded_layers = tf.keras.Sequential()\n",
    "for layer in embedded.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "    embedded_layers.add(layer)\n",
    "embedded_layers.summary()\n",
    "\n",
    "def init_embeded_bilstm(unit=128, bi_layer_num=3, drop_rate=0.2):\n",
    "\n",
    "    def bilstm(input_shape_1,input_shape_2):\n",
    "        \n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        \n",
    "        emb = embedded_layers(input_x)\n",
    "        \n",
    "        # feature extraction layers\n",
    "        x = Concatenate()([input_x,emb])\n",
    "        for i in range(bi_layer_num-1):\n",
    "            x = Bidirectional(pLSTM(unit))(x)\n",
    "            if drop_rate: \n",
    "                x = SpatialDropout1D(rate=drop_rate)(x)\n",
    "        # output layers\n",
    "        x = Bidirectional(pLSTM(unit, return_sequences=False))(x)\n",
    "        if drop_rate: \n",
    "            x = Dropout(rate=drop_rate)(x)\n",
    "        outputs_param = pDense(N_OUTPUTS, activation='linear')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=input_x, outputs=outputs_param)\n",
    "        # model.summary()\n",
    "        return model\n",
    "    return bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 24, 100)      56000       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 24, 139)      0           input_5[0][0]                    \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 256)      274432      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 24, 256)      0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 24, 256)      394240      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 24, 256)      0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 256)          394240      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 17)           4369        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,123,281\n",
      "Trainable params: 1,067,281\n",
      "Non-trainable params: 56,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model = init_embeded_bilstm()(24, 39)\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98746 samples, validate on 12094 samples\n",
      "Epoch 1/30\n",
      "98746/98746 [==============================] - 48s 483us/sample - loss: 0.0590 - rmse: 0.2206 - R2: 0.7419 - val_loss: 0.0373 - val_rmse: 0.1669 - val_R2: 0.8411\n",
      "Epoch 2/30\n",
      "98746/98746 [==============================] - 27s 271us/sample - loss: 0.0379 - rmse: 0.1764 - R2: 0.8366 - val_loss: 0.0346 - val_rmse: 0.1603 - val_R2: 0.8524\n",
      "Epoch 3/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0344 - rmse: 0.1677 - R2: 0.8519 - val_loss: 0.0347 - val_rmse: 0.1603 - val_R2: 0.8523\n",
      "Epoch 4/30\n",
      "98746/98746 [==============================] - 27s 270us/sample - loss: 0.0324 - rmse: 0.1629 - R2: 0.8598 - val_loss: 0.0339 - val_rmse: 0.1569 - val_R2: 0.8551\n",
      "Epoch 5/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0309 - rmse: 0.1590 - R2: 0.8663 - val_loss: 0.0345 - val_rmse: 0.1572 - val_R2: 0.8522\n",
      "Epoch 6/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0296 - rmse: 0.1559 - R2: 0.8717 - val_loss: 0.0336 - val_rmse: 0.1557 - val_R2: 0.8564\n",
      "Epoch 7/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0286 - rmse: 0.1536 - R2: 0.8759 - val_loss: 0.0339 - val_rmse: 0.1552 - val_R2: 0.8548\n",
      "Epoch 8/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0276 - rmse: 0.1512 - R2: 0.8800 - val_loss: 0.0343 - val_rmse: 0.1557 - val_R2: 0.8537\n",
      "Epoch 9/30\n",
      "98746/98746 [==============================] - 27s 270us/sample - loss: 0.0269 - rmse: 0.1494 - R2: 0.8831 - val_loss: 0.0337 - val_rmse: 0.1534 - val_R2: 0.8566\n",
      "Epoch 10/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0263 - rmse: 0.1479 - R2: 0.8858 - val_loss: 0.0341 - val_rmse: 0.1543 - val_R2: 0.8548\n",
      "Epoch 11/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0257 - rmse: 0.1466 - R2: 0.8882 - val_loss: 0.0333 - val_rmse: 0.1517 - val_R2: 0.8576\n",
      "Epoch 12/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0249 - rmse: 0.1448 - R2: 0.8913 - val_loss: 0.0337 - val_rmse: 0.1530 - val_R2: 0.8560\n",
      "Epoch 13/30\n",
      "98746/98746 [==============================] - 26s 267us/sample - loss: 0.0244 - rmse: 0.1436 - R2: 0.8934 - val_loss: 0.0332 - val_rmse: 0.1522 - val_R2: 0.8585\n",
      "Epoch 14/30\n",
      "98746/98746 [==============================] - 26s 267us/sample - loss: 0.0240 - rmse: 0.1426 - R2: 0.8950 - val_loss: 0.0336 - val_rmse: 0.1520 - val_R2: 0.8566\n",
      "Epoch 15/30\n",
      "98746/98746 [==============================] - 26s 267us/sample - loss: 0.0237 - rmse: 0.1417 - R2: 0.8964 - val_loss: 0.0336 - val_rmse: 0.1524 - val_R2: 0.8575\n",
      "Epoch 16/30\n",
      "98746/98746 [==============================] - 26s 266us/sample - loss: 0.0232 - rmse: 0.1405 - R2: 0.8988 - val_loss: 0.0335 - val_rmse: 0.1519 - val_R2: 0.8569\n",
      "Epoch 17/30\n",
      "98746/98746 [==============================] - 26s 267us/sample - loss: 0.0227 - rmse: 0.1394 - R2: 0.9005 - val_loss: 0.0324 - val_rmse: 0.1498 - val_R2: 0.8621\n",
      "Epoch 18/30\n",
      "98746/98746 [==============================] - 26s 267us/sample - loss: 0.0225 - rmse: 0.1388 - R2: 0.9017 - val_loss: 0.0332 - val_rmse: 0.1503 - val_R2: 0.8586\n",
      "Epoch 19/30\n",
      "98746/98746 [==============================] - 26s 266us/sample - loss: 0.0222 - rmse: 0.1380 - R2: 0.9028 - val_loss: 0.0333 - val_rmse: 0.1506 - val_R2: 0.8583\n",
      "Epoch 20/30\n",
      "98746/98746 [==============================] - 27s 271us/sample - loss: 0.0221 - rmse: 0.1378 - R2: 0.9031 - val_loss: 0.0335 - val_rmse: 0.1510 - val_R2: 0.8577\n",
      "Epoch 21/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0214 - rmse: 0.1362 - R2: 0.9063 - val_loss: 0.0347 - val_rmse: 0.1528 - val_R2: 0.8528\n",
      "Epoch 22/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0211 - rmse: 0.1354 - R2: 0.9075 - val_loss: 0.0332 - val_rmse: 0.1502 - val_R2: 0.8580\n",
      "Epoch 23/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0208 - rmse: 0.1346 - R2: 0.9088 - val_loss: 0.0344 - val_rmse: 0.1519 - val_R2: 0.8534\n",
      "Epoch 24/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0209 - rmse: 0.1346 - R2: 0.9085 - val_loss: 0.0343 - val_rmse: 0.1518 - val_R2: 0.8541\n",
      "Epoch 25/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0206 - rmse: 0.1342 - R2: 0.9094 - val_loss: 0.0331 - val_rmse: 0.1497 - val_R2: 0.8592\n",
      "Epoch 26/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0204 - rmse: 0.1334 - R2: 0.9105 - val_loss: 0.0338 - val_rmse: 0.1503 - val_R2: 0.8564\n",
      "Epoch 27/30\n",
      "98746/98746 [==============================] - 27s 269us/sample - loss: 0.0202 - rmse: 0.1330 - R2: 0.9111 - val_loss: 0.0338 - val_rmse: 0.1506 - val_R2: 0.8562\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = emb_model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.save('model_embedded_bilstm.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03327701454338276, 0.14917862, 0.8477405]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = emb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15902291 0.13894631 0.14723567 0.19502921 0.16384531 0.22005402\n",
      " 0.26012667 0.10071308 0.13245143 0.24339959 0.13835357 0.1690107\n",
      " 0.17107858 0.27215488 0.17948705 0.15675618 0.15396349]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
