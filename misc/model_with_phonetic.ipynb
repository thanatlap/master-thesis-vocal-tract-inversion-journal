{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech + Phonetic AAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil \n",
    "import argparse\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Reshape, GRU, InputLayer, AlphaDropout, Activation, BatchNormalization, Dropout, Flatten, Dense, Bidirectional, LSTM, Conv1D, SpatialDropout1D, Concatenate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preprocessing data\n",
    "def delete_params(params):\n",
    "    '''\n",
    "    This function remove JX, WC, TRX, TRY, and MS1,2,3 paramter\n",
    "    '''\n",
    "    DEL_PARAMS_LIST = [2,8,15,16,21,22,23]\n",
    "    return np.delete(params,DEL_PARAMS_LIST , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "\n",
    "    # load data from preprocess pipeline\n",
    "    dataset = np.load(join('../data/d_dataset_p1/prep_data_13','training_subsets.npz'))\n",
    "    X_train =dataset['X_train']\n",
    "    y_train= dataset['y_train']\n",
    "    z_train= dataset['z_train']\n",
    "    X_val = dataset['X_val']\n",
    "    y_val = dataset['y_val']\n",
    "    z_val = dataset['z_val']\n",
    "    X_test = dataset['X_test']\n",
    "    y_test = dataset['y_test']\n",
    "    z_test = dataset['z_test']\n",
    "    \n",
    "    y_train = delete_params(y_train)\n",
    "    y_val = delete_params(y_val)\n",
    "    y_test = delete_params(y_test)\n",
    "\n",
    "    print('Train features and labels %s %s'%(str(X_train.shape),str(y_train.shape)))\n",
    "    print('Validating features and labels %s %s'%(str(X_val.shape),str(y_val.shape)))\n",
    "    print('Test features and labels %s %s'%(str(X_test.shape),str(y_test.shape)))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (98746, 24, 39) (98746, 17)\n",
      "Validating features and labels (12094, 24, 39) (12094, 17)\n",
      "Test features and labels (12092, 24, 39) (12092, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2', 'U', '@', 'O', 'o', 'A', 'y', 'E', 'i', '7', 'a', 'Q', 'V', 'e', '&', 'M', 'u', 'E:', '9'}\n"
     ]
    }
   ],
   "source": [
    "print(set(z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (98746, 24, 39) (98746, 17) (98746,)\n",
      "Validating features and labels (12094, 24, 39) (12094, 17) (12094,)\n",
      "Test features and labels (12092, 24, 39) (12092, 17) (12092,)\n"
     ]
    }
   ],
   "source": [
    "print('Train features and labels {} {} {}'.format(str(X_train.shape),str(y_train.shape),str(z_train.shape)))\n",
    "print('Validating features and labels {} {} {}'.format(str(X_val.shape),str(y_val.shape),str(z_val.shape)))\n",
    "print('Test features and labels {} {} {}'.format(str(X_test.shape),str(y_test.shape),str(z_test.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_oe=z_train.reshape(-1,1)\n",
    "z_val_oe=z_val.reshape(-1,1)\n",
    "z_test_oe=z_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(z_train_oe)\n",
    "\n",
    "z_train_oe = enc.transform(z_train_oe).toarray()\n",
    "z_test_oe = enc.transform(z_test_oe).toarray()\n",
    "z_val_oe = enc.transform(z_val_oe).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98746, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train_oe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12094, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_val_oe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train_oe[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "def init_bilstm_pho(unit=128, bi_layer_num=3, drop_rate=0.2):\n",
    "\n",
    "    def bilstm(input_shape_1,input_shape_2):\n",
    "        \n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        # feature extraction layers\n",
    "        x = input_x\n",
    "        for i in range(bi_layer_num-1):\n",
    "            x = Bidirectional(pLSTM(unit))(x)\n",
    "            if drop_rate: \n",
    "                x = SpatialDropout1D(rate=drop_rate)(x)\n",
    "        # output layers\n",
    "        x = Bidirectional(pLSTM(unit*2, return_sequences=False))(x)\n",
    "        if drop_rate: \n",
    "            x = Dropout(rate=drop_rate)(x)\n",
    "        x = pDense(1024, activation='relu')(x)\n",
    "        outputs_param = pDense(N_OUTPUTS, activation='linear')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=input_x, outputs=outputs_param)\n",
    "        # model.summary()\n",
    "        return model\n",
    "    return bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_bilstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3ff34845a066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_bilstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m39\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'init_bilstm' is not defined"
     ]
    }
   ],
   "source": [
    "model = init_bilstm()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred), axis = 0) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true, axis = 0)), axis = 0) \n",
    "    return K.mean(1 - (SS_res/SS_tot), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_baseline.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(actual,pred, axis=1):\n",
    "    # Compute RMSE by row (axis=1) result in rmse of each data\n",
    "    # Compute RMSE by column (axis=0) result in rmse of each label\n",
    "    return np.sqrt((np.square(actual - pred)).mean(axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Model + Phonetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM,\n",
    "    kernel_initializer='he_uniform',\n",
    "    return_sequences=True)\n",
    "\n",
    "pDense = partial(Dense,\n",
    "    kernel_initializer='he_normal',\n",
    "    activation='elu')\n",
    "\n",
    "def init_bilstm_pho(unit=128, bi_layer_num=3, drop_rate=0.2):\n",
    "\n",
    "    def bilstm(input_shape_1,input_shape_2):\n",
    "        \n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        # feature extraction layers\n",
    "        x = input_x\n",
    "        z = input_x\n",
    "        for i in range(bi_layer_num-1):\n",
    "            x = Bidirectional(pLSTM(unit))(x)\n",
    "            if drop_rate: \n",
    "                x = SpatialDropout1D(rate=drop_rate)(x)\n",
    "        # output layers\n",
    "        x = Bidirectional(pLSTM(unit*2, return_sequences=False))(x)\n",
    "        if drop_rate: \n",
    "            x = Dropout(rate=drop_rate)(x)\n",
    "                \n",
    "        for i in range(bi_layer_num-2):\n",
    "            z = Bidirectional(pLSTM(unit))(z)\n",
    "            if drop_rate: \n",
    "                z = SpatialDropout1D(rate=drop_rate)(z)\n",
    "        z = Bidirectional(pLSTM(unit*2, return_sequences=False))(z)\n",
    "        if drop_rate: \n",
    "            z = Dropout(rate=drop_rate)(z)\n",
    "        z = pDense(100, activation='relu')(z)\n",
    "        outputs_pho = pDense(19, activation='softmax', name='pho')(x)\n",
    "        \n",
    "        x = Concatenate()([x,z])\n",
    "        x = pDense(512, activation='relu')(x)\n",
    "        outputs_param = pDense(N_OUTPUTS, activation='linear', name='param')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=input_x, outputs=[outputs_param, outputs_pho])\n",
    "        # model.summary()\n",
    "        return model\n",
    "    return bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho = init_bilstm_pho()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"param\": \"mse\",\n",
    "    \"pho\": tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "}\n",
    "lossWeights = {\"param\": 1.0, \"pho\": 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"param\": [rmse, R2],\n",
    "    \"pho\": \"accuracy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho.compile(optimizer='adam',loss=losses, loss_weights=lossWeights, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = callbacks.EarlyStopping(monitor='param_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_pho.fit(X_train,{\"param\": y_train, \"pho\": z_train_oe},\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_data=(X_val,{\"param\": y_val, \"pho\": z_val_oe}),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pho.save('model_baseline_pho.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, label, model):\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    label = enc.inverse_transform(label)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(label, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pho_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(y_pho_pred, y_test, model_pho)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
