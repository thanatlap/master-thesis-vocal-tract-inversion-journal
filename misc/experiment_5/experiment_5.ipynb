{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on AAI Model Architectures\n",
    "- Created: 10 Mar 2020\n",
    "- Data: param_draft2\n",
    "- Increase data size and change model architecture\n",
    "- Pre SE\n",
    "- expeirment 12 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil \n",
    "import argparse\n",
    "from functools import partial\n",
    "import pickle\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Reshape, GRU, InputLayer, AlphaDropout, Activation, BatchNormalization, Dropout, Flatten, Dense, Bidirectional, LSTM, Conv1D, SpatialDropout1D, Concatenate, Multiply, Add\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = partial(np.load)\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred), axis = 0) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true, axis = 0)), axis = 0) \n",
    "    return K.mean(1 - (SS_res/SS_tot), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preprocessing data\n",
    "def delete_params(params):\n",
    "    '''\n",
    "    This function remove JX, WC, TRX, TRY, and MS1,2,3 paramter\n",
    "    '''\n",
    "    DEL_PARAMS_LIST = [2,8,15,16,21,22,23]\n",
    "    return np.delete(params,DEL_PARAMS_LIST , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(actual,pred, axis=1):\n",
    "    # Compute RMSE by row (axis=1) result in rmse of each data\n",
    "    # Compute RMSE by column (axis=0) result in rmse of each label\n",
    "    return np.sqrt((np.square(actual - pred)).mean(axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, label):\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    label = enc.inverse_transform(label)\n",
    "#     print('Confusion Matrix')\n",
    "#     print(confusion_matrix(label, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_se(actual,pred):\n",
    "    return np.sqrt((np.square(actual - pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "\n",
    "    # load data from preprocess pipeline\n",
    "    dataset = np.load(join('../../data/d_dataset_p2/prep_data_13','training_subsets.npz'))\n",
    "    X_train =dataset['X_train']\n",
    "    y_train= dataset['y_train']\n",
    "    z_train= dataset['z_train']\n",
    "    X_val = dataset['X_val']\n",
    "    y_val = dataset['y_val']\n",
    "    z_val = dataset['z_val']\n",
    "    X_test = dataset['X_test']\n",
    "    y_test = dataset['y_test']\n",
    "    z_test = dataset['z_test']\n",
    "    a_test = dataset['audio_test']\n",
    "    a_val = dataset['audio_val']\n",
    "    \n",
    "    y_train = delete_params(y_train)\n",
    "    y_val = delete_params(y_val)\n",
    "    y_test = delete_params(y_test)\n",
    "\n",
    "    print('Train features and labels %s %s'%(str(X_train.shape),str(y_train.shape)))\n",
    "    print('Validating features and labels %s %s'%(str(X_val.shape),str(y_val.shape)))\n",
    "    print('Test features and labels %s %s'%(str(X_test.shape),str(y_test.shape)))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test, a_test, a_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (76260, 24, 39) (76260, 17)\n",
      "Validating features and labels (9340, 24, 39) (9340, 17)\n",
      "Test features and labels (9338, 24, 39) (9338, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test, a_test, a_val = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E', 'u', '@', '2', 'A', 'e', 'E:', 'U', 'a', 'o', 'i', 'O', 'y', '9'}\n"
     ]
    }
   ],
   "source": [
    "print(set(z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (76260, 24, 39) (76260, 17) (76260,)\n",
      "Validating features and labels (9340, 24, 39) (9340, 17) (9340,)\n",
      "Test features and labels (9338, 24, 39) (9338, 17) (9338,)\n"
     ]
    }
   ],
   "source": [
    "print('Train features and labels {} {} {}'.format(str(X_train.shape),str(y_train.shape),str(z_train.shape)))\n",
    "print('Validating features and labels {} {} {}'.format(str(X_val.shape),str(y_val.shape),str(z_val.shape)))\n",
    "print('Test features and labels {} {} {}'.format(str(X_test.shape),str(y_test.shape),str(z_test.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_oe=z_train.reshape(-1,1)\n",
    "z_val_oe=z_val.reshape(-1,1)\n",
    "z_test_oe=z_test.reshape(-1,1)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(z_train_oe)\n",
    "\n",
    "z_train_oe = enc.transform(z_train_oe).toarray()\n",
    "z_test_oe = enc.transform(z_test_oe).toarray()\n",
    "z_val_oe = enc.transform(z_val_oe).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Train Baseline Model\n",
    "- Model without embedding feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Model without Embedded Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "pConv1D = partial(Conv1D, padding = 'same', activation = 'linear', kernel_initializer = 'he_uniform')\n",
    "\n",
    "def init_senet(feature_layer=1, cnn_unit=128, first_kernel=13, res_unit=128, res_kernel=7,\n",
    "    bilstm = 1, bilstm_unit=256, \n",
    "    dropout_rate=0.3,\n",
    "    reduction_ratio = 2,\n",
    "    activation_fn='relu'):\n",
    "\n",
    "\n",
    "    def cnn_block(input_x, cnn_unit, kernel_size):\n",
    "        x = pConv1D(cnn_unit, kernel_size=kernel_size)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        return x\n",
    "    \n",
    "    def residual_block(input_x):\n",
    "        x = pConv1D(res_unit, kernel_size=res_kernel)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        x = pConv1D(res_unit, kernel_size=res_kernel)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.Add()([x, input_x])\n",
    "        output = Activation(activation_fn)(x)\n",
    "        return output\n",
    "\n",
    "    def se_block(input_x):\n",
    "        x = layers.GlobalAveragePooling1D()(input_x)\n",
    "        channel_shape = getattr(x, '_shape_val')[-1]\n",
    "        x = Reshape((1, channel_shape))(x)\n",
    "        x = Dense(channel_shape // reduction_ratio, activation=activation_fn, kernel_initializer='he_uniform')(x)\n",
    "        x = Dense(channel_shape, activation='tanh', kernel_initializer='he_uniform')(x)\n",
    "        return x\n",
    "\n",
    "    def se_res_block(input_x):\n",
    "        se_x = se_block(input_x)\n",
    "        x = layers.Multiply()([input_x, se_x])\n",
    "        x = residual_block(x)\n",
    "        return x\n",
    "\n",
    "    def senet_nn(input_shape_1,input_shape_2):\n",
    "\n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        x = cnn_block(input_x, cnn_unit, first_kernel)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = cnn_block(x, cnn_unit=cnn_unit, kernel_size=1)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(bilstm-1):\n",
    "            x = Bidirectional(pLSTM(bilstm_unit))(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = Bidirectional(pLSTM(bilstm_unit, return_sequences=False))(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "        outputs = Dense(N_OUTPUTS, activation='linear', kernel_initializer='he_uniform')(x)\n",
    "        model = keras.Model(inputs=input_x, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    return senet_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_senet()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 24, 128)      65024       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 24, 128)      512         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 24, 128)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 128)       0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 64)        8256        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 128)       8320        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 24, 128)      0           activation[0][0]                 \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 24, 128)      114816      multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24, 128)      512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 24, 128)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 24, 128)      114816      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 128)      512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 24, 128)      0           batch_normalization_2[0][0]      \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 128)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 24, 128)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 64)        8256        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 128)       8320        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 24, 128)      0           spatial_dropout1d[0][0]          \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 24, 128)      114816      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 128)      512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 128)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 24, 128)      114816      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24, 128)      512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24, 128)      0           batch_normalization_4[0][0]      \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 128)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 24, 128)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 24, 128)      16512       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 24, 128)      512         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 24, 128)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 24, 128)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 512)          788480      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 17)           8721        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,374,225\n",
      "Trainable params: 1,372,689\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/100\n",
      "76260/76260 [==============================] - 27s 360us/sample - loss: 0.0896 - rmse: 0.2758 - R2: 0.6365 - val_loss: 0.0391 - val_rmse: 0.1813 - val_R2: 0.8427\n",
      "Epoch 2/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0525 - rmse: 0.2105 - R2: 0.7877 - val_loss: 0.0347 - val_rmse: 0.1701 - val_R2: 0.8601\n",
      "Epoch 3/100\n",
      "76260/76260 [==============================] - 18s 231us/sample - loss: 0.0465 - rmse: 0.1972 - R2: 0.8122 - val_loss: 0.0318 - val_rmse: 0.1643 - val_R2: 0.8713\n",
      "Epoch 4/100\n",
      "76260/76260 [==============================] - 18s 232us/sample - loss: 0.0434 - rmse: 0.1901 - R2: 0.8245 - val_loss: 0.0301 - val_rmse: 0.1594 - val_R2: 0.8779\n",
      "Epoch 5/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0414 - rmse: 0.1853 - R2: 0.8327 - val_loss: 0.0302 - val_rmse: 0.1582 - val_R2: 0.8772\n",
      "Epoch 6/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0395 - rmse: 0.1810 - R2: 0.8401 - val_loss: 0.0290 - val_rmse: 0.1561 - val_R2: 0.8827\n",
      "Epoch 7/100\n",
      "76260/76260 [==============================] - 17s 229us/sample - loss: 0.0382 - rmse: 0.1779 - R2: 0.8453 - val_loss: 0.0293 - val_rmse: 0.1557 - val_R2: 0.8807\n",
      "Epoch 8/100\n",
      "76260/76260 [==============================] - 18s 231us/sample - loss: 0.0377 - rmse: 0.1765 - R2: 0.8473 - val_loss: 0.0275 - val_rmse: 0.1513 - val_R2: 0.8880\n",
      "Epoch 9/100\n",
      "76260/76260 [==============================] - 17s 229us/sample - loss: 0.0364 - rmse: 0.1734 - R2: 0.8529 - val_loss: 0.0280 - val_rmse: 0.1522 - val_R2: 0.8862\n",
      "Epoch 10/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0356 - rmse: 0.1713 - R2: 0.8557 - val_loss: 0.0273 - val_rmse: 0.1504 - val_R2: 0.8891\n",
      "Epoch 11/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0345 - rmse: 0.1692 - R2: 0.8603 - val_loss: 0.0266 - val_rmse: 0.1483 - val_R2: 0.8916\n",
      "Epoch 12/100\n",
      "76260/76260 [==============================] - 18s 231us/sample - loss: 0.0342 - rmse: 0.1682 - R2: 0.8615 - val_loss: 0.0253 - val_rmse: 0.1454 - val_R2: 0.8967\n",
      "Epoch 13/100\n",
      "76260/76260 [==============================] - 17s 229us/sample - loss: 0.0335 - rmse: 0.1665 - R2: 0.8645 - val_loss: 0.0257 - val_rmse: 0.1469 - val_R2: 0.8954\n",
      "Epoch 14/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0331 - rmse: 0.1655 - R2: 0.8657 - val_loss: 0.0247 - val_rmse: 0.1434 - val_R2: 0.8991\n",
      "Epoch 15/100\n",
      "76260/76260 [==============================] - 17s 229us/sample - loss: 0.0325 - rmse: 0.1640 - R2: 0.8683 - val_loss: 0.0249 - val_rmse: 0.1443 - val_R2: 0.8983\n",
      "Epoch 16/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0317 - rmse: 0.1622 - R2: 0.8718 - val_loss: 0.0244 - val_rmse: 0.1424 - val_R2: 0.9006\n",
      "Epoch 17/100\n",
      "76260/76260 [==============================] - 17s 229us/sample - loss: 0.0316 - rmse: 0.1616 - R2: 0.8721 - val_loss: 0.0249 - val_rmse: 0.1439 - val_R2: 0.8982\n",
      "Epoch 18/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0313 - rmse: 0.1608 - R2: 0.8734 - val_loss: 0.0264 - val_rmse: 0.1462 - val_R2: 0.8918\n",
      "Epoch 19/100\n",
      "76260/76260 [==============================] - 18s 231us/sample - loss: 0.0309 - rmse: 0.1600 - R2: 0.8749 - val_loss: 0.0236 - val_rmse: 0.1406 - val_R2: 0.9042\n",
      "Epoch 20/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0303 - rmse: 0.1586 - R2: 0.8771 - val_loss: 0.0244 - val_rmse: 0.1420 - val_R2: 0.9011\n",
      "Epoch 21/100\n",
      "76260/76260 [==============================] - 17s 229us/sample - loss: 0.0305 - rmse: 0.1591 - R2: 0.8763 - val_loss: 0.0244 - val_rmse: 0.1416 - val_R2: 0.9006\n",
      "Epoch 22/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0298 - rmse: 0.1571 - R2: 0.8794 - val_loss: 0.0239 - val_rmse: 0.1402 - val_R2: 0.9028\n",
      "Epoch 23/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0292 - rmse: 0.1559 - R2: 0.8819 - val_loss: 0.0248 - val_rmse: 0.1416 - val_R2: 0.8989\n",
      "Epoch 24/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0292 - rmse: 0.1558 - R2: 0.8818 - val_loss: 0.0231 - val_rmse: 0.1385 - val_R2: 0.9055\n",
      "Epoch 25/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0286 - rmse: 0.1545 - R2: 0.8840 - val_loss: 0.0238 - val_rmse: 0.1400 - val_R2: 0.9027\n",
      "Epoch 26/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0287 - rmse: 0.1546 - R2: 0.8836 - val_loss: 0.0233 - val_rmse: 0.1387 - val_R2: 0.9052\n",
      "Epoch 27/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0284 - rmse: 0.1538 - R2: 0.8852 - val_loss: 0.0230 - val_rmse: 0.1372 - val_R2: 0.9057\n",
      "Epoch 28/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0279 - rmse: 0.1526 - R2: 0.8870 - val_loss: 0.0236 - val_rmse: 0.1385 - val_R2: 0.9032\n",
      "Epoch 29/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0278 - rmse: 0.1523 - R2: 0.8875 - val_loss: 0.0242 - val_rmse: 0.1397 - val_R2: 0.9009\n",
      "Epoch 30/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0275 - rmse: 0.1517 - R2: 0.8885 - val_loss: 0.0233 - val_rmse: 0.1378 - val_R2: 0.9045\n",
      "Epoch 31/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0273 - rmse: 0.1512 - R2: 0.8894 - val_loss: 0.0231 - val_rmse: 0.1374 - val_R2: 0.9061\n",
      "Epoch 32/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0272 - rmse: 0.1509 - R2: 0.8896 - val_loss: 0.0224 - val_rmse: 0.1365 - val_R2: 0.9084\n",
      "Epoch 33/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0266 - rmse: 0.1495 - R2: 0.8922 - val_loss: 0.0224 - val_rmse: 0.1354 - val_R2: 0.9082\n",
      "Epoch 34/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0265 - rmse: 0.1493 - R2: 0.8926 - val_loss: 0.0230 - val_rmse: 0.1373 - val_R2: 0.9063\n",
      "Epoch 35/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0269 - rmse: 0.1502 - R2: 0.8909 - val_loss: 0.0222 - val_rmse: 0.1351 - val_R2: 0.9093\n",
      "Epoch 36/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0264 - rmse: 0.1488 - R2: 0.8931 - val_loss: 0.0222 - val_rmse: 0.1350 - val_R2: 0.9092\n",
      "Epoch 37/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0261 - rmse: 0.1483 - R2: 0.8942 - val_loss: 0.0232 - val_rmse: 0.1373 - val_R2: 0.9057\n",
      "Epoch 38/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0260 - rmse: 0.1478 - R2: 0.8948 - val_loss: 0.0226 - val_rmse: 0.1354 - val_R2: 0.9073\n",
      "Epoch 39/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0257 - rmse: 0.1472 - R2: 0.8959 - val_loss: 0.0221 - val_rmse: 0.1344 - val_R2: 0.9095\n",
      "Epoch 40/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0258 - rmse: 0.1472 - R2: 0.8958 - val_loss: 0.0221 - val_rmse: 0.1345 - val_R2: 0.9095\n",
      "Epoch 41/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0257 - rmse: 0.1470 - R2: 0.8962 - val_loss: 0.0222 - val_rmse: 0.1345 - val_R2: 0.9093\n",
      "Epoch 42/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0254 - rmse: 0.1463 - R2: 0.8972 - val_loss: 0.0223 - val_rmse: 0.1360 - val_R2: 0.9092\n",
      "Epoch 43/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0254 - rmse: 0.1464 - R2: 0.8971 - val_loss: 0.0226 - val_rmse: 0.1354 - val_R2: 0.9075\n",
      "Epoch 44/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0252 - rmse: 0.1457 - R2: 0.8981 - val_loss: 0.0219 - val_rmse: 0.1337 - val_R2: 0.9102\n",
      "Epoch 45/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0249 - rmse: 0.1452 - R2: 0.8992 - val_loss: 0.0224 - val_rmse: 0.1347 - val_R2: 0.9083\n",
      "Epoch 46/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0246 - rmse: 0.1445 - R2: 0.9004 - val_loss: 0.0227 - val_rmse: 0.1350 - val_R2: 0.9067\n",
      "Epoch 47/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0246 - rmse: 0.1443 - R2: 0.9005 - val_loss: 0.0218 - val_rmse: 0.1326 - val_R2: 0.9107\n",
      "Epoch 48/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0245 - rmse: 0.1440 - R2: 0.9009 - val_loss: 0.0226 - val_rmse: 0.1355 - val_R2: 0.9076\n",
      "Epoch 49/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0243 - rmse: 0.1436 - R2: 0.9018 - val_loss: 0.0230 - val_rmse: 0.1354 - val_R2: 0.9054\n",
      "Epoch 50/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0243 - rmse: 0.1435 - R2: 0.9016 - val_loss: 0.0226 - val_rmse: 0.1347 - val_R2: 0.9071\n",
      "Epoch 51/100\n",
      "76260/76260 [==============================] - 17s 228us/sample - loss: 0.0246 - rmse: 0.1442 - R2: 0.9005 - val_loss: 0.0222 - val_rmse: 0.1339 - val_R2: 0.9087\n",
      "Epoch 52/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0242 - rmse: 0.1434 - R2: 0.9020 - val_loss: 0.0225 - val_rmse: 0.1346 - val_R2: 0.9083\n",
      "Epoch 53/100\n",
      "76260/76260 [==============================] - 17s 227us/sample - loss: 0.0239 - rmse: 0.1426 - R2: 0.9031 - val_loss: 0.0224 - val_rmse: 0.1342 - val_R2: 0.9081\n",
      "Epoch 54/100\n",
      "76260/76260 [==============================] - 18s 235us/sample - loss: 0.0238 - rmse: 0.1423 - R2: 0.9038 - val_loss: 0.0226 - val_rmse: 0.1348 - val_R2: 0.9067\n",
      "Epoch 55/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0235 - rmse: 0.1417 - R2: 0.9047 - val_loss: 0.0222 - val_rmse: 0.1330 - val_R2: 0.9094\n",
      "Epoch 56/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0238 - rmse: 0.1423 - R2: 0.9034 - val_loss: 0.0221 - val_rmse: 0.1333 - val_R2: 0.9089\n",
      "Epoch 57/100\n",
      "76260/76260 [==============================] - 18s 230us/sample - loss: 0.0240 - rmse: 0.1426 - R2: 0.9030 - val_loss: 0.0224 - val_rmse: 0.1335 - val_R2: 0.9089\n",
      "Epoch 00057: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_baseline.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02214339342503674, 0.13358897, 0.90401524]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15131707 0.12680595 0.12171652 0.13883751 0.14916609 0.18558254\n",
      " 0.20481043 0.09804399 0.11042881 0.14687408 0.15451697 0.1364162\n",
      " 0.13520527 0.18700868 0.14672336 0.14532703 0.15154928]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Trained Embedding Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHONETIC_OUTPUT = len(set(z_train))\n",
    "EMBEDDED_FEATURE = 128\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "\n",
    "def embeded_model(input_shape_1,input_shape_2):\n",
    "    inputs = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "    x = pLSTM(64, return_sequences=False)(inputs)\n",
    "    Dense(EMBEDDED_FEATURE, activation='sigmoid', kernel_initializer='he_uniform')(x)\n",
    "    outputs = Dense(PHONETIC_OUTPUT, activation='softmax', kernel_initializer='he_uniform')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 24, 39)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                26624     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 27,534\n",
      "Trainable params: 27,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = embeded_model(24, 39)\n",
    "embedded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/100\n",
      "76260/76260 [==============================] - 5s 71us/sample - loss: 2.0958 - accuracy: 0.7063 - val_loss: 1.9013 - val_accuracy: 0.8675\n",
      "Epoch 2/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.9206 - accuracy: 0.8484 - val_loss: 1.8615 - val_accuracy: 0.9006\n",
      "Epoch 3/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8885 - accuracy: 0.8757 - val_loss: 1.8475 - val_accuracy: 0.9134\n",
      "Epoch 4/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8722 - accuracy: 0.8900 - val_loss: 1.8419 - val_accuracy: 0.9175\n",
      "Epoch 5/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8626 - accuracy: 0.8981 - val_loss: 1.8372 - val_accuracy: 0.9208\n",
      "Epoch 6/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8555 - accuracy: 0.9046 - val_loss: 1.8346 - val_accuracy: 0.9227\n",
      "Epoch 7/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8501 - accuracy: 0.9098 - val_loss: 1.8318 - val_accuracy: 0.9248\n",
      "Epoch 8/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8454 - accuracy: 0.9140 - val_loss: 1.8298 - val_accuracy: 0.9273\n",
      "Epoch 9/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8413 - accuracy: 0.9176 - val_loss: 1.8262 - val_accuracy: 0.9300\n",
      "Epoch 10/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8370 - accuracy: 0.9219 - val_loss: 1.8288 - val_accuracy: 0.9285\n",
      "Epoch 11/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8342 - accuracy: 0.9244 - val_loss: 1.8259 - val_accuracy: 0.9304\n",
      "Epoch 12/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8311 - accuracy: 0.9272 - val_loss: 1.8212 - val_accuracy: 0.9355\n",
      "Epoch 13/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8312 - accuracy: 0.9269 - val_loss: 1.8275 - val_accuracy: 0.9284\n",
      "Epoch 14/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8289 - accuracy: 0.9291 - val_loss: 1.8257 - val_accuracy: 0.9305\n",
      "Epoch 15/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8264 - accuracy: 0.9313 - val_loss: 1.8211 - val_accuracy: 0.9353\n",
      "Epoch 16/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8228 - accuracy: 0.9346 - val_loss: 1.8192 - val_accuracy: 0.9372\n",
      "Epoch 17/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8221 - accuracy: 0.9359 - val_loss: 1.8205 - val_accuracy: 0.9358\n",
      "Epoch 18/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8212 - accuracy: 0.9367 - val_loss: 1.8257 - val_accuracy: 0.9315\n",
      "Epoch 19/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8190 - accuracy: 0.9386 - val_loss: 1.8170 - val_accuracy: 0.9401\n",
      "Epoch 20/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8170 - accuracy: 0.9407 - val_loss: 1.8179 - val_accuracy: 0.9382\n",
      "Epoch 21/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8155 - accuracy: 0.9423 - val_loss: 1.8173 - val_accuracy: 0.9382\n",
      "Epoch 22/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8146 - accuracy: 0.9428 - val_loss: 1.8162 - val_accuracy: 0.9394\n",
      "Epoch 23/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8128 - accuracy: 0.9446 - val_loss: 1.8159 - val_accuracy: 0.9397\n",
      "Epoch 24/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8122 - accuracy: 0.9453 - val_loss: 1.8162 - val_accuracy: 0.9397\n",
      "Epoch 25/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8103 - accuracy: 0.9470 - val_loss: 1.8175 - val_accuracy: 0.9387\n",
      "Epoch 26/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8115 - accuracy: 0.9456 - val_loss: 1.8120 - val_accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8111 - accuracy: 0.9464 - val_loss: 1.8120 - val_accuracy: 0.9441\n",
      "Epoch 28/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8108 - accuracy: 0.9465 - val_loss: 1.8158 - val_accuracy: 0.9409\n",
      "Epoch 29/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8081 - accuracy: 0.9492 - val_loss: 1.8160 - val_accuracy: 0.9403\n",
      "Epoch 30/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8063 - accuracy: 0.9510 - val_loss: 1.8158 - val_accuracy: 0.9405\n",
      "Epoch 31/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8099 - accuracy: 0.9472 - val_loss: 1.8165 - val_accuracy: 0.9394\n",
      "Epoch 32/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8075 - accuracy: 0.9493 - val_loss: 1.8192 - val_accuracy: 0.9366\n",
      "Epoch 33/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8062 - accuracy: 0.9506 - val_loss: 1.8145 - val_accuracy: 0.9407\n",
      "Epoch 34/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8045 - accuracy: 0.9523 - val_loss: 1.8118 - val_accuracy: 0.9443\n",
      "Epoch 35/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8031 - accuracy: 0.9540 - val_loss: 1.8141 - val_accuracy: 0.9422\n",
      "Epoch 36/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8023 - accuracy: 0.9546 - val_loss: 1.8136 - val_accuracy: 0.9415\n",
      "Epoch 37/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8024 - accuracy: 0.9544 - val_loss: 1.8135 - val_accuracy: 0.9422\n",
      "Epoch 38/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8046 - accuracy: 0.9519 - val_loss: 1.8154 - val_accuracy: 0.9409\n",
      "Epoch 39/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8050 - accuracy: 0.9515 - val_loss: 1.8115 - val_accuracy: 0.9444\n",
      "Epoch 40/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8031 - accuracy: 0.9535 - val_loss: 1.8136 - val_accuracy: 0.9427\n",
      "Epoch 41/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8029 - accuracy: 0.9537 - val_loss: 1.8129 - val_accuracy: 0.9422\n",
      "Epoch 42/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8006 - accuracy: 0.9559 - val_loss: 1.8147 - val_accuracy: 0.9404\n",
      "Epoch 43/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8003 - accuracy: 0.9565 - val_loss: 1.8151 - val_accuracy: 0.9407\n",
      "Epoch 44/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7980 - accuracy: 0.9589 - val_loss: 1.8122 - val_accuracy: 0.9441\n",
      "Epoch 45/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7994 - accuracy: 0.9569 - val_loss: 1.8084 - val_accuracy: 0.9474\n",
      "Epoch 46/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7986 - accuracy: 0.9577 - val_loss: 1.8152 - val_accuracy: 0.9406\n",
      "Epoch 47/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7997 - accuracy: 0.9567 - val_loss: 1.8125 - val_accuracy: 0.9433\n",
      "Epoch 48/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8009 - accuracy: 0.9557 - val_loss: 1.8143 - val_accuracy: 0.9410\n",
      "Epoch 49/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7973 - accuracy: 0.9592 - val_loss: 1.8103 - val_accuracy: 0.9452\n",
      "Epoch 50/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7983 - accuracy: 0.9584 - val_loss: 1.8122 - val_accuracy: 0.9430\n",
      "Epoch 51/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7981 - accuracy: 0.9581 - val_loss: 1.8156 - val_accuracy: 0.9404\n",
      "Epoch 52/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7978 - accuracy: 0.9586 - val_loss: 1.8183 - val_accuracy: 0.9370\n",
      "Epoch 53/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7972 - accuracy: 0.9592 - val_loss: 1.8104 - val_accuracy: 0.9449\n",
      "Epoch 54/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7961 - accuracy: 0.9603 - val_loss: 1.8106 - val_accuracy: 0.9437\n",
      "Epoch 55/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7962 - accuracy: 0.9601 - val_loss: 1.8089 - val_accuracy: 0.9469\n",
      "Epoch 00055: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = embedded.fit(X_train,z_train_oe,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,z_val_oe),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.save('embedded.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluated Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.94      0.97      0.96       701\n",
      "           9       0.98      0.97      0.98       688\n",
      "           @       0.97      0.97      0.97       635\n",
      "           A       0.93      0.97      0.95       645\n",
      "           E       0.93      0.96      0.94       697\n",
      "          E:       0.94      0.94      0.94       655\n",
      "           O       0.93      0.95      0.94       729\n",
      "           U       0.92      0.92      0.92       687\n",
      "           a       0.97      0.93      0.95       689\n",
      "           e       0.93      0.95      0.94       644\n",
      "           i       0.98      0.93      0.95       684\n",
      "           o       0.95      0.88      0.91       634\n",
      "           u       0.90      0.95      0.92       659\n",
      "           y       0.94      0.94      0.94       591\n",
      "\n",
      "    accuracy                           0.94      9338\n",
      "   macro avg       0.95      0.94      0.94      9338\n",
      "weighted avg       0.95      0.94      0.94      9338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z_pred = embedded.predict(X_test)\n",
    "evaluate_model(z_pred, z_test_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Model with Embedding Feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                26624     \n",
      "=================================================================\n",
      "Total params: 26,624\n",
      "Trainable params: 0\n",
      "Non-trainable params: 26,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = tf.keras.models.load_model('embedded.hdf5')\n",
    "\n",
    "embedded_layers = tf.keras.Sequential()\n",
    "for layer in embedded.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    embedded_layers.add(layer)\n",
    "embedded_layers.summary()\n",
    "\n",
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "pConv1D = partial(Conv1D, padding = 'same', activation = 'linear', kernel_initializer = 'he_uniform')\n",
    "\n",
    "def init_senet_w_emb(feature_layer=1, cnn_unit=128, first_kernel=13, res_unit=128, res_kernel=7,\n",
    "    bilstm = 1, bilstm_unit=256, \n",
    "    dropout_rate=0.3,\n",
    "    reduction_ratio = 2,\n",
    "    activation_fn='relu'):\n",
    "\n",
    "    def cnn_block(input_x, cnn_unit, kernel_size):\n",
    "        x = pConv1D(cnn_unit, kernel_size=kernel_size)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        return x\n",
    "    \n",
    "    def residual_block(input_x):\n",
    "        x = pConv1D(res_unit, kernel_size=res_kernel)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        x = pConv1D(res_unit, kernel_size=res_kernel)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.Add()([x, input_x])\n",
    "        output = Activation(activation_fn)(x)\n",
    "        return output\n",
    "\n",
    "    def se_block(input_x):\n",
    "        x = layers.GlobalAveragePooling1D()(input_x)\n",
    "        channel_shape = getattr(x, '_shape_val')[-1]\n",
    "        x = Reshape((1, channel_shape))(x)\n",
    "        x = Dense(channel_shape // reduction_ratio, activation=activation_fn, kernel_initializer='he_uniform')(x)\n",
    "        x = Dense(channel_shape, activation='tanh', kernel_initializer='he_uniform')(x)\n",
    "        return x\n",
    "\n",
    "    def se_res_block(input_x):\n",
    "        se_x = se_block(input_x)\n",
    "        x = layers.Multiply()([input_x, se_x])\n",
    "        x = residual_block(x)\n",
    "        return x\n",
    "\n",
    "    def senet_nn(input_shape_1,input_shape_2):\n",
    "\n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        \n",
    "        x = cnn_block(input_x, cnn_unit, first_kernel)\n",
    "\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = cnn_block(x, cnn_unit=cnn_unit, kernel_size=1)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(bilstm-1):\n",
    "            x = Bidirectional(pLSTM(bilstm_unit))(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = Bidirectional(pLSTM(bilstm_unit, return_sequences=False))(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "        embedded = embedded_layers(input_x)\n",
    "        embedded_x = layers.Concatenate()([x, embedded])\n",
    "        outputs = Dense(N_OUTPUTS, activation='linear', kernel_initializer='he_uniform')(embedded_x)\n",
    "        model = keras.Model(inputs=input_x, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    return senet_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 24, 128)      65024       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 24, 128)      512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 128)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        8256        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 128)       8320        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 24, 128)      0           activation_6[0][0]               \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 24, 128)      114816      multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 24, 128)      512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 128)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 24, 128)      114816      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 24, 128)      512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 128)      0           batch_normalization_8[0][0]      \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 24, 128)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 24, 128)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 64)        8256        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 128)       8320        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 24, 128)      0           spatial_dropout1d_3[0][0]        \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 24, 128)      114816      multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 24, 128)      512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 24, 128)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 24, 128)      114816      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 24, 128)      512         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 128)      0           batch_normalization_10[0][0]     \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 24, 128)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 24, 128)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 24, 128)      16512       spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 24, 128)      512         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 24, 128)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 24, 128)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 512)          788480      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 64)           26624       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 576)          0           dropout_1[0][0]                  \n",
      "                                                                 sequential[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 17)           9809        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,401,937\n",
      "Trainable params: 1,373,777\n",
      "Non-trainable params: 28,160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model = init_senet_w_emb()(24, 39)\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/100\n",
      "76260/76260 - 32s - loss: 0.0781 - rmse: 0.2554 - R2: 0.6841 - val_loss: 0.0392 - val_rmse: 0.1863 - val_R2: 0.8411\n",
      "Epoch 2/100\n",
      "76260/76260 - 21s - loss: 0.0445 - rmse: 0.1987 - R2: 0.8199 - val_loss: 0.0359 - val_rmse: 0.1775 - val_R2: 0.8539\n",
      "Epoch 3/100\n",
      "76260/76260 - 21s - loss: 0.0410 - rmse: 0.1900 - R2: 0.8336 - val_loss: 0.0333 - val_rmse: 0.1707 - val_R2: 0.8637\n",
      "Epoch 4/100\n",
      "76260/76260 - 21s - loss: 0.0390 - rmse: 0.1847 - R2: 0.8417 - val_loss: 0.0315 - val_rmse: 0.1656 - val_R2: 0.8709\n",
      "Epoch 5/100\n",
      "76260/76260 - 21s - loss: 0.0376 - rmse: 0.1808 - R2: 0.8475 - val_loss: 0.0300 - val_rmse: 0.1613 - val_R2: 0.8769\n",
      "Epoch 6/100\n",
      "76260/76260 - 21s - loss: 0.0362 - rmse: 0.1771 - R2: 0.8528 - val_loss: 0.0304 - val_rmse: 0.1621 - val_R2: 0.8760\n",
      "Epoch 7/100\n",
      "76260/76260 - 21s - loss: 0.0350 - rmse: 0.1738 - R2: 0.8577 - val_loss: 0.0279 - val_rmse: 0.1553 - val_R2: 0.8857\n",
      "Epoch 8/100\n",
      "76260/76260 - 21s - loss: 0.0342 - rmse: 0.1717 - R2: 0.8609 - val_loss: 0.0272 - val_rmse: 0.1531 - val_R2: 0.8889\n",
      "Epoch 9/100\n",
      "76260/76260 - 21s - loss: 0.0335 - rmse: 0.1697 - R2: 0.8637 - val_loss: 0.0275 - val_rmse: 0.1538 - val_R2: 0.8878\n",
      "Epoch 10/100\n",
      "76260/76260 - 21s - loss: 0.0329 - rmse: 0.1678 - R2: 0.8665 - val_loss: 0.0264 - val_rmse: 0.1503 - val_R2: 0.8923\n",
      "Epoch 11/100\n",
      "76260/76260 - 21s - loss: 0.0322 - rmse: 0.1662 - R2: 0.8692 - val_loss: 0.0268 - val_rmse: 0.1516 - val_R2: 0.8901\n",
      "Epoch 12/100\n",
      "76260/76260 - 21s - loss: 0.0316 - rmse: 0.1645 - R2: 0.8716 - val_loss: 0.0261 - val_rmse: 0.1502 - val_R2: 0.8933\n",
      "Epoch 13/100\n",
      "76260/76260 - 21s - loss: 0.0311 - rmse: 0.1630 - R2: 0.8737 - val_loss: 0.0261 - val_rmse: 0.1499 - val_R2: 0.8936\n",
      "Epoch 14/100\n",
      "76260/76260 - 21s - loss: 0.0306 - rmse: 0.1616 - R2: 0.8758 - val_loss: 0.0256 - val_rmse: 0.1477 - val_R2: 0.8948\n",
      "Epoch 15/100\n",
      "76260/76260 - 21s - loss: 0.0304 - rmse: 0.1611 - R2: 0.8762 - val_loss: 0.0251 - val_rmse: 0.1469 - val_R2: 0.8974\n",
      "Epoch 16/100\n",
      "76260/76260 - 21s - loss: 0.0299 - rmse: 0.1596 - R2: 0.8789 - val_loss: 0.0246 - val_rmse: 0.1454 - val_R2: 0.8992\n",
      "Epoch 17/100\n",
      "76260/76260 - 21s - loss: 0.0294 - rmse: 0.1583 - R2: 0.8807 - val_loss: 0.0249 - val_rmse: 0.1457 - val_R2: 0.8986\n",
      "Epoch 18/100\n",
      "76260/76260 - 21s - loss: 0.0291 - rmse: 0.1576 - R2: 0.8818 - val_loss: 0.0248 - val_rmse: 0.1453 - val_R2: 0.8977\n",
      "Epoch 19/100\n",
      "76260/76260 - 21s - loss: 0.0288 - rmse: 0.1566 - R2: 0.8831 - val_loss: 0.0243 - val_rmse: 0.1439 - val_R2: 0.9005\n",
      "Epoch 20/100\n",
      "76260/76260 - 21s - loss: 0.0285 - rmse: 0.1557 - R2: 0.8844 - val_loss: 0.0250 - val_rmse: 0.1453 - val_R2: 0.8978\n",
      "Epoch 21/100\n",
      "76260/76260 - 21s - loss: 0.0281 - rmse: 0.1547 - R2: 0.8861 - val_loss: 0.0246 - val_rmse: 0.1443 - val_R2: 0.8997\n",
      "Epoch 22/100\n",
      "76260/76260 - 21s - loss: 0.0277 - rmse: 0.1537 - R2: 0.8875 - val_loss: 0.0245 - val_rmse: 0.1440 - val_R2: 0.9003\n",
      "Epoch 23/100\n",
      "76260/76260 - 21s - loss: 0.0274 - rmse: 0.1529 - R2: 0.8887 - val_loss: 0.0238 - val_rmse: 0.1421 - val_R2: 0.9025\n",
      "Epoch 24/100\n",
      "76260/76260 - 21s - loss: 0.0273 - rmse: 0.1526 - R2: 0.8893 - val_loss: 0.0234 - val_rmse: 0.1410 - val_R2: 0.9042\n",
      "Epoch 25/100\n",
      "76260/76260 - 21s - loss: 0.0270 - rmse: 0.1517 - R2: 0.8904 - val_loss: 0.0237 - val_rmse: 0.1411 - val_R2: 0.9031\n",
      "Epoch 26/100\n",
      "76260/76260 - 22s - loss: 0.0269 - rmse: 0.1512 - R2: 0.8910 - val_loss: 0.0233 - val_rmse: 0.1402 - val_R2: 0.9047\n",
      "Epoch 27/100\n",
      "76260/76260 - 21s - loss: 0.0265 - rmse: 0.1504 - R2: 0.8924 - val_loss: 0.0236 - val_rmse: 0.1409 - val_R2: 0.9035\n",
      "Epoch 28/100\n",
      "76260/76260 - 22s - loss: 0.0263 - rmse: 0.1499 - R2: 0.8932 - val_loss: 0.0245 - val_rmse: 0.1429 - val_R2: 0.8997\n",
      "Epoch 29/100\n",
      "76260/76260 - 21s - loss: 0.0263 - rmse: 0.1498 - R2: 0.8933 - val_loss: 0.0233 - val_rmse: 0.1399 - val_R2: 0.9048\n",
      "Epoch 30/100\n",
      "76260/76260 - 21s - loss: 0.0259 - rmse: 0.1487 - R2: 0.8951 - val_loss: 0.0237 - val_rmse: 0.1403 - val_R2: 0.9030\n",
      "Epoch 31/100\n",
      "76260/76260 - 21s - loss: 0.0257 - rmse: 0.1483 - R2: 0.8956 - val_loss: 0.0229 - val_rmse: 0.1388 - val_R2: 0.9067\n",
      "Epoch 32/100\n",
      "76260/76260 - 21s - loss: 0.0256 - rmse: 0.1478 - R2: 0.8963 - val_loss: 0.0235 - val_rmse: 0.1404 - val_R2: 0.9036\n",
      "Epoch 33/100\n",
      "76260/76260 - 21s - loss: 0.0255 - rmse: 0.1475 - R2: 0.8966 - val_loss: 0.0228 - val_rmse: 0.1382 - val_R2: 0.9063\n",
      "Epoch 34/100\n",
      "76260/76260 - 21s - loss: 0.0252 - rmse: 0.1467 - R2: 0.8980 - val_loss: 0.0227 - val_rmse: 0.1382 - val_R2: 0.9075\n",
      "Epoch 35/100\n",
      "76260/76260 - 21s - loss: 0.0251 - rmse: 0.1466 - R2: 0.8982 - val_loss: 0.0235 - val_rmse: 0.1394 - val_R2: 0.9041\n",
      "Epoch 36/100\n",
      "76260/76260 - 21s - loss: 0.0249 - rmse: 0.1462 - R2: 0.8988 - val_loss: 0.0224 - val_rmse: 0.1370 - val_R2: 0.9081\n",
      "Epoch 37/100\n",
      "76260/76260 - 21s - loss: 0.0248 - rmse: 0.1457 - R2: 0.8994 - val_loss: 0.0224 - val_rmse: 0.1378 - val_R2: 0.9085\n",
      "Epoch 38/100\n",
      "76260/76260 - 21s - loss: 0.0248 - rmse: 0.1456 - R2: 0.8996 - val_loss: 0.0228 - val_rmse: 0.1376 - val_R2: 0.9067\n",
      "Epoch 39/100\n",
      "76260/76260 - 21s - loss: 0.0245 - rmse: 0.1449 - R2: 0.9006 - val_loss: 0.0223 - val_rmse: 0.1361 - val_R2: 0.9089\n",
      "Epoch 40/100\n",
      "76260/76260 - 21s - loss: 0.0243 - rmse: 0.1442 - R2: 0.9017 - val_loss: 0.0223 - val_rmse: 0.1369 - val_R2: 0.9088\n",
      "Epoch 41/100\n",
      "76260/76260 - 21s - loss: 0.0243 - rmse: 0.1443 - R2: 0.9016 - val_loss: 0.0231 - val_rmse: 0.1387 - val_R2: 0.9054\n",
      "Epoch 42/100\n",
      "76260/76260 - 21s - loss: 0.0240 - rmse: 0.1437 - R2: 0.9027 - val_loss: 0.0230 - val_rmse: 0.1383 - val_R2: 0.9059\n",
      "Epoch 43/100\n",
      "76260/76260 - 21s - loss: 0.0238 - rmse: 0.1430 - R2: 0.9037 - val_loss: 0.0223 - val_rmse: 0.1364 - val_R2: 0.9083\n",
      "Epoch 44/100\n",
      "76260/76260 - 21s - loss: 0.0238 - rmse: 0.1429 - R2: 0.9037 - val_loss: 0.0225 - val_rmse: 0.1365 - val_R2: 0.9081\n",
      "Epoch 45/100\n",
      "76260/76260 - 21s - loss: 0.0237 - rmse: 0.1427 - R2: 0.9041 - val_loss: 0.0230 - val_rmse: 0.1374 - val_R2: 0.9057\n",
      "Epoch 46/100\n",
      "76260/76260 - 21s - loss: 0.0233 - rmse: 0.1417 - R2: 0.9056 - val_loss: 0.0229 - val_rmse: 0.1368 - val_R2: 0.9063\n",
      "Epoch 47/100\n",
      "76260/76260 - 21s - loss: 0.0234 - rmse: 0.1420 - R2: 0.9050 - val_loss: 0.0222 - val_rmse: 0.1353 - val_R2: 0.9091\n",
      "Epoch 48/100\n",
      "76260/76260 - 21s - loss: 0.0231 - rmse: 0.1413 - R2: 0.9064 - val_loss: 0.0228 - val_rmse: 0.1371 - val_R2: 0.9071\n",
      "Epoch 49/100\n",
      "76260/76260 - 21s - loss: 0.0233 - rmse: 0.1414 - R2: 0.9058 - val_loss: 0.0220 - val_rmse: 0.1350 - val_R2: 0.9096\n",
      "Epoch 50/100\n",
      "76260/76260 - 21s - loss: 0.0232 - rmse: 0.1414 - R2: 0.9060 - val_loss: 0.0221 - val_rmse: 0.1353 - val_R2: 0.9095\n",
      "Epoch 51/100\n",
      "76260/76260 - 21s - loss: 0.0232 - rmse: 0.1412 - R2: 0.9062 - val_loss: 0.0232 - val_rmse: 0.1376 - val_R2: 0.9040\n",
      "Epoch 52/100\n",
      "76260/76260 - 21s - loss: 0.0227 - rmse: 0.1403 - R2: 0.9080 - val_loss: 0.0226 - val_rmse: 0.1363 - val_R2: 0.9076\n",
      "Epoch 53/100\n",
      "76260/76260 - 21s - loss: 0.0226 - rmse: 0.1399 - R2: 0.9083 - val_loss: 0.0225 - val_rmse: 0.1360 - val_R2: 0.9077\n",
      "Epoch 54/100\n",
      "76260/76260 - 21s - loss: 0.0225 - rmse: 0.1396 - R2: 0.9088 - val_loss: 0.0231 - val_rmse: 0.1371 - val_R2: 0.9046\n",
      "Epoch 55/100\n",
      "76260/76260 - 21s - loss: 0.0228 - rmse: 0.1401 - R2: 0.9078 - val_loss: 0.0230 - val_rmse: 0.1371 - val_R2: 0.9059\n",
      "Epoch 56/100\n",
      "76260/76260 - 21s - loss: 0.0226 - rmse: 0.1398 - R2: 0.9086 - val_loss: 0.0227 - val_rmse: 0.1358 - val_R2: 0.9075\n",
      "Epoch 57/100\n",
      "76260/76260 - 21s - loss: 0.0223 - rmse: 0.1391 - R2: 0.9097 - val_loss: 0.0223 - val_rmse: 0.1356 - val_R2: 0.9087\n",
      "Epoch 58/100\n",
      "76260/76260 - 21s - loss: 0.0224 - rmse: 0.1392 - R2: 0.9094 - val_loss: 0.0229 - val_rmse: 0.1361 - val_R2: 0.9056\n",
      "Epoch 59/100\n",
      "76260/76260 - 21s - loss: 0.0221 - rmse: 0.1384 - R2: 0.9108 - val_loss: 0.0224 - val_rmse: 0.1349 - val_R2: 0.9083\n",
      "Epoch 00059: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = emb_model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.save('model_with_embedded.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = tf.keras.models.load_model('model_with_embedded.hdf5', custom_objects={'rmse': rmse, 'R2':R2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022715538753722, 0.1358718, 0.900469]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = emb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check error by each data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = compute_rmse(y_test,y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15131707 0.12680595 0.12171652 0.13883751 0.14916609 0.18558254\n",
      " 0.20481043 0.09804399 0.11042881 0.14687408 0.15451697 0.1364162\n",
      " 0.13520527 0.18700868 0.14672336 0.14532703 0.15154928]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rank by highest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df = pd.DataFrame({'phonetic':z_test, 'err':errs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U</td>\n",
       "      <td>0.111194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>0.292217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>0.138014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>0.111953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "      <td>0.109335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  phonetic       err\n",
       "0        U  0.111194\n",
       "1        O  0.292217\n",
       "2        O  0.138014\n",
       "3        U  0.111953\n",
       "4        i  0.109335"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>a</td>\n",
       "      <td>0.027051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>E</td>\n",
       "      <td>0.030484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>a</td>\n",
       "      <td>0.032255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>a</td>\n",
       "      <td>0.032279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A</td>\n",
       "      <td>0.033125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>e</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553</th>\n",
       "      <td>u</td>\n",
       "      <td>0.651560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>O</td>\n",
       "      <td>0.681745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5656</th>\n",
       "      <td>u</td>\n",
       "      <td>0.691570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>e</td>\n",
       "      <td>0.815813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9338 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     phonetic       err\n",
       "1870        a  0.027051\n",
       "8732        E  0.030484\n",
       "363         a  0.032255\n",
       "3205        a  0.032279\n",
       "48          A  0.033125\n",
       "...       ...       ...\n",
       "5226        e  0.646154\n",
       "6553        u  0.651560\n",
       "7443        O  0.681745\n",
       "5656        u  0.691570\n",
       "2784        e  0.815813\n",
       "\n",
       "[9338 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df.sort_values('err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000020BB7388F28>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_df.hist('err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df_high = err_df[err_df['err'] > 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>0.292217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y</td>\n",
       "      <td>0.304253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i</td>\n",
       "      <td>0.196064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>0.245593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>0.161447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phonetic       err\n",
       "1         O  0.292217\n",
       "5         y  0.304253\n",
       "6         i  0.196064\n",
       "8         i  0.245593\n",
       "14        A  0.161447"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df_high.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20bb86b8c50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEGCAYAAAB8Ys7jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAO+UlEQVR4nO3dfYxldX3H8ffHXZUHQaUM1oLjoKVQq6A41SK2NaIpilHbYgoRpbVmmzYifYpZbSNgoiGtMdqkNd2qlEaiTRAfKilCoIbSKrq7PLNYfFgVFYHaFEREoN/+cc+G8TI7Mzv3zJn7W96v5Obec+6Z+/vszuxnzp577u+kqpAktecx6x1AkrQ6FrgkNcoCl6RGWeCS1CgLXJIatXHIwQ4++OCam5sbckhJat62bdvuqqqZ8fWDFvjc3Bxbt24dckhJal6Sby623kMoktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUqEE/ibmcuc0XT/waO889qYckkjT93AOXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY1atsCTfCTJHUluXLDuoCSXJbm1u3/y2saUJI1byR74PwInjq3bDFxeVUcAl3fLkqQBLVvgVXUl8IOx1a8Bzu8enw+8tudckqRlrPYY+FOq6nsA3f0h/UWSJK3Eml9SLckmYBPA7OzsWg/Xi0kv7eZl3SQNYbV74N9P8lSA7v6O3W1YVVuqar6q5mdmZlY5nCRp3GoL/DPA6d3j04FP9xNHkrRSKzmN8GPAF4Ajk9yW5PeBc4GXJ7kVeHm3LEka0LLHwKvq1N08dULPWSRJe8BPYkpSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNWqiAk/yJ0luSnJjko8l2aevYJKkpa26wJMcCrwVmK+qZwMbgFP6CiZJWtqkh1A2Avsm2QjsB3x38kiSpJXYuNovrKrvJHkv8C3gPuDSqrp0fLskm4BNALOzs6sd7lFnbvPFE7/GznNP6iGJpGk1ySGUJwOvAQ4Hfg7YP8lp49tV1Zaqmq+q+ZmZmdUnlST9lEkOobwM+EZV3VlVDwAXAS/qJ5YkaTmTFPi3gF9Jsl+SACcAO/qJJUlazqoLvKquBi4EtgM3dK+1padckqRlrPpNTICqOgs4q6cskqQ94CcxJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaNVGBJ3lSkguT3JJkR5Lj+gomSVraxgm//gPAJVV1cpLHAfv1kEmStAKrLvAkBwK/BvwuQFX9BPhJP7EkScuZ5BDKM4A7gfOSXJPkQ0n2H98oyaYkW5NsvfPOOycYTpK00CQFvhE4FvhgVT0PuBfYPL5RVW2pqvmqmp+ZmZlgOEnSQpMU+G3AbVV1dbd8IaNClyQNYNUFXlW3A99OcmS36gTg5l5SSZKWNelZKGcAF3RnoHwd+L3JI0mSVmKiAq+qa4H5nrJIkvaAn8SUpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElq1KTTyWovN7f54om+fue5J/WURNI498AlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMmLvAkG5Jck+SzfQSSJK1MH3vgZwI7engdSdIemKjAkxwGnAR8qJ84kqSVmvSKPO8H3gYcsLsNkmwCNgHMzs5OOJwejSa9KhB4ZSDtnVa9B57kVcAdVbVtqe2qaktVzVfV/MzMzGqHkySNmeQQyvHAq5PsBD4OvDTJR3tJJUla1qoLvKreXlWHVdUccApwRVWd1lsySdKSPA9ckho16ZuYAFTV54HP9/FakqSVcQ9ckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpUb3MRig9Gkx6aTcv66a+uQcuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSo1Zd4EmeluTfkuxIclOSM/sMJkla2iQXdHgQ+LOq2p7kAGBbksuq6uaeskmSlrDqPfCq+l5Vbe8e3wPsAA7tK5gkaWm9XFItyRzwPODqRZ7bBGwCmJ2d7WM46VFr0su6gZd225tM/CZmkicAnwD+uKruHn++qrZU1XxVzc/MzEw6nCSpM1GBJ3kso/K+oKou6ieSJGklJjkLJcCHgR1V9b7+IkmSVmKSPfDjgTcAL01ybXd7ZU+5JEnLWPWbmFV1FZAes0iS9oCfxJSkRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWpUL5dUk/ToMuml3fq4rNu0XF5uPf8u3AOXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURMVeJITk3wlyVeTbO4rlCRpeasu8CQbgL8FXgE8Czg1ybP6CiZJWtoke+AvAL5aVV+vqp8AHwde008sSdJyUlWr+8LkZODEqnpzt/wG4IVV9Zax7TYBm7rFI4GvrD4uAAcDd034GpOahgwwHTnM8LBpyDENGWA6ckxDBugnx9OramZ85STXxMwi6x7x26CqtgBbJhjnpwdNtlbVfF+v12qGaclhhunKMQ0ZpiXHNGRY6xyTHEK5DXjaguXDgO9OFkeStFKTFPiXgSOSHJ7kccApwGf6iSVJWs6qD6FU1YNJ3gJ8DtgAfKSqbuot2e71djhmAtOQAaYjhxkeNg05piEDTEeOacgAa5hj1W9iSpLWl5/ElKRGWeCS1KhJTiMcRJJ9gJ9ndIri16rqx+scSZKmwtQeA0+yEXgP8Cbgm4z+t3AYcB7wF1X1wMB53rnY+qp618A5jgF+tVv896q6bsjx11uSPx1bVYw+JHFVVX1j4CwBXg88o6relWQW+Nmq+tKQOaZJkicDRwD77FpXVVcOnOEg4HDgjqr69pBjd+MfBRwKXF1VP1yw/sSquqTPsab5EMpfAwcBh1fV86vqecAzgScB712HPPcuuD3EaA6YuSEDJDkTuAA4pLt9NMkZQ2aYAgeM3Q4E5oF/TXLKwFn+DjgOOLVbvofR/ECDSPK2BY9fN/bce4bKsWDMNwNXMjoz7Zzu/uwBxz88yScZnfXxOuCcJP+S5BGfYFzDDG8FPg2cAdyYZOH0Iv1/T6pqKm/ArXT/QxhbvwG4dQryPR743MBjXg/sv2B5f+D6Ace/qru/B7h7we0e4O51/n4cBGwfeMzt3f01C9ZdN/T4448XWx4ozw2M9ryv7ZaPAv55oLEPA74E/MLY+mcz+l/7K4GZgf4OntA9ngO2AmeO/5z0dZvmPfCq7k89tvIhFvnI/jrYD3jGwGOG0d7/Lg+x+JQGa6KqXtzdH1BVBy64HVBVBw6VYzfZfsCAfxedB7pZOQug29P7vwHHz24eL7Y8hB9X9x5VksdX1S2M5j8awjuBzVX1X0kuTPK/Sb4AXMVop+/2bpu1tqG6wyZVtRN4CfCKJO9jDb4n01zgNyd54/jKJKcBtwwdJskNSa7vbjcxmpTrAwPHOA+4OsnZSc4Gvgh8eOAMUynJS4H/GXjYvwE+CRyS5N2MymLIQxe1m8eLLQ/htiRPAj4FXJbk0ww3vcaxVXVF97iA51TVccDRwD5VtZ3Roba1dnuS5+5a6Mr8VYwmtHpO34NN85uYhwIXAfcB2xh9U34Z2Bf4zar6zsB5nr5g8UHg+1X14JAZuhzHAi9m9Nv8yqq6ZugM6ynJDTyynA5iVBRv7Pb6hsxzFHACo+/H5VW1Y8CxH2L0nkwY/bv40a6nGJXWY4fKski2XweeCFxSo+mm13q864Dn1+gT4tuAl1TVPUkOBK6oqvkk26vq2DXOcRjwYFXdvshzx1fVf/Q63rQW+C7dntUvMfqhvKmqLl/nSFpHY79IYVTm/11V965HHk2HJO9ndFbWJ5K8itHhkq8xOsz5bka/6E6uqj9cx5i9m/oCl6TlJDkEuAR4Q1XdlOQxPDwP9zHAPwCvrqq9asZUC1zSXiHJMxmd2nkHo/eHHgJeBDwd+IOhD68NwQKXtFdJcgSjve4AN+yNxb2LBS5JjZrm0wglSUuwwCWpURa49hpJdiY5eI3HeMfY8n+u5XjSUjwGrr1Gkp3AfFXdtYZj/LCqnrBWry/tCffA1Zwkc0luSXJ+N7XBhUn2654+I8n2buqDo7rtD0ryqW7bLyY5ult/dpKPJPl8kq93M8ntGuO0JF9Kcm2Sv0+yIcm5wL7dugu67RZOF/q2btzrum2lNWWBq1VHAluq6mhGMyL+Ubf+ru7j0h8E/rxbdw6jmeCOBt4B/NOC1zkK+A3gBcBZSR6b5BeB3wGOr6rnMjqf+PVVtRm4r6qeW1WvXxgmySuA1wIvrKpjgL/q/48s/bSpvyKPtBvfXjCvxEeBXXvPF3X324Df6h6/GPhtgKq6IsnPJHli99zFVXU/cH+SO4CnMJrb5PnAl0fXbGBfRh8OWcrLgPOq6kfdOD+Y5A8nrYQFrlbtbva9+7v7h3j453uxaTzHt1/4NQHOr6q370GeLJJJWlMeQlGrZpMc1z0+ldFUrrtzJaNLn5HkJYwOs9y9xPaXAyd382vsOoa+axKtB5IsNsvfpcCbdh2L7y7rJa0pC1yt2gGcnuR6RtPJfnCJbc8G5rttzwVOX+qFq+pm4C+BS7uvuQx4avf0FuD6XW9iLviaS4DPAFuTXMvDx9+lNeNphGpOkjngs1X17HWOIq0r98AlqVHugUtSo9wDl6RGWeCS1CgLXJIaZYFLUqMscElq1P8DekZq6cY0RikAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_df[err_df['err'] > 0.5].groupby('phonetic')['phonetic'].count().sort_values(ascending=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phonetic\n",
       "2     106\n",
       "9     189\n",
       "@     119\n",
       "A      98\n",
       "E     250\n",
       "E:    201\n",
       "O     192\n",
       "U     107\n",
       "a     191\n",
       "e     216\n",
       "i     256\n",
       "o     207\n",
       "u     231\n",
       "y     126\n",
       "Name: phonetic, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df_high.groupby('phonetic')['phonetic'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate each param of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = compute_se(y_test,y_pred)\n",
    "errs = compute_rmse(y_test,y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se = pd.DataFrame(se, columns=[\"HX\",\"HY\",\"JA\",\"LP\",\"LD\",\"VS\",\"VO\",\"TCX\",\"TCY\",\"TTX\",\"TTY\",\"TBX\",\"TBY\",\"TS1\",\"TS2\",\"TS3\",\"TS4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se['phonetic'] = z_test\n",
    "df_se['mean_err'] = errs\n",
    "df_se['audio'] = a_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HX</th>\n",
       "      <th>HY</th>\n",
       "      <th>JA</th>\n",
       "      <th>LP</th>\n",
       "      <th>LD</th>\n",
       "      <th>VS</th>\n",
       "      <th>VO</th>\n",
       "      <th>TCX</th>\n",
       "      <th>TCY</th>\n",
       "      <th>TTX</th>\n",
       "      <th>TTY</th>\n",
       "      <th>TBX</th>\n",
       "      <th>TBY</th>\n",
       "      <th>TS1</th>\n",
       "      <th>TS2</th>\n",
       "      <th>TS3</th>\n",
       "      <th>TS4</th>\n",
       "      <th>phonetic</th>\n",
       "      <th>mean_err</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117773</td>\n",
       "      <td>0.077305</td>\n",
       "      <td>0.066924</td>\n",
       "      <td>0.086757</td>\n",
       "      <td>0.119798</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.333487</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.049593</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.160527</td>\n",
       "      <td>0.052398</td>\n",
       "      <td>0.074304</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.032247</td>\n",
       "      <td>0.026956</td>\n",
       "      <td>U</td>\n",
       "      <td>0.111194</td>\n",
       "      <td>[-0.0036667322, -0.0067870035, -0.009936802, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.402004</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>0.195948</td>\n",
       "      <td>0.134879</td>\n",
       "      <td>0.374650</td>\n",
       "      <td>0.221204</td>\n",
       "      <td>0.456783</td>\n",
       "      <td>0.036066</td>\n",
       "      <td>0.139318</td>\n",
       "      <td>0.229163</td>\n",
       "      <td>0.030990</td>\n",
       "      <td>0.204872</td>\n",
       "      <td>0.228125</td>\n",
       "      <td>0.395959</td>\n",
       "      <td>0.347401</td>\n",
       "      <td>0.518145</td>\n",
       "      <td>0.121751</td>\n",
       "      <td>O</td>\n",
       "      <td>0.292217</td>\n",
       "      <td>[-0.0077388003, -0.011906635, -0.15257795, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049907</td>\n",
       "      <td>0.178747</td>\n",
       "      <td>0.050386</td>\n",
       "      <td>0.109552</td>\n",
       "      <td>0.119077</td>\n",
       "      <td>0.232686</td>\n",
       "      <td>0.286637</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.073880</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.056864</td>\n",
       "      <td>0.131981</td>\n",
       "      <td>0.275934</td>\n",
       "      <td>0.048149</td>\n",
       "      <td>0.049092</td>\n",
       "      <td>0.120624</td>\n",
       "      <td>O</td>\n",
       "      <td>0.138014</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135809</td>\n",
       "      <td>0.066334</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.035465</td>\n",
       "      <td>0.053018</td>\n",
       "      <td>0.040019</td>\n",
       "      <td>0.298855</td>\n",
       "      <td>0.044735</td>\n",
       "      <td>0.163779</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>0.108015</td>\n",
       "      <td>0.050581</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>0.198981</td>\n",
       "      <td>0.035514</td>\n",
       "      <td>0.104978</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>U</td>\n",
       "      <td>0.111953</td>\n",
       "      <td>[0.026149532, 0.034463353, 0.037094187, 0.0368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.047954</td>\n",
       "      <td>0.148823</td>\n",
       "      <td>0.155678</td>\n",
       "      <td>0.139910</td>\n",
       "      <td>0.070116</td>\n",
       "      <td>0.122367</td>\n",
       "      <td>0.042102</td>\n",
       "      <td>0.038261</td>\n",
       "      <td>0.044839</td>\n",
       "      <td>0.189018</td>\n",
       "      <td>0.070025</td>\n",
       "      <td>0.033955</td>\n",
       "      <td>0.115402</td>\n",
       "      <td>0.054007</td>\n",
       "      <td>0.144176</td>\n",
       "      <td>0.174937</td>\n",
       "      <td>i</td>\n",
       "      <td>0.109335</td>\n",
       "      <td>[-0.021888198, -0.033991054, -0.042626306, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HX        HY        JA        LP        LD        VS        VO  \\\n",
       "0  0.117773  0.077305  0.066924  0.086757  0.119798  0.005893  0.333487   \n",
       "1  0.402004  0.326394  0.195948  0.134879  0.374650  0.221204  0.456783   \n",
       "2  0.049907  0.178747  0.050386  0.109552  0.119077  0.232686  0.286637   \n",
       "3  0.135809  0.066334  0.009185  0.035465  0.053018  0.040019  0.298855   \n",
       "4  0.020397  0.047954  0.148823  0.155678  0.139910  0.070116  0.122367   \n",
       "\n",
       "        TCX       TCY       TTX       TTY       TBX       TBY       TS1  \\\n",
       "0  0.004245  0.049593  0.043796  0.160527  0.052398  0.074304  0.111977   \n",
       "1  0.036066  0.139318  0.229163  0.030990  0.204872  0.228125  0.395959   \n",
       "2  0.004917  0.073880  0.052863  0.000451  0.056864  0.131981  0.275934   \n",
       "3  0.044735  0.163779  0.009319  0.108015  0.050581  0.008441  0.198981   \n",
       "4  0.042102  0.038261  0.044839  0.189018  0.070025  0.033955  0.115402   \n",
       "\n",
       "        TS2       TS3       TS4 phonetic  mean_err  \\\n",
       "0  0.001008  0.032247  0.026956        U  0.111194   \n",
       "1  0.347401  0.518145  0.121751        O  0.292217   \n",
       "2  0.048149  0.049092  0.120624        O  0.138014   \n",
       "3  0.035514  0.104978  0.008624        U  0.111953   \n",
       "4  0.054007  0.144176  0.174937        i  0.109335   \n",
       "\n",
       "                                               audio  \n",
       "0  [-0.0036667322, -0.0067870035, -0.009936802, -...  \n",
       "1  [-0.0077388003, -0.011906635, -0.15257795, -0....  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.026149532, 0.034463353, 0.037094187, 0.0368...  \n",
       "4  [-0.021888198, -0.033991054, -0.042626306, -0....  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-38ad2d03395b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'phonetic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'7'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_err'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TS4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(self, by, bins, **kwargs)\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \"\"\"\n\u001b[1;32m-> 1125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"hist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ax\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left_ax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;31m# no non-numeric frames or series allowed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no numeric data to plot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;31m# GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "df_se[(df_se['phonetic'] == '7') & (df_se['mean_err'] > 0.5)]['TS4'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA audio of testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort = df_se.sort_values('mean_err',ascending=False)\n",
    "df_se_sort.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort[df_se_sort['phonetic'] == '&'].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(df_se_sort['audio'][0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort[df_se_sort['phonetic'] == '&'].tail(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(df_se_sort['audio'][12073], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
