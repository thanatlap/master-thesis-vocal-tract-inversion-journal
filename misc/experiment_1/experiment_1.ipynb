{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on AAI Model Architectures\n",
    "- Created: 10 Mar 2020\n",
    "- Data: param_draft2 20k\n",
    "- Model 4 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil \n",
    "import argparse\n",
    "from functools import partial\n",
    "import pickle\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Reshape, GRU, InputLayer, AlphaDropout, Activation, BatchNormalization, Dropout, Flatten, Dense, Bidirectional, LSTM, Conv1D, SpatialDropout1D, Concatenate, Multiply, Add\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = partial(np.load)\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred), axis = 0) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true, axis = 0)), axis = 0) \n",
    "    return K.mean(1 - (SS_res/SS_tot), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preprocessing data\n",
    "def delete_params(params):\n",
    "    '''\n",
    "    This function remove JX, WC, TRX, TRY, and MS1,2,3 paramter\n",
    "    '''\n",
    "    DEL_PARAMS_LIST = [2,8,15,16,21,22,23]\n",
    "    return np.delete(params,DEL_PARAMS_LIST , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(actual,pred, axis=1):\n",
    "    # Compute RMSE by row (axis=1) result in rmse of each data\n",
    "    # Compute RMSE by column (axis=0) result in rmse of each label\n",
    "    return np.sqrt((np.square(actual - pred)).mean(axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, label):\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    label = enc.inverse_transform(label)\n",
    "#     print('Confusion Matrix')\n",
    "#     print(confusion_matrix(label, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_se(actual,pred):\n",
    "    return np.sqrt((np.square(actual - pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "\n",
    "    # load data from preprocess pipeline\n",
    "    dataset = np.load(join('../../data/d_dataset_p2/prep_data_13','training_subsets.npz'))\n",
    "    X_train =dataset['X_train']\n",
    "    y_train= dataset['y_train']\n",
    "    z_train= dataset['z_train']\n",
    "    X_val = dataset['X_val']\n",
    "    y_val = dataset['y_val']\n",
    "    z_val = dataset['z_val']\n",
    "    X_test = dataset['X_test']\n",
    "    y_test = dataset['y_test']\n",
    "    z_test = dataset['z_test']\n",
    "    a_test = dataset['audio_test']\n",
    "    a_val = dataset['audio_val']\n",
    "    \n",
    "    y_train = delete_params(y_train)\n",
    "    y_val = delete_params(y_val)\n",
    "    y_test = delete_params(y_test)\n",
    "\n",
    "    print('Train features and labels %s %s'%(str(X_train.shape),str(y_train.shape)))\n",
    "    print('Validating features and labels %s %s'%(str(X_val.shape),str(y_val.shape)))\n",
    "    print('Test features and labels %s %s'%(str(X_test.shape),str(y_test.shape)))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test, a_test, a_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (76260, 24, 39) (76260, 17)\n",
      "Validating features and labels (9340, 24, 39) (9340, 17)\n",
      "Test features and labels (9338, 24, 39) (9338, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test, a_test, a_val = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e', 'u', 'i', 'O', 'E:', 'E', '9', 'A', 'a', '2', 'y', 'o', 'U', '@'}\n"
     ]
    }
   ],
   "source": [
    "print(set(z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (76260, 24, 39) (76260, 17) (76260,)\n",
      "Validating features and labels (9340, 24, 39) (9340, 17) (9340,)\n",
      "Test features and labels (9338, 24, 39) (9338, 17) (9338,)\n"
     ]
    }
   ],
   "source": [
    "print('Train features and labels {} {} {}'.format(str(X_train.shape),str(y_train.shape),str(z_train.shape)))\n",
    "print('Validating features and labels {} {} {}'.format(str(X_val.shape),str(y_val.shape),str(z_val.shape)))\n",
    "print('Test features and labels {} {} {}'.format(str(X_test.shape),str(y_test.shape),str(z_test.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_oe=z_train.reshape(-1,1)\n",
    "z_val_oe=z_val.reshape(-1,1)\n",
    "z_test_oe=z_test.reshape(-1,1)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(z_train_oe)\n",
    "\n",
    "z_train_oe = enc.transform(z_train_oe).toarray()\n",
    "z_test_oe = enc.transform(z_test_oe).toarray()\n",
    "z_val_oe = enc.transform(z_val_oe).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Train Baseline Model\n",
    "- Model without embedding feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Model without Embedded Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "pConv1D = partial(Conv1D, padding = 'same', activation = 'linear', kernel_initializer = 'he_uniform')\n",
    "\n",
    "def init_senet(feature_layer=1, cnn_unit=64, first_kernel=11, res_unit=128, res_kernel=7,\n",
    "    bilstm = 1, bilstm_unit=256, \n",
    "    dropout_rate=0.3,\n",
    "    reduction_ratio = 2,\n",
    "    activation_fn='relu'):\n",
    "\n",
    "\n",
    "    def cnn_block(input_x, cnn_unit, kernel_size):\n",
    "        x = pConv1D(cnn_unit, kernel_size=kernel_size)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        return x\n",
    "\n",
    "    def se_block(input_x):\n",
    "        x = layers.GlobalAveragePooling1D()(input_x)\n",
    "        channel_shape = getattr(x, '_shape_val')[-1]\n",
    "        x = Reshape((1, channel_shape))(x)\n",
    "        x = Dense(channel_shape // reduction_ratio, activation=activation_fn, kernel_initializer='he_uniform')(x)\n",
    "        x = Dense(channel_shape, activation='tanh', kernel_initializer='he_uniform')(x)\n",
    "        return x\n",
    "\n",
    "    def residual_block(input_x):\n",
    "        x = cnn_block(input_x, res_unit,kernel_size=res_kernel)\n",
    "        x = pConv1D(res_unit, kernel_size=3)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    def se_res_block(input_x):\n",
    "        res_x = residual_block(input_x)\n",
    "        se_x = se_block(res_x)\n",
    "        x = layers.Multiply()([res_x, se_x])\n",
    "        x = Activation(activation_fn)(x)\n",
    "        # input_x = cnn_block(input_x, cnn_unit=cnn_unit, kernel_size=1)\n",
    "        outputs = layers.Add()([x, input_x])\n",
    "        return outputs\n",
    "\n",
    "    def senet_nn(input_shape_1,input_shape_2):\n",
    "\n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        x = cnn_block(input_x, 128, first_kernel)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = cnn_block(x, cnn_unit=cnn_unit, kernel_size=1)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(bilstm-1):\n",
    "            x = Bidirectional(pLSTM(bilstm_unit))(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = Bidirectional(pLSTM(bilstm_unit, return_sequences=False))(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "        outputs = Dense(N_OUTPUTS, activation='linear', kernel_initializer='he_uniform')(x)\n",
    "        model = keras.Model(inputs=input_x, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    return senet_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_senet()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 24, 128)      55040       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 24, 128)      512         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 24, 128)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 24, 128)      114816      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24, 128)      512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 24, 128)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 24, 128)      49280       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 128)      512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 128)       0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 64)        8256        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 128)       8320        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 24, 128)      0           batch_normalization_2[0][0]      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 128)      0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 24, 128)      0           activation_2[0][0]               \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 24, 128)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 24, 128)      114816      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 128)      512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 128)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 24, 128)      49280       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24, 128)      512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 64)        8256        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 128)       8320        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 24, 128)      0           batch_normalization_4[0][0]      \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 128)      0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24, 128)      0           activation_4[0][0]               \n",
      "                                                                 spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 24, 128)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 24, 64)       8256        spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 24, 64)       256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 24, 64)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 24, 64)       0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 512)          657408      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 17)           8721        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,093,585\n",
      "Trainable params: 1,092,177\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/50\n",
      "76260/76260 [==============================] - 29s 378us/sample - loss: 0.1043 - rmse: 0.2991 - R2: 0.5770 - val_loss: 0.0428 - val_rmse: 0.1895 - val_R2: 0.8285\n",
      "Epoch 2/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0590 - rmse: 0.2234 - R2: 0.7614 - val_loss: 0.0348 - val_rmse: 0.1711 - val_R2: 0.8595\n",
      "Epoch 3/50\n",
      "76260/76260 [==============================] - 16s 215us/sample - loss: 0.0513 - rmse: 0.2069 - R2: 0.7928 - val_loss: 0.0344 - val_rmse: 0.1691 - val_R2: 0.8598\n",
      "Epoch 4/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0476 - rmse: 0.1987 - R2: 0.8075 - val_loss: 0.0328 - val_rmse: 0.1652 - val_R2: 0.8664\n",
      "Epoch 5/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0450 - rmse: 0.1933 - R2: 0.8181 - val_loss: 0.0320 - val_rmse: 0.1631 - val_R2: 0.8697\n",
      "Epoch 6/50\n",
      "76260/76260 [==============================] - 16s 213us/sample - loss: 0.0433 - rmse: 0.1896 - R2: 0.8246 - val_loss: 0.0314 - val_rmse: 0.1598 - val_R2: 0.8727\n",
      "Epoch 7/50\n",
      "76260/76260 [==============================] - 17s 217us/sample - loss: 0.0416 - rmse: 0.1857 - R2: 0.8316 - val_loss: 0.0286 - val_rmse: 0.1558 - val_R2: 0.8838\n",
      "Epoch 8/50\n",
      "76260/76260 [==============================] - 17s 217us/sample - loss: 0.0403 - rmse: 0.1828 - R2: 0.8368 - val_loss: 0.0276 - val_rmse: 0.1523 - val_R2: 0.8881\n",
      "Epoch 9/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0394 - rmse: 0.1807 - R2: 0.8402 - val_loss: 0.0291 - val_rmse: 0.1562 - val_R2: 0.8815\n",
      "Epoch 10/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0388 - rmse: 0.1790 - R2: 0.8429 - val_loss: 0.0266 - val_rmse: 0.1495 - val_R2: 0.8920\n",
      "Epoch 11/50\n",
      "76260/76260 [==============================] - 16s 215us/sample - loss: 0.0375 - rmse: 0.1765 - R2: 0.8483 - val_loss: 0.0269 - val_rmse: 0.1500 - val_R2: 0.8902\n",
      "Epoch 12/50\n",
      "76260/76260 [==============================] - 16s 215us/sample - loss: 0.0369 - rmse: 0.1750 - R2: 0.8505 - val_loss: 0.0284 - val_rmse: 0.1533 - val_R2: 0.8850\n",
      "Epoch 13/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0364 - rmse: 0.1736 - R2: 0.8528 - val_loss: 0.0262 - val_rmse: 0.1497 - val_R2: 0.8936\n",
      "Epoch 14/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0354 - rmse: 0.1714 - R2: 0.8567 - val_loss: 0.0253 - val_rmse: 0.1462 - val_R2: 0.8968\n",
      "Epoch 15/50\n",
      "76260/76260 [==============================] - 16s 213us/sample - loss: 0.0349 - rmse: 0.1704 - R2: 0.8585 - val_loss: 0.0261 - val_rmse: 0.1483 - val_R2: 0.8928\n",
      "Epoch 16/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0345 - rmse: 0.1693 - R2: 0.8604 - val_loss: 0.0249 - val_rmse: 0.1451 - val_R2: 0.8991\n",
      "Epoch 17/50\n",
      "76260/76260 [==============================] - 16s 213us/sample - loss: 0.0340 - rmse: 0.1682 - R2: 0.8623 - val_loss: 0.0255 - val_rmse: 0.1464 - val_R2: 0.8959\n",
      "Epoch 18/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0336 - rmse: 0.1671 - R2: 0.8641 - val_loss: 0.0254 - val_rmse: 0.1459 - val_R2: 0.8967\n",
      "Epoch 19/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0329 - rmse: 0.1655 - R2: 0.8669 - val_loss: 0.0255 - val_rmse: 0.1464 - val_R2: 0.8966\n",
      "Epoch 20/50\n",
      "76260/76260 [==============================] - 16s 215us/sample - loss: 0.0325 - rmse: 0.1645 - R2: 0.8684 - val_loss: 0.0262 - val_rmse: 0.1465 - val_R2: 0.8939\n",
      "Epoch 21/50\n",
      "76260/76260 [==============================] - 16s 215us/sample - loss: 0.0326 - rmse: 0.1648 - R2: 0.8681 - val_loss: 0.0247 - val_rmse: 0.1428 - val_R2: 0.8997\n",
      "Epoch 22/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0318 - rmse: 0.1630 - R2: 0.8710 - val_loss: 0.0246 - val_rmse: 0.1432 - val_R2: 0.9002\n",
      "Epoch 23/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0315 - rmse: 0.1622 - R2: 0.8725 - val_loss: 0.0242 - val_rmse: 0.1429 - val_R2: 0.9015\n",
      "Epoch 24/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0313 - rmse: 0.1616 - R2: 0.8735 - val_loss: 0.0234 - val_rmse: 0.1409 - val_R2: 0.9048\n",
      "Epoch 25/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0308 - rmse: 0.1605 - R2: 0.8753 - val_loss: 0.0251 - val_rmse: 0.1445 - val_R2: 0.8981\n",
      "Epoch 26/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0305 - rmse: 0.1599 - R2: 0.8765 - val_loss: 0.0244 - val_rmse: 0.1424 - val_R2: 0.9006\n",
      "Epoch 27/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0304 - rmse: 0.1596 - R2: 0.8768 - val_loss: 0.0232 - val_rmse: 0.1394 - val_R2: 0.9058\n",
      "Epoch 28/50\n",
      "76260/76260 [==============================] - 17s 216us/sample - loss: 0.0301 - rmse: 0.1588 - R2: 0.8780 - val_loss: 0.0242 - val_rmse: 0.1413 - val_R2: 0.9021\n",
      "Epoch 29/50\n",
      "76260/76260 [==============================] - 16s 215us/sample - loss: 0.0300 - rmse: 0.1584 - R2: 0.8786 - val_loss: 0.0241 - val_rmse: 0.1411 - val_R2: 0.9018\n",
      "Epoch 30/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0296 - rmse: 0.1577 - R2: 0.8801 - val_loss: 0.0239 - val_rmse: 0.1408 - val_R2: 0.9027\n",
      "Epoch 31/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0290 - rmse: 0.1564 - R2: 0.8825 - val_loss: 0.0239 - val_rmse: 0.1400 - val_R2: 0.9027\n",
      "Epoch 32/50\n",
      "76260/76260 [==============================] - 16s 213us/sample - loss: 0.0294 - rmse: 0.1569 - R2: 0.8810 - val_loss: 0.0237 - val_rmse: 0.1400 - val_R2: 0.9032\n",
      "Epoch 33/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0289 - rmse: 0.1559 - R2: 0.8829 - val_loss: 0.0241 - val_rmse: 0.1403 - val_R2: 0.9015\n",
      "Epoch 34/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0287 - rmse: 0.1554 - R2: 0.8838 - val_loss: 0.0229 - val_rmse: 0.1386 - val_R2: 0.9068\n",
      "Epoch 35/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0284 - rmse: 0.1546 - R2: 0.8851 - val_loss: 0.0231 - val_rmse: 0.1383 - val_R2: 0.9056\n",
      "Epoch 36/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0286 - rmse: 0.1549 - R2: 0.8844 - val_loss: 0.0225 - val_rmse: 0.1371 - val_R2: 0.9084\n",
      "Epoch 37/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0279 - rmse: 0.1535 - R2: 0.8870 - val_loss: 0.0233 - val_rmse: 0.1391 - val_R2: 0.9050\n",
      "Epoch 38/50\n",
      "76260/76260 [==============================] - 16s 213us/sample - loss: 0.0278 - rmse: 0.1531 - R2: 0.8875 - val_loss: 0.0220 - val_rmse: 0.1358 - val_R2: 0.9104\n",
      "Epoch 39/50\n",
      "76260/76260 [==============================] - 16s 213us/sample - loss: 0.0277 - rmse: 0.1528 - R2: 0.8877 - val_loss: 0.0227 - val_rmse: 0.1374 - val_R2: 0.9074\n",
      "Epoch 40/50\n",
      "76260/76260 [==============================] - 17s 217us/sample - loss: 0.0277 - rmse: 0.1526 - R2: 0.8881 - val_loss: 0.0229 - val_rmse: 0.1383 - val_R2: 0.9069\n",
      "Epoch 41/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0272 - rmse: 0.1518 - R2: 0.8899 - val_loss: 0.0229 - val_rmse: 0.1373 - val_R2: 0.9060\n",
      "Epoch 42/50\n",
      "76260/76260 [==============================] - 17s 217us/sample - loss: 0.0272 - rmse: 0.1516 - R2: 0.8901 - val_loss: 0.0236 - val_rmse: 0.1391 - val_R2: 0.9035\n",
      "Epoch 43/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0273 - rmse: 0.1517 - R2: 0.8895 - val_loss: 0.0228 - val_rmse: 0.1373 - val_R2: 0.9072\n",
      "Epoch 44/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0268 - rmse: 0.1507 - R2: 0.8915 - val_loss: 0.0231 - val_rmse: 0.1371 - val_R2: 0.9054\n",
      "Epoch 45/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0271 - rmse: 0.1511 - R2: 0.8905 - val_loss: 0.0236 - val_rmse: 0.1386 - val_R2: 0.9037\n",
      "Epoch 46/50\n",
      "76260/76260 [==============================] - 17s 216us/sample - loss: 0.0266 - rmse: 0.1502 - R2: 0.8924 - val_loss: 0.0227 - val_rmse: 0.1359 - val_R2: 0.9077\n",
      "Epoch 47/50\n",
      "76260/76260 [==============================] - 16s 216us/sample - loss: 0.0262 - rmse: 0.1494 - R2: 0.8938 - val_loss: 0.0227 - val_rmse: 0.1360 - val_R2: 0.9070\n",
      "Epoch 48/50\n",
      "76260/76260 [==============================] - 16s 214us/sample - loss: 0.0263 - rmse: 0.1494 - R2: 0.8935 - val_loss: 0.0224 - val_rmse: 0.1363 - val_R2: 0.9088\n",
      "Epoch 00048: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_baseline.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02244182689760489, 0.13611364, 0.9028548]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14833601 0.12518951 0.11918243 0.13856264 0.15138036 0.18913966\n",
      " 0.20408257 0.10170649 0.12059173 0.14863955 0.15249004 0.13627044\n",
      " 0.13745228 0.18547738 0.14702036 0.14917187 0.1553259 ]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Trained Embedding Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHONETIC_OUTPUT = len(set(z_train))\n",
    "EMBEDDED_FEATURE = 39\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "\n",
    "def embeded_model(input_shape_1,input_shape_2):\n",
    "    inputs = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "    x = pLSTM(EMBEDDED_FEATURE)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(PHONETIC_OUTPUT, activation='softmax', kernel_initializer='he_uniform')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 24, 39)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 24, 39)            12324     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14)                13118     \n",
      "=================================================================\n",
      "Total params: 25,442\n",
      "Trainable params: 25,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = embeded_model(24, 39)\n",
    "embedded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/50\n",
      "76260/76260 [==============================] - 6s 76us/sample - loss: 2.0143 - accuracy: 0.7720 - val_loss: 1.8802 - val_accuracy: 0.8880\n",
      "Epoch 2/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8968 - accuracy: 0.8678 - val_loss: 1.8532 - val_accuracy: 0.9080\n",
      "Epoch 3/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8734 - accuracy: 0.8886 - val_loss: 1.8420 - val_accuracy: 0.9181\n",
      "Epoch 4/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8600 - accuracy: 0.9009 - val_loss: 1.8388 - val_accuracy: 0.9210\n",
      "Epoch 5/50\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8514 - accuracy: 0.9089 - val_loss: 1.8309 - val_accuracy: 0.9275\n",
      "Epoch 6/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8446 - accuracy: 0.9156 - val_loss: 1.8286 - val_accuracy: 0.9285\n",
      "Epoch 7/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8388 - accuracy: 0.9210 - val_loss: 1.8273 - val_accuracy: 0.9315\n",
      "Epoch 8/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8349 - accuracy: 0.9244 - val_loss: 1.8287 - val_accuracy: 0.9269\n",
      "Epoch 9/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8310 - accuracy: 0.9278 - val_loss: 1.8302 - val_accuracy: 0.9259\n",
      "Epoch 10/50\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8274 - accuracy: 0.9313 - val_loss: 1.8261 - val_accuracy: 0.9303\n",
      "Epoch 11/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8247 - accuracy: 0.9341 - val_loss: 1.8261 - val_accuracy: 0.9306\n",
      "Epoch 12/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8220 - accuracy: 0.9368 - val_loss: 1.8227 - val_accuracy: 0.9344\n",
      "Epoch 13/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8194 - accuracy: 0.9393 - val_loss: 1.8241 - val_accuracy: 0.9319\n",
      "Epoch 14/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8174 - accuracy: 0.9411 - val_loss: 1.8231 - val_accuracy: 0.9332\n",
      "Epoch 15/50\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8149 - accuracy: 0.9434 - val_loss: 1.8238 - val_accuracy: 0.9310\n",
      "Epoch 16/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8136 - accuracy: 0.9448 - val_loss: 1.8211 - val_accuracy: 0.9352\n",
      "Epoch 17/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8117 - accuracy: 0.9466 - val_loss: 1.8220 - val_accuracy: 0.9330\n",
      "Epoch 18/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8103 - accuracy: 0.9478 - val_loss: 1.8193 - val_accuracy: 0.9373\n",
      "Epoch 19/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8094 - accuracy: 0.9485 - val_loss: 1.8223 - val_accuracy: 0.9336\n",
      "Epoch 20/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8077 - accuracy: 0.9505 - val_loss: 1.8233 - val_accuracy: 0.9323\n",
      "Epoch 21/50\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8068 - accuracy: 0.9512 - val_loss: 1.8208 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8053 - accuracy: 0.9524 - val_loss: 1.8191 - val_accuracy: 0.9362\n",
      "Epoch 23/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8045 - accuracy: 0.9534 - val_loss: 1.8175 - val_accuracy: 0.9382\n",
      "Epoch 24/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8030 - accuracy: 0.9545 - val_loss: 1.8189 - val_accuracy: 0.9370\n",
      "Epoch 25/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8022 - accuracy: 0.9553 - val_loss: 1.8215 - val_accuracy: 0.9336\n",
      "Epoch 26/50\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8015 - accuracy: 0.9558 - val_loss: 1.8227 - val_accuracy: 0.9320\n",
      "Epoch 27/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8008 - accuracy: 0.9566 - val_loss: 1.8274 - val_accuracy: 0.9275\n",
      "Epoch 28/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8002 - accuracy: 0.9571 - val_loss: 1.8194 - val_accuracy: 0.9361\n",
      "Epoch 29/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7991 - accuracy: 0.9584 - val_loss: 1.8198 - val_accuracy: 0.9349\n",
      "Epoch 30/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7986 - accuracy: 0.9589 - val_loss: 1.8235 - val_accuracy: 0.9315\n",
      "Epoch 31/50\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.7977 - accuracy: 0.9597 - val_loss: 1.8232 - val_accuracy: 0.9318\n",
      "Epoch 32/50\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.7976 - accuracy: 0.9596 - val_loss: 1.8188 - val_accuracy: 0.9368\n",
      "Epoch 33/50\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7968 - accuracy: 0.9605 - val_loss: 1.8176 - val_accuracy: 0.9379\n",
      "Epoch 00033: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = embedded.fit(X_train,z_train_oe,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,z_val_oe),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.save('embedded.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluated Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.95      0.96      0.95       701\n",
      "           9       0.97      0.97      0.97       688\n",
      "           @       0.97      0.97      0.97       635\n",
      "           A       0.93      0.97      0.95       645\n",
      "           E       0.93      0.94      0.94       697\n",
      "          E:       0.94      0.93      0.94       655\n",
      "           O       0.91      0.95      0.93       729\n",
      "           U       0.90      0.90      0.90       687\n",
      "           a       0.97      0.93      0.95       689\n",
      "           e       0.91      0.94      0.92       644\n",
      "           i       0.98      0.92      0.94       684\n",
      "           o       0.96      0.83      0.89       634\n",
      "           u       0.89      0.96      0.92       659\n",
      "           y       0.94      0.95      0.94       591\n",
      "\n",
      "    accuracy                           0.94      9338\n",
      "   macro avg       0.94      0.94      0.94      9338\n",
      "weighted avg       0.94      0.94      0.94      9338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z_pred = embedded.predict(X_test)\n",
    "evaluate_model(z_pred, z_test_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Model with Embedding Feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 24, 39)            12324     \n",
      "=================================================================\n",
      "Total params: 12,324\n",
      "Trainable params: 0\n",
      "Non-trainable params: 12,324\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = tf.keras.models.load_model('embedded.hdf5')\n",
    "\n",
    "embedded_layers = tf.keras.Sequential()\n",
    "for layer in embedded.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "    embedded_layers.add(layer)\n",
    "embedded_layers.summary()\n",
    "\n",
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "pConv1D = partial(Conv1D, padding = 'same', activation = 'linear', kernel_initializer = 'he_uniform')\n",
    "\n",
    "def init_senet_w_emb(feature_layer=1, cnn_unit=64, first_kernel=11, res_unit=128, res_kernel=7,\n",
    "    bilstm = 1, bilstm_unit=256, \n",
    "    dropout_rate=0.3,\n",
    "    reduction_ratio = 2,\n",
    "    activation_fn='relu'):\n",
    "\n",
    "\n",
    "    def cnn_block(input_x, cnn_unit, kernel_size):\n",
    "        x = pConv1D(cnn_unit, kernel_size=kernel_size)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        return x\n",
    "\n",
    "    def se_block(input_x):\n",
    "        x = layers.GlobalAveragePooling1D()(input_x)\n",
    "        channel_shape = getattr(x, '_shape_val')[-1]\n",
    "        x = Reshape((1, channel_shape))(x)\n",
    "        x = Dense(channel_shape // reduction_ratio, activation=activation_fn, kernel_initializer='he_uniform')(x)\n",
    "        x = Dense(channel_shape, activation='tanh', kernel_initializer='he_uniform')(x)\n",
    "        return x\n",
    "\n",
    "    def residual_block(input_x):\n",
    "        x = cnn_block(input_x, res_unit,kernel_size=res_kernel)\n",
    "        x = pConv1D(res_unit, kernel_size=3)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    def se_res_block(input_x):\n",
    "        res_x = residual_block(input_x)\n",
    "        se_x = se_block(res_x)\n",
    "        x = layers.Multiply()([res_x, se_x])\n",
    "        x = Activation(activation_fn)(x)\n",
    "#         input_x = cnn_block(input_x, cnn_unit=res_unit, kernel_size=1)\n",
    "        x = layers.Add()([x, input_x])\n",
    "        return x\n",
    "\n",
    "    def senet_nn(input_shape_1,input_shape_2):\n",
    "\n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        embedded = embedded_layers(input_x)\n",
    "        x = layers.Concatenate()([input_x, embedded])\n",
    "        x = cnn_block(x, 128, first_kernel)\n",
    "\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = cnn_block(x, cnn_unit=cnn_unit, kernel_size=1)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(bilstm-1):\n",
    "            x = Bidirectional(pLSTM(bilstm_unit))(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = Bidirectional(pLSTM(bilstm_unit, return_sequences=False))(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "        outputs = Dense(N_OUTPUTS, activation='linear', kernel_initializer='he_uniform')(x)\n",
    "        model = keras.Model(inputs=input_x, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    return senet_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 24, 128)      55040       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 24, 128)      512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 128)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 24, 128)      114816      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 24, 128)      512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 128)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 24, 128)      49280       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 24, 128)      512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 64)        8256        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 128)       8320        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 24, 128)      0           batch_normalization_8[0][0]      \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 24, 128)      0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 128)      0           activation_8[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 24, 128)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 24, 128)      114816      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 24, 128)      512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 24, 128)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 24, 128)      49280       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 24, 128)      512         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 128)       0           global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 64)        8256        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 128)       8320        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 24, 128)      0           batch_normalization_10[0][0]     \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 24, 128)      0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 128)      0           activation_10[0][0]              \n",
      "                                                                 spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 24, 128)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 24, 64)       8256        spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 24, 64)       256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 24, 64)       0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 24, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 512)          657408      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 17)           8721        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,093,585\n",
      "Trainable params: 1,092,177\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model = init_senet_w_emb()(24, 39)\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/50\n",
      "76260/76260 - 24s - loss: 0.1036 - rmse: 0.2980 - R2: 0.5799 - val_loss: 0.0407 - val_rmse: 0.1860 - val_R2: 0.8341\n",
      "Epoch 2/50\n",
      "76260/76260 - 16s - loss: 0.0580 - rmse: 0.2217 - R2: 0.7650 - val_loss: 0.0358 - val_rmse: 0.1718 - val_R2: 0.8546\n",
      "Epoch 3/50\n",
      "76260/76260 - 16s - loss: 0.0504 - rmse: 0.2054 - R2: 0.7959 - val_loss: 0.0333 - val_rmse: 0.1664 - val_R2: 0.8646\n",
      "Epoch 4/50\n",
      "76260/76260 - 16s - loss: 0.0468 - rmse: 0.1973 - R2: 0.8105 - val_loss: 0.0317 - val_rmse: 0.1618 - val_R2: 0.8712\n",
      "Epoch 5/50\n",
      "76260/76260 - 16s - loss: 0.0442 - rmse: 0.1914 - R2: 0.8212 - val_loss: 0.0314 - val_rmse: 0.1617 - val_R2: 0.8721\n",
      "Epoch 6/50\n",
      "76260/76260 - 16s - loss: 0.0425 - rmse: 0.1877 - R2: 0.8276 - val_loss: 0.0303 - val_rmse: 0.1586 - val_R2: 0.8763\n",
      "Epoch 7/50\n",
      "76260/76260 - 16s - loss: 0.0408 - rmse: 0.1839 - R2: 0.8345 - val_loss: 0.0295 - val_rmse: 0.1578 - val_R2: 0.8806\n",
      "Epoch 8/50\n",
      "76260/76260 - 16s - loss: 0.0395 - rmse: 0.1809 - R2: 0.8397 - val_loss: 0.0284 - val_rmse: 0.1533 - val_R2: 0.8840\n",
      "Epoch 9/50\n",
      "76260/76260 - 16s - loss: 0.0387 - rmse: 0.1789 - R2: 0.8432 - val_loss: 0.0282 - val_rmse: 0.1541 - val_R2: 0.8849\n",
      "Epoch 10/50\n",
      "76260/76260 - 16s - loss: 0.0376 - rmse: 0.1765 - R2: 0.8474 - val_loss: 0.0260 - val_rmse: 0.1484 - val_R2: 0.8944\n",
      "Epoch 11/50\n",
      "76260/76260 - 16s - loss: 0.0368 - rmse: 0.1746 - R2: 0.8511 - val_loss: 0.0265 - val_rmse: 0.1486 - val_R2: 0.8923\n",
      "Epoch 12/50\n",
      "76260/76260 - 16s - loss: 0.0360 - rmse: 0.1728 - R2: 0.8540 - val_loss: 0.0273 - val_rmse: 0.1507 - val_R2: 0.8890\n",
      "Epoch 13/50\n",
      "76260/76260 - 16s - loss: 0.0353 - rmse: 0.1710 - R2: 0.8570 - val_loss: 0.0276 - val_rmse: 0.1516 - val_R2: 0.8881\n",
      "Epoch 14/50\n",
      "76260/76260 - 16s - loss: 0.0347 - rmse: 0.1697 - R2: 0.8592 - val_loss: 0.0259 - val_rmse: 0.1473 - val_R2: 0.8944\n",
      "Epoch 15/50\n",
      "76260/76260 - 16s - loss: 0.0341 - rmse: 0.1683 - R2: 0.8617 - val_loss: 0.0270 - val_rmse: 0.1493 - val_R2: 0.8890\n",
      "Epoch 16/50\n",
      "76260/76260 - 16s - loss: 0.0336 - rmse: 0.1671 - R2: 0.8640 - val_loss: 0.0255 - val_rmse: 0.1461 - val_R2: 0.8954\n",
      "Epoch 17/50\n",
      "76260/76260 - 17s - loss: 0.0332 - rmse: 0.1662 - R2: 0.8652 - val_loss: 0.0251 - val_rmse: 0.1451 - val_R2: 0.8977\n",
      "Epoch 18/50\n",
      "76260/76260 - 16s - loss: 0.0325 - rmse: 0.1645 - R2: 0.8684 - val_loss: 0.0251 - val_rmse: 0.1450 - val_R2: 0.8972\n",
      "Epoch 19/50\n",
      "76260/76260 - 16s - loss: 0.0326 - rmse: 0.1645 - R2: 0.8680 - val_loss: 0.0252 - val_rmse: 0.1447 - val_R2: 0.8974\n",
      "Epoch 20/50\n",
      "76260/76260 - 16s - loss: 0.0317 - rmse: 0.1627 - R2: 0.8713 - val_loss: 0.0254 - val_rmse: 0.1452 - val_R2: 0.8965\n",
      "Epoch 21/50\n",
      "76260/76260 - 16s - loss: 0.0316 - rmse: 0.1624 - R2: 0.8721 - val_loss: 0.0241 - val_rmse: 0.1423 - val_R2: 0.9020\n",
      "Epoch 22/50\n",
      "76260/76260 - 16s - loss: 0.0312 - rmse: 0.1614 - R2: 0.8738 - val_loss: 0.0249 - val_rmse: 0.1431 - val_R2: 0.8987\n",
      "Epoch 23/50\n",
      "76260/76260 - 16s - loss: 0.0306 - rmse: 0.1600 - R2: 0.8762 - val_loss: 0.0257 - val_rmse: 0.1453 - val_R2: 0.8954\n",
      "Epoch 24/50\n",
      "76260/76260 - 16s - loss: 0.0307 - rmse: 0.1601 - R2: 0.8759 - val_loss: 0.0244 - val_rmse: 0.1428 - val_R2: 0.8999\n",
      "Epoch 25/50\n",
      "76260/76260 - 16s - loss: 0.0303 - rmse: 0.1591 - R2: 0.8772 - val_loss: 0.0246 - val_rmse: 0.1428 - val_R2: 0.8993\n",
      "Epoch 26/50\n",
      "76260/76260 - 16s - loss: 0.0298 - rmse: 0.1581 - R2: 0.8792 - val_loss: 0.0247 - val_rmse: 0.1425 - val_R2: 0.8987\n",
      "Epoch 27/50\n",
      "76260/76260 - 16s - loss: 0.0297 - rmse: 0.1579 - R2: 0.8796 - val_loss: 0.0240 - val_rmse: 0.1408 - val_R2: 0.9016\n",
      "Epoch 28/50\n",
      "76260/76260 - 16s - loss: 0.0296 - rmse: 0.1574 - R2: 0.8801 - val_loss: 0.0248 - val_rmse: 0.1426 - val_R2: 0.8987\n",
      "Epoch 29/50\n",
      "76260/76260 - 16s - loss: 0.0290 - rmse: 0.1561 - R2: 0.8825 - val_loss: 0.0241 - val_rmse: 0.1411 - val_R2: 0.9016\n",
      "Epoch 30/50\n",
      "76260/76260 - 16s - loss: 0.0290 - rmse: 0.1561 - R2: 0.8824 - val_loss: 0.0251 - val_rmse: 0.1432 - val_R2: 0.8976\n",
      "Epoch 31/50\n",
      "76260/76260 - 16s - loss: 0.0287 - rmse: 0.1553 - R2: 0.8838 - val_loss: 0.0242 - val_rmse: 0.1411 - val_R2: 0.9007\n",
      "Epoch 32/50\n",
      "76260/76260 - 16s - loss: 0.0284 - rmse: 0.1547 - R2: 0.8848 - val_loss: 0.0237 - val_rmse: 0.1399 - val_R2: 0.9026\n",
      "Epoch 33/50\n",
      "76260/76260 - 16s - loss: 0.0283 - rmse: 0.1543 - R2: 0.8855 - val_loss: 0.0252 - val_rmse: 0.1433 - val_R2: 0.8962\n",
      "Epoch 34/50\n",
      "76260/76260 - 16s - loss: 0.0280 - rmse: 0.1535 - R2: 0.8869 - val_loss: 0.0240 - val_rmse: 0.1402 - val_R2: 0.9014\n",
      "Epoch 35/50\n",
      "76260/76260 - 16s - loss: 0.0282 - rmse: 0.1540 - R2: 0.8857 - val_loss: 0.0251 - val_rmse: 0.1424 - val_R2: 0.8972\n",
      "Epoch 36/50\n",
      "76260/76260 - 16s - loss: 0.0278 - rmse: 0.1531 - R2: 0.8873 - val_loss: 0.0230 - val_rmse: 0.1377 - val_R2: 0.9063\n",
      "Epoch 37/50\n",
      "76260/76260 - 16s - loss: 0.0274 - rmse: 0.1522 - R2: 0.8890 - val_loss: 0.0244 - val_rmse: 0.1418 - val_R2: 0.9002\n",
      "Epoch 38/50\n",
      "76260/76260 - 16s - loss: 0.0275 - rmse: 0.1523 - R2: 0.8888 - val_loss: 0.0234 - val_rmse: 0.1386 - val_R2: 0.9046\n",
      "Epoch 39/50\n",
      "76260/76260 - 16s - loss: 0.0270 - rmse: 0.1512 - R2: 0.8905 - val_loss: 0.0231 - val_rmse: 0.1376 - val_R2: 0.9058\n",
      "Epoch 40/50\n",
      "76260/76260 - 16s - loss: 0.0270 - rmse: 0.1511 - R2: 0.8906 - val_loss: 0.0246 - val_rmse: 0.1417 - val_R2: 0.8999\n",
      "Epoch 41/50\n",
      "76260/76260 - 16s - loss: 0.0268 - rmse: 0.1506 - R2: 0.8918 - val_loss: 0.0234 - val_rmse: 0.1381 - val_R2: 0.9036\n",
      "Epoch 42/50\n",
      "76260/76260 - 16s - loss: 0.0265 - rmse: 0.1501 - R2: 0.8927 - val_loss: 0.0242 - val_rmse: 0.1406 - val_R2: 0.9014\n",
      "Epoch 43/50\n",
      "76260/76260 - 16s - loss: 0.0266 - rmse: 0.1501 - R2: 0.8923 - val_loss: 0.0235 - val_rmse: 0.1380 - val_R2: 0.9038\n",
      "Epoch 44/50\n",
      "76260/76260 - 16s - loss: 0.0264 - rmse: 0.1498 - R2: 0.8929 - val_loss: 0.0236 - val_rmse: 0.1388 - val_R2: 0.9035\n",
      "Epoch 45/50\n",
      "76260/76260 - 16s - loss: 0.0262 - rmse: 0.1492 - R2: 0.8939 - val_loss: 0.0233 - val_rmse: 0.1377 - val_R2: 0.9045\n",
      "Epoch 46/50\n",
      "76260/76260 - 16s - loss: 0.0259 - rmse: 0.1486 - R2: 0.8951 - val_loss: 0.0229 - val_rmse: 0.1366 - val_R2: 0.9062\n",
      "Epoch 47/50\n",
      "76260/76260 - 16s - loss: 0.0260 - rmse: 0.1486 - R2: 0.8946 - val_loss: 0.0225 - val_rmse: 0.1361 - val_R2: 0.9078\n",
      "Epoch 48/50\n",
      "76260/76260 - 16s - loss: 0.0259 - rmse: 0.1484 - R2: 0.8954 - val_loss: 0.0246 - val_rmse: 0.1402 - val_R2: 0.8994\n",
      "Epoch 49/50\n",
      "76260/76260 - 16s - loss: 0.0256 - rmse: 0.1478 - R2: 0.8962 - val_loss: 0.0234 - val_rmse: 0.1379 - val_R2: 0.9045\n",
      "Epoch 50/50\n",
      "76260/76260 - 16s - loss: 0.0254 - rmse: 0.1473 - R2: 0.8970 - val_loss: 0.0233 - val_rmse: 0.1371 - val_R2: 0.9044\n"
     ]
    }
   ],
   "source": [
    "history = emb_model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.save('model_with_embedded.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = tf.keras.models.load_model('model_with_embedded.hdf5', custom_objects={'rmse': rmse, 'R2':R2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.023318270235714374, 0.13730691, 0.8975433]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = emb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check error by each data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = compute_rmse(y_test,y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14833601 0.12518951 0.11918243 0.13856264 0.15138036 0.18913966\n",
      " 0.20408257 0.10170649 0.12059173 0.14863955 0.15249004 0.13627044\n",
      " 0.13745228 0.18547738 0.14702036 0.14917187 0.1553259 ]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rank by highest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df = pd.DataFrame({'phonetic':z_test, 'err':errs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U</td>\n",
       "      <td>0.115419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>0.283488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>0.145359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>0.078873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "      <td>0.123012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  phonetic       err\n",
       "0        U  0.115419\n",
       "1        O  0.283488\n",
       "2        O  0.145359\n",
       "3        U  0.078873\n",
       "4        i  0.123012"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>a</td>\n",
       "      <td>0.035802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5071</th>\n",
       "      <td>A</td>\n",
       "      <td>0.035853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>A</td>\n",
       "      <td>0.037077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>2</td>\n",
       "      <td>0.038161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334</th>\n",
       "      <td>o</td>\n",
       "      <td>0.039026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6368</th>\n",
       "      <td>2</td>\n",
       "      <td>0.626692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5656</th>\n",
       "      <td>u</td>\n",
       "      <td>0.650269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>9</td>\n",
       "      <td>0.656332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7227</th>\n",
       "      <td>u</td>\n",
       "      <td>0.661507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>u</td>\n",
       "      <td>0.678495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9338 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     phonetic       err\n",
       "3281        a  0.035802\n",
       "5071        A  0.035853\n",
       "2968        A  0.037077\n",
       "3894        2  0.038161\n",
       "4334        o  0.039026\n",
       "...       ...       ...\n",
       "6368        2  0.626692\n",
       "5656        u  0.650269\n",
       "5129        9  0.656332\n",
       "7227        u  0.661507\n",
       "4555        u  0.678495\n",
       "\n",
       "[9338 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df.sort_values('err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001E43343E358>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_df.hist('err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df_high = err_df[err_df['err'] > 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>0.283488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i</td>\n",
       "      <td>0.193276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>0.230653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>U</td>\n",
       "      <td>0.159936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phonetic       err\n",
       "1         O  0.283488\n",
       "6         i  0.193276\n",
       "8         i  0.230653\n",
       "14        A  0.226100\n",
       "18        U  0.159936"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df_high.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e433764048>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_df[err_df['err'] > 0.5].groupby('phonetic')['phonetic'].count().sort_values(ascending=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phonetic\n",
       "2      70\n",
       "9     184\n",
       "@     133\n",
       "A      85\n",
       "E     174\n",
       "E:    171\n",
       "O     193\n",
       "U     111\n",
       "a     175\n",
       "e     209\n",
       "i     289\n",
       "o     184\n",
       "u     218\n",
       "y     123\n",
       "Name: phonetic, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df_high.groupby('phonetic')['phonetic'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate each param of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = compute_se(y_test,y_pred)\n",
    "errs = compute_rmse(y_test,y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se = pd.DataFrame(se, columns=[\"HX\",\"HY\",\"JA\",\"LP\",\"LD\",\"VS\",\"VO\",\"TCX\",\"TCY\",\"TTX\",\"TTY\",\"TBX\",\"TBY\",\"TS1\",\"TS2\",\"TS3\",\"TS4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se['phonetic'] = z_test\n",
    "df_se['mean_err'] = errs\n",
    "df_se['audio'] = a_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HX</th>\n",
       "      <th>HY</th>\n",
       "      <th>JA</th>\n",
       "      <th>LP</th>\n",
       "      <th>LD</th>\n",
       "      <th>VS</th>\n",
       "      <th>VO</th>\n",
       "      <th>TCX</th>\n",
       "      <th>TCY</th>\n",
       "      <th>TTX</th>\n",
       "      <th>TTY</th>\n",
       "      <th>TBX</th>\n",
       "      <th>TBY</th>\n",
       "      <th>TS1</th>\n",
       "      <th>TS2</th>\n",
       "      <th>TS3</th>\n",
       "      <th>TS4</th>\n",
       "      <th>phonetic</th>\n",
       "      <th>mean_err</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.114307</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.072413</td>\n",
       "      <td>0.126587</td>\n",
       "      <td>0.033710</td>\n",
       "      <td>0.402854</td>\n",
       "      <td>0.091562</td>\n",
       "      <td>0.035189</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.044808</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.054798</td>\n",
       "      <td>0.033576</td>\n",
       "      <td>0.066584</td>\n",
       "      <td>0.079148</td>\n",
       "      <td>U</td>\n",
       "      <td>0.115419</td>\n",
       "      <td>[-0.0036667322, -0.0067870035, -0.009936802, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357513</td>\n",
       "      <td>0.293304</td>\n",
       "      <td>0.198497</td>\n",
       "      <td>0.147736</td>\n",
       "      <td>0.310341</td>\n",
       "      <td>0.264825</td>\n",
       "      <td>0.395689</td>\n",
       "      <td>0.060571</td>\n",
       "      <td>0.131548</td>\n",
       "      <td>0.210760</td>\n",
       "      <td>0.115824</td>\n",
       "      <td>0.211891</td>\n",
       "      <td>0.311978</td>\n",
       "      <td>0.422195</td>\n",
       "      <td>0.339982</td>\n",
       "      <td>0.459955</td>\n",
       "      <td>0.204212</td>\n",
       "      <td>O</td>\n",
       "      <td>0.283488</td>\n",
       "      <td>[-0.0077388003, -0.011906635, -0.15257795, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033070</td>\n",
       "      <td>0.139970</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>0.117686</td>\n",
       "      <td>0.146222</td>\n",
       "      <td>0.238119</td>\n",
       "      <td>0.279346</td>\n",
       "      <td>0.136286</td>\n",
       "      <td>0.207129</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.117553</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.163568</td>\n",
       "      <td>0.215327</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>0.130082</td>\n",
       "      <td>O</td>\n",
       "      <td>0.145359</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.049741</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.176167</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>0.020521</td>\n",
       "      <td>0.052028</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>0.075002</td>\n",
       "      <td>0.121391</td>\n",
       "      <td>0.187221</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>U</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>[0.026149532, 0.034463353, 0.037094187, 0.0368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037142</td>\n",
       "      <td>0.079436</td>\n",
       "      <td>0.146946</td>\n",
       "      <td>0.195756</td>\n",
       "      <td>0.197194</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.204950</td>\n",
       "      <td>0.040940</td>\n",
       "      <td>0.024028</td>\n",
       "      <td>0.038695</td>\n",
       "      <td>0.126442</td>\n",
       "      <td>0.127264</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>0.083708</td>\n",
       "      <td>0.066435</td>\n",
       "      <td>0.246892</td>\n",
       "      <td>i</td>\n",
       "      <td>0.123012</td>\n",
       "      <td>[-0.021888198, -0.033991054, -0.042626306, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HX        HY        JA        LP        LD        VS        VO  \\\n",
       "0  0.044966  0.114307  0.002211  0.072413  0.126587  0.033710  0.402854   \n",
       "1  0.357513  0.293304  0.198497  0.147736  0.310341  0.264825  0.395689   \n",
       "2  0.033070  0.139970  0.026395  0.117686  0.146222  0.238119  0.279346   \n",
       "3  0.101272  0.049741  0.000629  0.012308  0.009070  0.176167  0.055172   \n",
       "4  0.037142  0.079436  0.146946  0.195756  0.197194  0.011711  0.204950   \n",
       "\n",
       "        TCX       TCY       TTX       TTY       TBX       TBY       TS1  \\\n",
       "0  0.091562  0.035189  0.012820  0.001042  0.044808  0.007313  0.054798   \n",
       "1  0.060571  0.131548  0.210760  0.115824  0.211891  0.311978  0.422195   \n",
       "2  0.136286  0.207129  0.019928  0.117553  0.016278  0.163568  0.215327   \n",
       "3  0.007766  0.020521  0.052028  0.001492  0.004869  0.008206  0.075002   \n",
       "4  0.040940  0.024028  0.038695  0.126442  0.127264  0.006106  0.016215   \n",
       "\n",
       "        TS2       TS3       TS4 phonetic  mean_err  \\\n",
       "0  0.033576  0.066584  0.079148        U  0.115419   \n",
       "1  0.339982  0.459955  0.204212        O  0.283488   \n",
       "2  0.027693  0.032896  0.130082        O  0.145359   \n",
       "3  0.121391  0.187221  0.004378        U  0.078873   \n",
       "4  0.083708  0.066435  0.246892        i  0.123012   \n",
       "\n",
       "                                               audio  \n",
       "0  [-0.0036667322, -0.0067870035, -0.009936802, -...  \n",
       "1  [-0.0077388003, -0.011906635, -0.15257795, -0....  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.026149532, 0.034463353, 0.037094187, 0.0368...  \n",
       "4  [-0.021888198, -0.033991054, -0.042626306, -0....  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-38ad2d03395b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'phonetic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'7'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_err'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TS4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(self, by, bins, **kwargs)\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \"\"\"\n\u001b[1;32m-> 1125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"hist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ax\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left_ax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;31m# no non-numeric frames or series allowed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no numeric data to plot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;31m# GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "df_se[(df_se['phonetic'] == '7') & (df_se['mean_err'] > 0.5)]['TS4'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA audio of testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort = df_se.sort_values('mean_err',ascending=False)\n",
    "df_se_sort.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort[df_se_sort['phonetic'] == '&'].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(df_se_sort['audio'][0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort[df_se_sort['phonetic'] == '&'].tail(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(df_se_sort['audio'][12073], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
