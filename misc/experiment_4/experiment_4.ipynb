{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on AAI Model Architectures\n",
    "- Created: 10 Mar 2020\n",
    "- Data: param_draft2\n",
    "- Increase data size and change model architecture\n",
    "- Remove SE\n",
    "- expeirment 10 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil \n",
    "import argparse\n",
    "from functools import partial\n",
    "import pickle\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Reshape, GRU, InputLayer, AlphaDropout, Activation, BatchNormalization, Dropout, Flatten, Dense, Bidirectional, LSTM, Conv1D, SpatialDropout1D, Concatenate, Multiply, Add\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = partial(np.load)\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred), axis = 0) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true, axis = 0)), axis = 0) \n",
    "    return K.mean(1 - (SS_res/SS_tot), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preprocessing data\n",
    "def delete_params(params):\n",
    "    '''\n",
    "    This function remove JX, WC, TRX, TRY, and MS1,2,3 paramter\n",
    "    '''\n",
    "    DEL_PARAMS_LIST = [2,8,15,16,21,22,23]\n",
    "    return np.delete(params,DEL_PARAMS_LIST , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(actual,pred, axis=1):\n",
    "    # Compute RMSE by row (axis=1) result in rmse of each data\n",
    "    # Compute RMSE by column (axis=0) result in rmse of each label\n",
    "    return np.sqrt((np.square(actual - pred)).mean(axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, label):\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    label = enc.inverse_transform(label)\n",
    "#     print('Confusion Matrix')\n",
    "#     print(confusion_matrix(label, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_se(actual,pred):\n",
    "    return np.sqrt((np.square(actual - pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "\n",
    "    # load data from preprocess pipeline\n",
    "    dataset = np.load(join('../../data/d_dataset_p2/prep_data_13','training_subsets.npz'))\n",
    "    X_train =dataset['X_train']\n",
    "    y_train= dataset['y_train']\n",
    "    z_train= dataset['z_train']\n",
    "    X_val = dataset['X_val']\n",
    "    y_val = dataset['y_val']\n",
    "    z_val = dataset['z_val']\n",
    "    X_test = dataset['X_test']\n",
    "    y_test = dataset['y_test']\n",
    "    z_test = dataset['z_test']\n",
    "    a_test = dataset['audio_test']\n",
    "    a_val = dataset['audio_val']\n",
    "    \n",
    "    y_train = delete_params(y_train)\n",
    "    y_val = delete_params(y_val)\n",
    "    y_test = delete_params(y_test)\n",
    "\n",
    "    print('Train features and labels %s %s'%(str(X_train.shape),str(y_train.shape)))\n",
    "    print('Validating features and labels %s %s'%(str(X_val.shape),str(y_val.shape)))\n",
    "    print('Test features and labels %s %s'%(str(X_test.shape),str(y_test.shape)))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test, a_test, a_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (76260, 24, 39) (76260, 17)\n",
      "Validating features and labels (9340, 24, 39) (9340, 17)\n",
      "Test features and labels (9338, 24, 39) (9338, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, z_train, z_val, z_test, a_test, a_val = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2', 'u', 'y', 'o', 'i', '9', 'O', 'A', '@', 'a', 'e', 'U', 'E:', 'E'}\n"
     ]
    }
   ],
   "source": [
    "print(set(z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features and labels (76260, 24, 39) (76260, 17) (76260,)\n",
      "Validating features and labels (9340, 24, 39) (9340, 17) (9340,)\n",
      "Test features and labels (9338, 24, 39) (9338, 17) (9338,)\n"
     ]
    }
   ],
   "source": [
    "print('Train features and labels {} {} {}'.format(str(X_train.shape),str(y_train.shape),str(z_train.shape)))\n",
    "print('Validating features and labels {} {} {}'.format(str(X_val.shape),str(y_val.shape),str(z_val.shape)))\n",
    "print('Test features and labels {} {} {}'.format(str(X_test.shape),str(y_test.shape),str(z_test.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_oe=z_train.reshape(-1,1)\n",
    "z_val_oe=z_val.reshape(-1,1)\n",
    "z_test_oe=z_test.reshape(-1,1)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(z_train_oe)\n",
    "\n",
    "z_train_oe = enc.transform(z_train_oe).toarray()\n",
    "z_test_oe = enc.transform(z_test_oe).toarray()\n",
    "z_val_oe = enc.transform(z_val_oe).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Train Baseline Model\n",
    "- Model without embedding feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Model without Embedded Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "pConv1D = partial(Conv1D, padding = 'same', activation = 'linear', kernel_initializer = 'he_uniform')\n",
    "\n",
    "def init_senet(feature_layer=1, cnn_unit=64, first_kernel=11, res_unit=64, res_kernel=3,\n",
    "    bilstm = 1, bilstm_unit=256, \n",
    "    dropout_rate=0.3,\n",
    "    reduction_ratio = 2,\n",
    "    activation_fn='relu'):\n",
    "\n",
    "\n",
    "    def cnn_block(input_x, cnn_unit, kernel_size):\n",
    "        x = pConv1D(cnn_unit, kernel_size=kernel_size)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        return x\n",
    "    \n",
    "    def residual_block(input_x):\n",
    "        x = pConv1D(res_unit, kernel_size=res_kernel)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        x = pConv1D(res_unit, kernel_size=res_kernel)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.Add()([x, input_x])\n",
    "        output = Activation(activation_fn)(x)\n",
    "        return output\n",
    "\n",
    "    def se_block(input_x):\n",
    "        x = layers.GlobalAveragePooling1D()(input_x)\n",
    "        channel_shape = getattr(x, '_shape_val')[-1]\n",
    "        x = Reshape((1, channel_shape))(x)\n",
    "        x = Dense(channel_shape // reduction_ratio, activation=activation_fn, kernel_initializer='he_uniform')(x)\n",
    "        x = Dense(channel_shape, activation='tanh', kernel_initializer='he_uniform')(x)\n",
    "        return x\n",
    "\n",
    "    def se_res_block(input_x):\n",
    "        res_x = residual_block(input_x)\n",
    "        se_x = se_block(res_x)\n",
    "        x = layers.Multiply()([res_x, se_x])\n",
    "        return x\n",
    "\n",
    "    def senet_nn(input_shape_1,input_shape_2):\n",
    "\n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        x = cnn_block(input_x, cnn_unit, first_kernel)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = cnn_block(x, cnn_unit=cnn_unit, kernel_size=1)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(bilstm-1):\n",
    "            x = Bidirectional(pLSTM(bilstm_unit))(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = Bidirectional(pLSTM(bilstm_unit, return_sequences=False))(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "        outputs = Dense(N_OUTPUTS, activation='linear', kernel_initializer='he_uniform')(x)\n",
    "        model = keras.Model(inputs=input_x, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    return senet_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_senet()(24, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 24, 64)       27520       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 24, 64)       256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 24, 64)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 24, 64)       12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24, 64)       256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 24, 64)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 24, 64)       12352       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 64)       256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 24, 64)       0           batch_normalization_2[0][0]      \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 64)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 64)        0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 32)        2080        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64)        2112        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 24, 64)       0           activation_2[0][0]               \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 24, 64)       0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 24, 64)       12352       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 64)       256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 64)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 24, 64)       12352       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24, 64)       256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24, 64)       0           batch_normalization_4[0][0]      \n",
      "                                                                 spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 64)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 32)        2080        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 64)        2112        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 24, 64)       0           activation_4[0][0]               \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 24, 64)       0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 24, 64)       4160        spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 24, 64)       256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 24, 64)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 24, 64)       0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 512)          657408      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 17)           8721        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 757,137\n",
      "Trainable params: 756,369\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/100\n",
      "76260/76260 [==============================] - 24s 311us/sample - loss: 0.1088 - rmse: 0.3078 - R2: 0.5618 - val_loss: 0.0442 - val_rmse: 0.1932 - val_R2: 0.8201\n",
      "Epoch 2/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0630 - rmse: 0.2314 - R2: 0.7454 - val_loss: 0.0398 - val_rmse: 0.1816 - val_R2: 0.8389\n",
      "Epoch 3/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0550 - rmse: 0.2141 - R2: 0.7784 - val_loss: 0.0389 - val_rmse: 0.1804 - val_R2: 0.8433\n",
      "Epoch 4/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0509 - rmse: 0.2055 - R2: 0.7949 - val_loss: 0.0359 - val_rmse: 0.1738 - val_R2: 0.8554\n",
      "Epoch 5/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0485 - rmse: 0.2003 - R2: 0.8044 - val_loss: 0.0345 - val_rmse: 0.1697 - val_R2: 0.8600\n",
      "Epoch 6/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0466 - rmse: 0.1962 - R2: 0.8116 - val_loss: 0.0334 - val_rmse: 0.1677 - val_R2: 0.8652\n",
      "Epoch 7/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0450 - rmse: 0.1925 - R2: 0.8183 - val_loss: 0.0317 - val_rmse: 0.1636 - val_R2: 0.8721\n",
      "Epoch 8/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0434 - rmse: 0.1892 - R2: 0.8246 - val_loss: 0.0303 - val_rmse: 0.1592 - val_R2: 0.8773\n",
      "Epoch 9/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0424 - rmse: 0.1867 - R2: 0.8287 - val_loss: 0.0319 - val_rmse: 0.1629 - val_R2: 0.8705\n",
      "Epoch 10/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0420 - rmse: 0.1858 - R2: 0.8304 - val_loss: 0.0305 - val_rmse: 0.1596 - val_R2: 0.8758\n",
      "Epoch 11/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0408 - rmse: 0.1832 - R2: 0.8353 - val_loss: 0.0299 - val_rmse: 0.1573 - val_R2: 0.8785\n",
      "Epoch 12/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0399 - rmse: 0.1811 - R2: 0.8391 - val_loss: 0.0317 - val_rmse: 0.1613 - val_R2: 0.8708\n",
      "Epoch 13/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0394 - rmse: 0.1802 - R2: 0.8408 - val_loss: 0.0305 - val_rmse: 0.1587 - val_R2: 0.8757\n",
      "Epoch 14/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0388 - rmse: 0.1788 - R2: 0.8432 - val_loss: 0.0292 - val_rmse: 0.1565 - val_R2: 0.8817\n",
      "Epoch 15/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0385 - rmse: 0.1781 - R2: 0.8443 - val_loss: 0.0304 - val_rmse: 0.1585 - val_R2: 0.8765\n",
      "Epoch 16/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0378 - rmse: 0.1764 - R2: 0.8476 - val_loss: 0.0291 - val_rmse: 0.1551 - val_R2: 0.8819\n",
      "Epoch 17/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0376 - rmse: 0.1760 - R2: 0.8482 - val_loss: 0.0287 - val_rmse: 0.1542 - val_R2: 0.8838\n",
      "Epoch 18/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0370 - rmse: 0.1747 - R2: 0.8505 - val_loss: 0.0286 - val_rmse: 0.1539 - val_R2: 0.8829\n",
      "Epoch 19/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0363 - rmse: 0.1730 - R2: 0.8536 - val_loss: 0.0286 - val_rmse: 0.1537 - val_R2: 0.8842\n",
      "Epoch 20/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0359 - rmse: 0.1722 - R2: 0.8548 - val_loss: 0.0281 - val_rmse: 0.1525 - val_R2: 0.8869\n",
      "Epoch 21/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0359 - rmse: 0.1721 - R2: 0.8549 - val_loss: 0.0282 - val_rmse: 0.1523 - val_R2: 0.8854\n",
      "Epoch 22/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0356 - rmse: 0.1712 - R2: 0.8564 - val_loss: 0.0291 - val_rmse: 0.1546 - val_R2: 0.8820\n",
      "Epoch 23/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0349 - rmse: 0.1698 - R2: 0.8592 - val_loss: 0.0279 - val_rmse: 0.1522 - val_R2: 0.8871\n",
      "Epoch 24/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0350 - rmse: 0.1699 - R2: 0.8586 - val_loss: 0.0277 - val_rmse: 0.1515 - val_R2: 0.8878\n",
      "Epoch 25/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0345 - rmse: 0.1686 - R2: 0.8607 - val_loss: 0.0282 - val_rmse: 0.1519 - val_R2: 0.8856\n",
      "Epoch 26/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0341 - rmse: 0.1680 - R2: 0.8623 - val_loss: 0.0280 - val_rmse: 0.1508 - val_R2: 0.8862\n",
      "Epoch 27/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0336 - rmse: 0.1669 - R2: 0.8644 - val_loss: 0.0265 - val_rmse: 0.1480 - val_R2: 0.8926\n",
      "Epoch 28/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0340 - rmse: 0.1675 - R2: 0.8627 - val_loss: 0.0292 - val_rmse: 0.1527 - val_R2: 0.8803\n",
      "Epoch 29/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0338 - rmse: 0.1672 - R2: 0.8632 - val_loss: 0.0270 - val_rmse: 0.1491 - val_R2: 0.8904\n",
      "Epoch 30/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0332 - rmse: 0.1657 - R2: 0.8660 - val_loss: 0.0286 - val_rmse: 0.1520 - val_R2: 0.8840\n",
      "Epoch 31/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0334 - rmse: 0.1660 - R2: 0.8650 - val_loss: 0.0264 - val_rmse: 0.1468 - val_R2: 0.8928\n",
      "Epoch 32/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0332 - rmse: 0.1656 - R2: 0.8657 - val_loss: 0.0266 - val_rmse: 0.1476 - val_R2: 0.8921\n",
      "Epoch 33/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0325 - rmse: 0.1640 - R2: 0.8688 - val_loss: 0.0276 - val_rmse: 0.1488 - val_R2: 0.8874\n",
      "Epoch 34/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0321 - rmse: 0.1632 - R2: 0.8706 - val_loss: 0.0263 - val_rmse: 0.1469 - val_R2: 0.8935\n",
      "Epoch 35/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0321 - rmse: 0.1632 - R2: 0.8704 - val_loss: 0.0280 - val_rmse: 0.1496 - val_R2: 0.8865\n",
      "Epoch 36/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0322 - rmse: 0.1633 - R2: 0.8698 - val_loss: 0.0264 - val_rmse: 0.1465 - val_R2: 0.8934\n",
      "Epoch 37/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0320 - rmse: 0.1627 - R2: 0.8707 - val_loss: 0.0259 - val_rmse: 0.1456 - val_R2: 0.8949\n",
      "Epoch 38/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0318 - rmse: 0.1622 - R2: 0.8716 - val_loss: 0.0261 - val_rmse: 0.1461 - val_R2: 0.8938\n",
      "Epoch 39/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0315 - rmse: 0.1616 - R2: 0.8725 - val_loss: 0.0267 - val_rmse: 0.1469 - val_R2: 0.8917\n",
      "Epoch 40/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0312 - rmse: 0.1609 - R2: 0.8738 - val_loss: 0.0266 - val_rmse: 0.1471 - val_R2: 0.8915\n",
      "Epoch 41/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0309 - rmse: 0.1604 - R2: 0.8751 - val_loss: 0.0257 - val_rmse: 0.1446 - val_R2: 0.8953\n",
      "Epoch 42/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0310 - rmse: 0.1603 - R2: 0.8748 - val_loss: 0.0270 - val_rmse: 0.1486 - val_R2: 0.8904\n",
      "Epoch 43/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0309 - rmse: 0.1602 - R2: 0.8750 - val_loss: 0.0271 - val_rmse: 0.1476 - val_R2: 0.8903\n",
      "Epoch 44/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0307 - rmse: 0.1597 - R2: 0.8759 - val_loss: 0.0248 - val_rmse: 0.1431 - val_R2: 0.8996\n",
      "Epoch 45/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0305 - rmse: 0.1592 - R2: 0.8768 - val_loss: 0.0263 - val_rmse: 0.1461 - val_R2: 0.8933\n",
      "Epoch 46/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0302 - rmse: 0.1587 - R2: 0.8779 - val_loss: 0.0256 - val_rmse: 0.1443 - val_R2: 0.8960\n",
      "Epoch 47/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0304 - rmse: 0.1588 - R2: 0.8773 - val_loss: 0.0254 - val_rmse: 0.1439 - val_R2: 0.8957\n",
      "Epoch 48/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0303 - rmse: 0.1587 - R2: 0.8777 - val_loss: 0.0271 - val_rmse: 0.1469 - val_R2: 0.8905\n",
      "Epoch 49/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0301 - rmse: 0.1582 - R2: 0.8783 - val_loss: 0.0257 - val_rmse: 0.1441 - val_R2: 0.8956\n",
      "Epoch 50/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0302 - rmse: 0.1582 - R2: 0.8782 - val_loss: 0.0258 - val_rmse: 0.1441 - val_R2: 0.8947\n",
      "Epoch 51/100\n",
      "76260/76260 [==============================] - 14s 184us/sample - loss: 0.0300 - rmse: 0.1577 - R2: 0.8790 - val_loss: 0.0252 - val_rmse: 0.1430 - val_R2: 0.8962\n",
      "Epoch 52/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0298 - rmse: 0.1574 - R2: 0.8796 - val_loss: 0.0269 - val_rmse: 0.1468 - val_R2: 0.8900\n",
      "Epoch 53/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0295 - rmse: 0.1568 - R2: 0.8806 - val_loss: 0.0261 - val_rmse: 0.1440 - val_R2: 0.8933\n",
      "Epoch 54/100\n",
      "76260/76260 [==============================] - 14s 185us/sample - loss: 0.0297 - rmse: 0.1570 - R2: 0.8800 - val_loss: 0.0252 - val_rmse: 0.1429 - val_R2: 0.8975\n",
      "Epoch 00054: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_baseline.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02536442904505926, 0.14339672, 0.8905086]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = compute_rmse(y_test,y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16194154 0.13497644 0.12880892 0.14495559 0.16120693 0.20821488\n",
      " 0.2171956  0.10638557 0.12369659 0.15653774 0.16296486 0.14184149\n",
      " 0.14496596 0.19481928 0.15752185 0.15270784 0.16652579]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Trained Embedding Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHONETIC_OUTPUT = len(set(z_train))\n",
    "EMBEDDED_FEATURE = 39\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "\n",
    "def embeded_model(input_shape_1,input_shape_2):\n",
    "    inputs = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "    x = pLSTM(EMBEDDED_FEATURE)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(PHONETIC_OUTPUT, activation='softmax', kernel_initializer='he_uniform')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 24, 39)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 24, 39)            12324     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 936)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14)                13118     \n",
      "=================================================================\n",
      "Total params: 25,442\n",
      "Trainable params: 25,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = embeded_model(24, 39)\n",
    "embedded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/100\n",
      "76260/76260 [==============================] - 6s 74us/sample - loss: 2.0143 - accuracy: 0.7720 - val_loss: 1.8802 - val_accuracy: 0.8880\n",
      "Epoch 2/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8968 - accuracy: 0.8678 - val_loss: 1.8532 - val_accuracy: 0.9080\n",
      "Epoch 3/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8734 - accuracy: 0.8886 - val_loss: 1.8419 - val_accuracy: 0.9184\n",
      "Epoch 4/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8600 - accuracy: 0.9009 - val_loss: 1.8391 - val_accuracy: 0.9200\n",
      "Epoch 5/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8515 - accuracy: 0.9089 - val_loss: 1.8316 - val_accuracy: 0.9285\n",
      "Epoch 6/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8445 - accuracy: 0.9155 - val_loss: 1.8294 - val_accuracy: 0.9293\n",
      "Epoch 7/100\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8392 - accuracy: 0.9199 - val_loss: 1.8293 - val_accuracy: 0.9294\n",
      "Epoch 8/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8349 - accuracy: 0.9241 - val_loss: 1.8281 - val_accuracy: 0.9284\n",
      "Epoch 9/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8305 - accuracy: 0.9287 - val_loss: 1.8282 - val_accuracy: 0.9279\n",
      "Epoch 10/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8275 - accuracy: 0.9313 - val_loss: 1.8253 - val_accuracy: 0.9310\n",
      "Epoch 11/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8244 - accuracy: 0.9344 - val_loss: 1.8251 - val_accuracy: 0.9319\n",
      "Epoch 12/100\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8212 - accuracy: 0.9379 - val_loss: 1.8243 - val_accuracy: 0.9312\n",
      "Epoch 13/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8193 - accuracy: 0.9397 - val_loss: 1.8259 - val_accuracy: 0.9313\n",
      "Epoch 14/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8168 - accuracy: 0.9419 - val_loss: 1.8223 - val_accuracy: 0.9339\n",
      "Epoch 15/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.8147 - accuracy: 0.9435 - val_loss: 1.8253 - val_accuracy: 0.9314\n",
      "Epoch 16/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8132 - accuracy: 0.9451 - val_loss: 1.8219 - val_accuracy: 0.9342\n",
      "Epoch 17/100\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8115 - accuracy: 0.9469 - val_loss: 1.8204 - val_accuracy: 0.9364\n",
      "Epoch 18/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8103 - accuracy: 0.9478 - val_loss: 1.8219 - val_accuracy: 0.9334\n",
      "Epoch 19/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8089 - accuracy: 0.9491 - val_loss: 1.8219 - val_accuracy: 0.9333\n",
      "Epoch 20/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8080 - accuracy: 0.9498 - val_loss: 1.8228 - val_accuracy: 0.9319\n",
      "Epoch 21/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8065 - accuracy: 0.9514 - val_loss: 1.8204 - val_accuracy: 0.9353\n",
      "Epoch 22/100\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8059 - accuracy: 0.9520 - val_loss: 1.8190 - val_accuracy: 0.9363\n",
      "Epoch 23/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8045 - accuracy: 0.9531 - val_loss: 1.8186 - val_accuracy: 0.9373\n",
      "Epoch 24/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8039 - accuracy: 0.9538 - val_loss: 1.8211 - val_accuracy: 0.9353\n",
      "Epoch 25/100\n",
      "76260/76260 [==============================] - 3s 44us/sample - loss: 1.8027 - accuracy: 0.9549 - val_loss: 1.8239 - val_accuracy: 0.9312\n",
      "Epoch 26/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8020 - accuracy: 0.9555 - val_loss: 1.8209 - val_accuracy: 0.9352\n",
      "Epoch 27/100\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.8008 - accuracy: 0.9567 - val_loss: 1.8261 - val_accuracy: 0.9299\n",
      "Epoch 28/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.8003 - accuracy: 0.9570 - val_loss: 1.8213 - val_accuracy: 0.9337\n",
      "Epoch 29/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7992 - accuracy: 0.9582 - val_loss: 1.8216 - val_accuracy: 0.9325\n",
      "Epoch 30/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7985 - accuracy: 0.9590 - val_loss: 1.8193 - val_accuracy: 0.9361\n",
      "Epoch 31/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7980 - accuracy: 0.9592 - val_loss: 1.8218 - val_accuracy: 0.9337\n",
      "Epoch 32/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7976 - accuracy: 0.9594 - val_loss: 1.8193 - val_accuracy: 0.9360\n",
      "Epoch 33/100\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.7962 - accuracy: 0.9610 - val_loss: 1.8184 - val_accuracy: 0.9366\n",
      "Epoch 34/100\n",
      "76260/76260 [==============================] - 3s 42us/sample - loss: 1.7956 - accuracy: 0.9613 - val_loss: 1.8193 - val_accuracy: 0.9366\n",
      "Epoch 35/100\n",
      "76260/76260 [==============================] - 3s 42us/sample - loss: 1.7952 - accuracy: 0.9618 - val_loss: 1.8224 - val_accuracy: 0.9332\n",
      "Epoch 36/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7954 - accuracy: 0.9615 - val_loss: 1.8197 - val_accuracy: 0.9350\n",
      "Epoch 37/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7942 - accuracy: 0.9627 - val_loss: 1.8219 - val_accuracy: 0.9339\n",
      "Epoch 38/100\n",
      "76260/76260 [==============================] - 3s 42us/sample - loss: 1.7945 - accuracy: 0.9626 - val_loss: 1.8225 - val_accuracy: 0.9325\n",
      "Epoch 39/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7935 - accuracy: 0.9635 - val_loss: 1.8190 - val_accuracy: 0.9361\n",
      "Epoch 40/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7930 - accuracy: 0.9638 - val_loss: 1.8190 - val_accuracy: 0.9351\n",
      "Epoch 41/100\n",
      "76260/76260 [==============================] - 3s 39us/sample - loss: 1.7920 - accuracy: 0.9647 - val_loss: 1.8248 - val_accuracy: 0.9302\n",
      "Epoch 42/100\n",
      "76260/76260 [==============================] - 3s 40us/sample - loss: 1.7912 - accuracy: 0.9658 - val_loss: 1.8198 - val_accuracy: 0.9365\n",
      "Epoch 43/100\n",
      "76260/76260 [==============================] - 3s 41us/sample - loss: 1.7917 - accuracy: 0.9652 - val_loss: 1.8195 - val_accuracy: 0.9363\n",
      "Epoch 00043: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = embedded.fit(X_train,z_train_oe,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val,z_val_oe),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.save('embedded.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluated Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.93      0.96      0.94       701\n",
      "           9       0.96      0.98      0.97       688\n",
      "           @       0.96      0.94      0.95       635\n",
      "           A       0.94      0.95      0.94       645\n",
      "           E       0.92      0.94      0.93       697\n",
      "          E:       0.94      0.94      0.94       655\n",
      "           O       0.91      0.94      0.92       729\n",
      "           U       0.91      0.89      0.90       687\n",
      "           a       0.95      0.94      0.95       689\n",
      "           e       0.93      0.93      0.93       644\n",
      "           i       0.97      0.92      0.94       684\n",
      "           o       0.95      0.87      0.91       634\n",
      "           u       0.89      0.95      0.92       659\n",
      "           y       0.93      0.92      0.93       591\n",
      "\n",
      "    accuracy                           0.93      9338\n",
      "   macro avg       0.93      0.93      0.93      9338\n",
      "weighted avg       0.93      0.93      0.93      9338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z_pred = embedded.predict(X_test)\n",
    "evaluate_model(z_pred, z_test_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Model with Embedding Feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 24, 39)            12324     \n",
      "=================================================================\n",
      "Total params: 12,324\n",
      "Trainable params: 0\n",
      "Non-trainable params: 12,324\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = tf.keras.models.load_model('embedded.hdf5')\n",
    "\n",
    "embedded_layers = tf.keras.Sequential()\n",
    "for layer in embedded.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "    embedded_layers.add(layer)\n",
    "embedded_layers.summary()\n",
    "\n",
    "N_OUTPUTS = 17\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "pConv1D = partial(Conv1D, padding = 'same', activation = 'linear', kernel_initializer = 'he_uniform')\n",
    "\n",
    "def init_senet_w_emb(feature_layer=1, cnn_unit=64, first_kernel=11, res_unit=64, res_kernel=3,\n",
    "    bilstm = 1, bilstm_unit=256, \n",
    "    dropout_rate=0.3,\n",
    "    reduction_ratio = 2,\n",
    "    activation_fn='relu'):\n",
    "\n",
    "    def cnn_block(input_x, cnn_unit, kernel_size):\n",
    "        x = pConv1D(cnn_unit, kernel_size=kernel_size)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        return x\n",
    "    \n",
    "    def residual_block(input_x):\n",
    "        x = pConv1D(res_unit, kernel_size=res_kernel)(input_x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation_fn)(x)\n",
    "        x = pConv1D(res_unit, kernel_size=res_kernel)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = keras.layers.Add()([x, input_x])\n",
    "        output = Activation(activation_fn)(x)\n",
    "        return output\n",
    "\n",
    "    def se_block(input_x):\n",
    "        x = layers.GlobalAveragePooling1D()(input_x)\n",
    "        channel_shape = getattr(x, '_shape_val')[-1]\n",
    "        x = Reshape((1, channel_shape))(x)\n",
    "        x = Dense(channel_shape // reduction_ratio, activation=activation_fn, kernel_initializer='he_uniform')(x)\n",
    "        x = Dense(channel_shape, activation='tanh', kernel_initializer='he_uniform')(x)\n",
    "        return x\n",
    "\n",
    "    def se_res_block(input_x):\n",
    "        res_x = residual_block(input_x)\n",
    "        se_x = se_block(res_x)\n",
    "        x = layers.Multiply()([res_x, se_x])\n",
    "        return x\n",
    "\n",
    "    def senet_nn(input_shape_1,input_shape_2):\n",
    "\n",
    "        input_x = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "        embedded = embedded_layers(input_x)\n",
    "        x = layers.Concatenate()([input_x, embedded])\n",
    "        x = cnn_block(input_x, cnn_unit, first_kernel)\n",
    "\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(feature_layer):\n",
    "            x = se_res_block(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = cnn_block(x, cnn_unit=cnn_unit, kernel_size=1)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        for i in range(bilstm-1):\n",
    "            x = Bidirectional(pLSTM(bilstm_unit))(x)\n",
    "            x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        x = Bidirectional(pLSTM(bilstm_unit, return_sequences=False))(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "        outputs = Dense(N_OUTPUTS, activation='linear', kernel_initializer='he_uniform')(x)\n",
    "        model = keras.Model(inputs=input_x, outputs=outputs)\n",
    "        return model\n",
    "\n",
    "    return senet_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 24, 39)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 24, 64)       27520       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 24, 64)       256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 64)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 24, 64)       12352       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 24, 64)       256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 64)       0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 24, 64)       12352       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 24, 64)       256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 64)       0           batch_normalization_8[0][0]      \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 24, 64)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 64)           0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 32)        2080        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        2112        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 24, 64)       0           activation_8[0][0]               \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 24, 64)       0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 24, 64)       12352       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 24, 64)       256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 24, 64)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 24, 64)       12352       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 24, 64)       256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 64)       0           batch_normalization_10[0][0]     \n",
      "                                                                 spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 24, 64)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 64)           0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 32)        2080        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 64)        2112        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 24, 64)       0           activation_10[0][0]              \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 24, 64)       0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 24, 64)       4160        spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 24, 64)       256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 24, 64)       0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 24, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 512)          657408      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 17)           8721        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 757,137\n",
      "Trainable params: 756,369\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model = init_senet_w_emb()(24, 39)\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.compile(optimizer='adam',loss='mse',metrics=[rmse, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76260 samples, validate on 9340 samples\n",
      "Epoch 1/100\n",
      "76260/76260 - 22s - loss: 0.1113 - rmse: 0.3109 - R2: 0.5505 - val_loss: 0.0460 - val_rmse: 0.1990 - val_R2: 0.8124\n",
      "Epoch 2/100\n",
      "76260/76260 - 14s - loss: 0.0629 - rmse: 0.2319 - R2: 0.7451 - val_loss: 0.0391 - val_rmse: 0.1801 - val_R2: 0.8426\n",
      "Epoch 3/100\n",
      "76260/76260 - 14s - loss: 0.0544 - rmse: 0.2136 - R2: 0.7800 - val_loss: 0.0354 - val_rmse: 0.1731 - val_R2: 0.8572\n",
      "Epoch 4/100\n",
      "76260/76260 - 14s - loss: 0.0506 - rmse: 0.2055 - R2: 0.7955 - val_loss: 0.0358 - val_rmse: 0.1730 - val_R2: 0.8552\n",
      "Epoch 5/100\n",
      "76260/76260 - 14s - loss: 0.0481 - rmse: 0.2000 - R2: 0.8056 - val_loss: 0.0330 - val_rmse: 0.1668 - val_R2: 0.8668\n",
      "Epoch 6/100\n",
      "76260/76260 - 14s - loss: 0.0462 - rmse: 0.1959 - R2: 0.8131 - val_loss: 0.0317 - val_rmse: 0.1636 - val_R2: 0.8720\n",
      "Epoch 7/100\n",
      "76260/76260 - 14s - loss: 0.0446 - rmse: 0.1925 - R2: 0.8197 - val_loss: 0.0311 - val_rmse: 0.1629 - val_R2: 0.8749\n",
      "Epoch 8/100\n",
      "76260/76260 - 14s - loss: 0.0436 - rmse: 0.1898 - R2: 0.8238 - val_loss: 0.0310 - val_rmse: 0.1615 - val_R2: 0.8748\n",
      "Epoch 9/100\n",
      "76260/76260 - 14s - loss: 0.0423 - rmse: 0.1872 - R2: 0.8288 - val_loss: 0.0315 - val_rmse: 0.1621 - val_R2: 0.8720\n",
      "Epoch 10/100\n",
      "76260/76260 - 14s - loss: 0.0416 - rmse: 0.1854 - R2: 0.8315 - val_loss: 0.0291 - val_rmse: 0.1571 - val_R2: 0.8821\n",
      "Epoch 11/100\n",
      "76260/76260 - 14s - loss: 0.0407 - rmse: 0.1833 - R2: 0.8354 - val_loss: 0.0298 - val_rmse: 0.1580 - val_R2: 0.8787\n",
      "Epoch 12/100\n",
      "76260/76260 - 14s - loss: 0.0398 - rmse: 0.1814 - R2: 0.8390 - val_loss: 0.0284 - val_rmse: 0.1544 - val_R2: 0.8849\n",
      "Epoch 13/100\n",
      "76260/76260 - 14s - loss: 0.0392 - rmse: 0.1799 - R2: 0.8415 - val_loss: 0.0279 - val_rmse: 0.1534 - val_R2: 0.8874\n",
      "Epoch 14/100\n",
      "76260/76260 - 14s - loss: 0.0385 - rmse: 0.1783 - R2: 0.8443 - val_loss: 0.0279 - val_rmse: 0.1537 - val_R2: 0.8869\n",
      "Epoch 15/100\n",
      "76260/76260 - 14s - loss: 0.0384 - rmse: 0.1779 - R2: 0.8447 - val_loss: 0.0284 - val_rmse: 0.1547 - val_R2: 0.8839\n",
      "Epoch 16/100\n",
      "76260/76260 - 14s - loss: 0.0376 - rmse: 0.1762 - R2: 0.8479 - val_loss: 0.0278 - val_rmse: 0.1528 - val_R2: 0.8874\n",
      "Epoch 17/100\n",
      "76260/76260 - 14s - loss: 0.0370 - rmse: 0.1747 - R2: 0.8504 - val_loss: 0.0279 - val_rmse: 0.1529 - val_R2: 0.8865\n",
      "Epoch 18/100\n",
      "76260/76260 - 14s - loss: 0.0366 - rmse: 0.1739 - R2: 0.8519 - val_loss: 0.0280 - val_rmse: 0.1523 - val_R2: 0.8860\n",
      "Epoch 19/100\n",
      "76260/76260 - 14s - loss: 0.0365 - rmse: 0.1735 - R2: 0.8527 - val_loss: 0.0274 - val_rmse: 0.1516 - val_R2: 0.8892\n",
      "Epoch 20/100\n",
      "76260/76260 - 14s - loss: 0.0361 - rmse: 0.1726 - R2: 0.8540 - val_loss: 0.0270 - val_rmse: 0.1498 - val_R2: 0.8911\n",
      "Epoch 21/100\n",
      "76260/76260 - 14s - loss: 0.0356 - rmse: 0.1717 - R2: 0.8559 - val_loss: 0.0282 - val_rmse: 0.1529 - val_R2: 0.8853\n",
      "Epoch 22/100\n",
      "76260/76260 - 14s - loss: 0.0352 - rmse: 0.1706 - R2: 0.8574 - val_loss: 0.0272 - val_rmse: 0.1501 - val_R2: 0.8900\n",
      "Epoch 23/100\n",
      "76260/76260 - 14s - loss: 0.0345 - rmse: 0.1691 - R2: 0.8605 - val_loss: 0.0271 - val_rmse: 0.1507 - val_R2: 0.8900\n",
      "Epoch 24/100\n",
      "76260/76260 - 14s - loss: 0.0352 - rmse: 0.1703 - R2: 0.8577 - val_loss: 0.0269 - val_rmse: 0.1494 - val_R2: 0.8903\n",
      "Epoch 25/100\n",
      "76260/76260 - 14s - loss: 0.0342 - rmse: 0.1681 - R2: 0.8617 - val_loss: 0.0265 - val_rmse: 0.1481 - val_R2: 0.8915\n",
      "Epoch 26/100\n",
      "76260/76260 - 14s - loss: 0.0340 - rmse: 0.1679 - R2: 0.8627 - val_loss: 0.0256 - val_rmse: 0.1469 - val_R2: 0.8959\n",
      "Epoch 27/100\n",
      "76260/76260 - 14s - loss: 0.0339 - rmse: 0.1674 - R2: 0.8630 - val_loss: 0.0263 - val_rmse: 0.1472 - val_R2: 0.8922\n",
      "Epoch 28/100\n",
      "76260/76260 - 14s - loss: 0.0335 - rmse: 0.1666 - R2: 0.8643 - val_loss: 0.0270 - val_rmse: 0.1486 - val_R2: 0.8900\n",
      "Epoch 29/100\n",
      "76260/76260 - 14s - loss: 0.0332 - rmse: 0.1661 - R2: 0.8654 - val_loss: 0.0263 - val_rmse: 0.1468 - val_R2: 0.8932\n",
      "Epoch 30/100\n",
      "76260/76260 - 14s - loss: 0.0330 - rmse: 0.1655 - R2: 0.8662 - val_loss: 0.0271 - val_rmse: 0.1496 - val_R2: 0.8904\n",
      "Epoch 31/100\n",
      "76260/76260 - 14s - loss: 0.0330 - rmse: 0.1654 - R2: 0.8663 - val_loss: 0.0267 - val_rmse: 0.1470 - val_R2: 0.8907\n",
      "Epoch 32/100\n",
      "76260/76260 - 14s - loss: 0.0330 - rmse: 0.1652 - R2: 0.8665 - val_loss: 0.0252 - val_rmse: 0.1445 - val_R2: 0.8980\n",
      "Epoch 33/100\n",
      "76260/76260 - 14s - loss: 0.0323 - rmse: 0.1638 - R2: 0.8692 - val_loss: 0.0262 - val_rmse: 0.1468 - val_R2: 0.8936\n",
      "Epoch 34/100\n",
      "76260/76260 - 14s - loss: 0.0325 - rmse: 0.1641 - R2: 0.8686 - val_loss: 0.0251 - val_rmse: 0.1443 - val_R2: 0.8984\n",
      "Epoch 35/100\n",
      "76260/76260 - 14s - loss: 0.0324 - rmse: 0.1638 - R2: 0.8690 - val_loss: 0.0250 - val_rmse: 0.1433 - val_R2: 0.8984\n",
      "Epoch 36/100\n",
      "76260/76260 - 14s - loss: 0.0321 - rmse: 0.1631 - R2: 0.8700 - val_loss: 0.0256 - val_rmse: 0.1455 - val_R2: 0.8958\n",
      "Epoch 37/100\n",
      "76260/76260 - 14s - loss: 0.0319 - rmse: 0.1626 - R2: 0.8713 - val_loss: 0.0253 - val_rmse: 0.1450 - val_R2: 0.8971\n",
      "Epoch 38/100\n",
      "76260/76260 - 14s - loss: 0.0317 - rmse: 0.1623 - R2: 0.8716 - val_loss: 0.0245 - val_rmse: 0.1424 - val_R2: 0.9006\n",
      "Epoch 39/100\n",
      "76260/76260 - 14s - loss: 0.0314 - rmse: 0.1615 - R2: 0.8730 - val_loss: 0.0245 - val_rmse: 0.1427 - val_R2: 0.9000\n",
      "Epoch 40/100\n",
      "76260/76260 - 14s - loss: 0.0315 - rmse: 0.1617 - R2: 0.8728 - val_loss: 0.0266 - val_rmse: 0.1477 - val_R2: 0.8923\n",
      "Epoch 41/100\n",
      "76260/76260 - 14s - loss: 0.0313 - rmse: 0.1611 - R2: 0.8735 - val_loss: 0.0254 - val_rmse: 0.1440 - val_R2: 0.8968\n",
      "Epoch 42/100\n",
      "76260/76260 - 14s - loss: 0.0310 - rmse: 0.1607 - R2: 0.8745 - val_loss: 0.0243 - val_rmse: 0.1433 - val_R2: 0.9014\n",
      "Epoch 43/100\n",
      "76260/76260 - 14s - loss: 0.0310 - rmse: 0.1605 - R2: 0.8747 - val_loss: 0.0250 - val_rmse: 0.1438 - val_R2: 0.8981\n",
      "Epoch 44/100\n",
      "76260/76260 - 14s - loss: 0.0306 - rmse: 0.1596 - R2: 0.8763 - val_loss: 0.0239 - val_rmse: 0.1416 - val_R2: 0.9025\n",
      "Epoch 45/100\n",
      "76260/76260 - 14s - loss: 0.0306 - rmse: 0.1597 - R2: 0.8760 - val_loss: 0.0250 - val_rmse: 0.1441 - val_R2: 0.8977\n",
      "Epoch 46/100\n",
      "76260/76260 - 14s - loss: 0.0302 - rmse: 0.1588 - R2: 0.8779 - val_loss: 0.0247 - val_rmse: 0.1424 - val_R2: 0.8997\n",
      "Epoch 47/100\n",
      "76260/76260 - 14s - loss: 0.0302 - rmse: 0.1587 - R2: 0.8777 - val_loss: 0.0244 - val_rmse: 0.1419 - val_R2: 0.9008\n",
      "Epoch 48/100\n",
      "76260/76260 - 14s - loss: 0.0301 - rmse: 0.1584 - R2: 0.8784 - val_loss: 0.0244 - val_rmse: 0.1422 - val_R2: 0.9010\n",
      "Epoch 49/100\n",
      "76260/76260 - 14s - loss: 0.0301 - rmse: 0.1583 - R2: 0.8783 - val_loss: 0.0242 - val_rmse: 0.1414 - val_R2: 0.9009\n",
      "Epoch 50/100\n",
      "76260/76260 - 14s - loss: 0.0299 - rmse: 0.1578 - R2: 0.8790 - val_loss: 0.0238 - val_rmse: 0.1408 - val_R2: 0.9032\n",
      "Epoch 51/100\n",
      "76260/76260 - 14s - loss: 0.0298 - rmse: 0.1576 - R2: 0.8794 - val_loss: 0.0252 - val_rmse: 0.1436 - val_R2: 0.8961\n",
      "Epoch 52/100\n",
      "76260/76260 - 14s - loss: 0.0299 - rmse: 0.1578 - R2: 0.8792 - val_loss: 0.0250 - val_rmse: 0.1431 - val_R2: 0.8981\n",
      "Epoch 53/100\n",
      "76260/76260 - 14s - loss: 0.0296 - rmse: 0.1571 - R2: 0.8803 - val_loss: 0.0245 - val_rmse: 0.1415 - val_R2: 0.9005\n",
      "Epoch 54/100\n",
      "76260/76260 - 14s - loss: 0.0296 - rmse: 0.1571 - R2: 0.8804 - val_loss: 0.0245 - val_rmse: 0.1425 - val_R2: 0.9002\n",
      "Epoch 55/100\n",
      "76260/76260 - 14s - loss: 0.0296 - rmse: 0.1570 - R2: 0.8804 - val_loss: 0.0240 - val_rmse: 0.1408 - val_R2: 0.9026\n",
      "Epoch 56/100\n",
      "76260/76260 - 14s - loss: 0.0293 - rmse: 0.1565 - R2: 0.8814 - val_loss: 0.0242 - val_rmse: 0.1415 - val_R2: 0.9010\n",
      "Epoch 57/100\n",
      "76260/76260 - 14s - loss: 0.0292 - rmse: 0.1562 - R2: 0.8818 - val_loss: 0.0241 - val_rmse: 0.1410 - val_R2: 0.9014\n",
      "Epoch 58/100\n",
      "76260/76260 - 14s - loss: 0.0291 - rmse: 0.1559 - R2: 0.8824 - val_loss: 0.0238 - val_rmse: 0.1399 - val_R2: 0.9029\n",
      "Epoch 59/100\n",
      "76260/76260 - 14s - loss: 0.0292 - rmse: 0.1559 - R2: 0.8822 - val_loss: 0.0238 - val_rmse: 0.1402 - val_R2: 0.9026\n",
      "Epoch 60/100\n",
      "76260/76260 - 14s - loss: 0.0290 - rmse: 0.1557 - R2: 0.8825 - val_loss: 0.0249 - val_rmse: 0.1420 - val_R2: 0.8984\n",
      "Epoch 00060: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = emb_model.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_data=(X_val,y_val),\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model.save('model_with_embedded.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = tf.keras.models.load_model('model_with_embedded.hdf5', custom_objects={'rmse': rmse, 'R2':R2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025251392964461192, 0.14263831, 0.8890895]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = emb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check error by each data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = compute_rmse(y_test,y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16194154 0.13497644 0.12880892 0.14495559 0.16120693 0.20821488\n",
      " 0.2171956  0.10638557 0.12369659 0.15653774 0.16296486 0.14184149\n",
      " 0.14496596 0.19481928 0.15752185 0.15270784 0.16652579]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rank by highest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df = pd.DataFrame({'phonetic':z_test, 'err':errs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U</td>\n",
       "      <td>0.119356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>0.291823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>0.151927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>0.070151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "      <td>0.127706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  phonetic       err\n",
       "0        U  0.119356\n",
       "1        O  0.291823\n",
       "2        O  0.151927\n",
       "3        U  0.070151\n",
       "4        i  0.127706"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>a</td>\n",
       "      <td>0.032212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>E</td>\n",
       "      <td>0.034436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5071</th>\n",
       "      <td>A</td>\n",
       "      <td>0.034988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>a</td>\n",
       "      <td>0.036122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>A</td>\n",
       "      <td>0.038854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>E</td>\n",
       "      <td>0.625002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>U</td>\n",
       "      <td>0.632457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>U</td>\n",
       "      <td>0.635934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>U</td>\n",
       "      <td>0.653842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>e</td>\n",
       "      <td>0.709113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9338 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     phonetic       err\n",
       "8035        a  0.032212\n",
       "9318        E  0.034436\n",
       "5071        A  0.034988\n",
       "1258        a  0.036122\n",
       "487         A  0.038854\n",
       "...       ...       ...\n",
       "6036        E  0.625002\n",
       "3950        U  0.632457\n",
       "5687        U  0.635934\n",
       "89          U  0.653842\n",
       "5226        e  0.709113\n",
       "\n",
       "[9338 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df.sort_values('err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001D4333FD908>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_df.hist('err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df_high = err_df[err_df['err'] > 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonetic</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "      <td>0.291823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>0.151927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y</td>\n",
       "      <td>0.160038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i</td>\n",
       "      <td>0.183955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>0.205061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  phonetic       err\n",
       "1        O  0.291823\n",
       "2        O  0.151927\n",
       "5        y  0.160038\n",
       "6        i  0.183955\n",
       "8        i  0.205061"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df_high.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d4337396a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_df[err_df['err'] > 0.5].groupby('phonetic')['phonetic'].count().sort_values(ascending=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phonetic\n",
       "2     100\n",
       "9     179\n",
       "@     212\n",
       "A      97\n",
       "E     225\n",
       "E:    191\n",
       "O     215\n",
       "U     140\n",
       "a     210\n",
       "e     238\n",
       "i     329\n",
       "o     192\n",
       "u     252\n",
       "y     159\n",
       "Name: phonetic, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_df_high.groupby('phonetic')['phonetic'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate each param of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = compute_se(y_test,y_pred)\n",
    "errs = compute_rmse(y_test,y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se = pd.DataFrame(se, columns=[\"HX\",\"HY\",\"JA\",\"LP\",\"LD\",\"VS\",\"VO\",\"TCX\",\"TCY\",\"TTX\",\"TTY\",\"TBX\",\"TBY\",\"TS1\",\"TS2\",\"TS3\",\"TS4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se['phonetic'] = z_test\n",
    "df_se['mean_err'] = errs\n",
    "df_se['audio'] = a_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HX</th>\n",
       "      <th>HY</th>\n",
       "      <th>JA</th>\n",
       "      <th>LP</th>\n",
       "      <th>LD</th>\n",
       "      <th>VS</th>\n",
       "      <th>VO</th>\n",
       "      <th>TCX</th>\n",
       "      <th>TCY</th>\n",
       "      <th>TTX</th>\n",
       "      <th>TTY</th>\n",
       "      <th>TBX</th>\n",
       "      <th>TBY</th>\n",
       "      <th>TS1</th>\n",
       "      <th>TS2</th>\n",
       "      <th>TS3</th>\n",
       "      <th>TS4</th>\n",
       "      <th>phonetic</th>\n",
       "      <th>mean_err</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106796</td>\n",
       "      <td>0.156995</td>\n",
       "      <td>0.020267</td>\n",
       "      <td>0.048870</td>\n",
       "      <td>0.121968</td>\n",
       "      <td>0.022292</td>\n",
       "      <td>0.396976</td>\n",
       "      <td>0.047706</td>\n",
       "      <td>0.091172</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.088316</td>\n",
       "      <td>0.071373</td>\n",
       "      <td>0.039106</td>\n",
       "      <td>0.038163</td>\n",
       "      <td>0.027247</td>\n",
       "      <td>0.034178</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>U</td>\n",
       "      <td>0.119356</td>\n",
       "      <td>[-0.0036667322, -0.0067870035, -0.009936802, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.276770</td>\n",
       "      <td>0.176993</td>\n",
       "      <td>0.170226</td>\n",
       "      <td>0.393636</td>\n",
       "      <td>0.294811</td>\n",
       "      <td>0.294975</td>\n",
       "      <td>0.082096</td>\n",
       "      <td>0.155937</td>\n",
       "      <td>0.267452</td>\n",
       "      <td>0.098560</td>\n",
       "      <td>0.278880</td>\n",
       "      <td>0.303437</td>\n",
       "      <td>0.365536</td>\n",
       "      <td>0.329519</td>\n",
       "      <td>0.494084</td>\n",
       "      <td>0.189483</td>\n",
       "      <td>O</td>\n",
       "      <td>0.291823</td>\n",
       "      <td>[-0.0077388003, -0.011906635, -0.15257795, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043133</td>\n",
       "      <td>0.091274</td>\n",
       "      <td>0.038767</td>\n",
       "      <td>0.126134</td>\n",
       "      <td>0.178741</td>\n",
       "      <td>0.215122</td>\n",
       "      <td>0.262871</td>\n",
       "      <td>0.189747</td>\n",
       "      <td>0.296608</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>0.170243</td>\n",
       "      <td>0.198044</td>\n",
       "      <td>0.041915</td>\n",
       "      <td>0.063391</td>\n",
       "      <td>0.088560</td>\n",
       "      <td>O</td>\n",
       "      <td>0.151927</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.108815</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.022134</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>0.076508</td>\n",
       "      <td>0.083298</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.071705</td>\n",
       "      <td>0.058917</td>\n",
       "      <td>0.106762</td>\n",
       "      <td>0.062005</td>\n",
       "      <td>0.095641</td>\n",
       "      <td>0.107754</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.097788</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>U</td>\n",
       "      <td>0.070151</td>\n",
       "      <td>[0.026149532, 0.034463353, 0.037094187, 0.0368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.072459</td>\n",
       "      <td>0.099061</td>\n",
       "      <td>0.170661</td>\n",
       "      <td>0.166349</td>\n",
       "      <td>0.187937</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.170254</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.030086</td>\n",
       "      <td>0.026878</td>\n",
       "      <td>0.119259</td>\n",
       "      <td>0.105838</td>\n",
       "      <td>0.060074</td>\n",
       "      <td>0.059379</td>\n",
       "      <td>0.099471</td>\n",
       "      <td>0.117612</td>\n",
       "      <td>0.288087</td>\n",
       "      <td>i</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>[-0.021888198, -0.033991054, -0.042626306, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HX        HY        JA        LP        LD        VS        VO  \\\n",
       "0  0.106796  0.156995  0.020267  0.048870  0.121968  0.022292  0.396976   \n",
       "1  0.421400  0.276770  0.176993  0.170226  0.393636  0.294811  0.294975   \n",
       "2  0.043133  0.091274  0.038767  0.126134  0.178741  0.215122  0.262871   \n",
       "3  0.108815  0.011169  0.028320  0.022134  0.019730  0.076508  0.083298   \n",
       "4  0.072459  0.099061  0.170661  0.166349  0.187937  0.010204  0.170254   \n",
       "\n",
       "        TCX       TCY       TTX       TTY       TBX       TBY       TS1  \\\n",
       "0  0.047706  0.091172  0.034469  0.088316  0.071373  0.039106  0.038163   \n",
       "1  0.082096  0.155937  0.267452  0.098560  0.278880  0.303437  0.365536   \n",
       "2  0.189747  0.296608  0.004877  0.107300  0.011007  0.170243  0.198044   \n",
       "3  0.005115  0.071705  0.058917  0.106762  0.062005  0.095641  0.107754   \n",
       "4  0.008540  0.030086  0.026878  0.119259  0.105838  0.060074  0.059379   \n",
       "\n",
       "        TS2       TS3       TS4 phonetic  mean_err  \\\n",
       "0  0.027247  0.034178  0.028261        U  0.119356   \n",
       "1  0.329519  0.494084  0.189483        O  0.291823   \n",
       "2  0.041915  0.063391  0.088560        O  0.151927   \n",
       "3  0.054902  0.097788  0.001995        U  0.070151   \n",
       "4  0.099471  0.117612  0.288087        i  0.127706   \n",
       "\n",
       "                                               audio  \n",
       "0  [-0.0036667322, -0.0067870035, -0.009936802, -...  \n",
       "1  [-0.0077388003, -0.011906635, -0.15257795, -0....  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.026149532, 0.034463353, 0.037094187, 0.0368...  \n",
       "4  [-0.021888198, -0.033991054, -0.042626306, -0....  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-38ad2d03395b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'phonetic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'7'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_se\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_err'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TS4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(self, by, bins, **kwargs)\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \"\"\"\n\u001b[1;32m-> 1125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"hist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ax\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left_ax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;31m# no non-numeric frames or series allowed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no numeric data to plot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;31m# GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "df_se[(df_se['phonetic'] == '7') & (df_se['mean_err'] > 0.5)]['TS4'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA audio of testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort = df_se.sort_values('mean_err',ascending=False)\n",
    "df_se_sort.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort[df_se_sort['phonetic'] == '&'].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(df_se_sort['audio'][0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se_sort[df_se_sort['phonetic'] == '&'].tail(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(df_se_sort['audio'][12073], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
