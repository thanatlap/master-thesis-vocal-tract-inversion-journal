{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained Vowel Classfication From Speech\n",
    "- created: 13 Apr 2020 </br>\n",
    "To detect the error in an inversion data because the formant cannot be used to compare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from joblib import dump, load\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil \n",
    "import argparse\n",
    "from functools import partial\n",
    "import pickle\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Reshape, GRU, InputLayer, AlphaDropout, Activation, BatchNormalization, Dropout, Flatten, Dense, Bidirectional, LSTM, Conv1D, SpatialDropout1D, Concatenate, Multiply, Add\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = partial(np.load)\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data_dir,prep_folder):\n",
    "\n",
    "    features = np.load(join(data_dir,prep_folder,'features.npy'))\n",
    "    \n",
    "    with open(join(data_dir,'syllable_name.txt')) as f:\n",
    "        label = np.array([char for line in f for word in line.split(',') for char in word.strip()])\n",
    "        \n",
    "    print('Predict Data {} {}'.format(features.shape, label.shape))\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, label):\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    label = enc.inverse_transform(label)\n",
    "#     print('Confusion Matrix')\n",
    "    print(confusion_matrix(label, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(label, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (3078, 23, 39) (3078,)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/d_records/record_total_data/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7', 'E', 'M', 'O', 'a', 'e', 'i', 'o', 'u'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3078,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=label.reshape(-1,1)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(label)\n",
    "\n",
    "label_oe = enc.transform(label).toarray()\n",
    "\n",
    "# dump(enc, 'onehot_pred.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label_oe, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined (Between) Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHONETIC_OUTPUT = len(['7', 'E', 'M', 'O', 'a', 'e', 'i', 'o', 'u'])\n",
    "EMBEDDED_FEATURE = 64\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "\n",
    "def embeded_model(input_shape_1,input_shape_2):\n",
    "    inputs = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "    x = pLSTM(EMBEDDED_FEATURE)(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = pLSTM(EMBEDDED_FEATURE, return_sequences=False)(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    outputs = Dense(PHONETIC_OUTPUT, activation='softmax', kernel_initializer='he_uniform')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 23, 39)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 23, 64)            26624     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 60,233\n",
      "Trainable params: 60,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = embeded_model(23, 39)\n",
    "embedded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 15\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def permutation_test(X_train, y_train, X_test, y_test, nsamples=10):\n",
    "    idx1 = np.arange(X_train.shape[0])\n",
    "    idx2 = np.arange(X_test.shape[0])\n",
    "    auc_values = np.empty(nsamples)\n",
    "    for b in range(nsamples):\n",
    "        np.random.shuffle(idx1)  # Shuffles in-place\n",
    "        np.random.shuffle(idx2)\n",
    "        embedded = embeded_model(23, 39)\n",
    "        embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "        embedded.fit(X_train, y_train[idx1], batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0, validation_split=0.2, callbacks=callback_list)\n",
    "        pred = embedded.predict(X_test)\n",
    "#         print(pred)\n",
    "        roc_auc = roc_auc_score(y_test[idx2].ravel(), pred.ravel())\n",
    "        auc_values[b] = roc_auc\n",
    "        print('Round {}'.format(b))\n",
    "    embedded = embeded_model(23, 39)\n",
    "    embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "    embedded.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0, validation_split=0.2, callbacks=callback_list)\n",
    "    pred = embedded.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test.ravel(), pred.ravel())\n",
    "    return roc_auc, np.mean(auc_values >= roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "Round 1\n",
      "Round 2\n",
      "Round 3\n",
      "Round 4\n",
      "Round 5\n",
      "Round 6\n",
      "Round 7\n",
      "Round 8\n",
      "Round 9\n"
     ]
    }
   ],
   "source": [
    "auc, mean = permutation_test(X_train, y_train, X_test, y_test, nsamples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975454993464328"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_auc( X_train, y_train, X_test, y_test, nsamples=1000):\n",
    "    auc_values = []\n",
    "    for b in range(nsamples):\n",
    "        idx = np.random.randint(X_train.shape[0], size=X_train.shape[0])\n",
    "        embedded = embeded_model(23, 39)\n",
    "        embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "        embedded.fit(X_train[idx], y_train[idx], batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0, validation_split=0.2, callbacks=callback_list)\n",
    "        pred = embedded.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_test.ravel(), pred.ravel())\n",
    "        auc_values.append(roc_auc)\n",
    "        print('Round {}'.format(b))\n",
    "    return np.percentile(auc_values, (2.5, 97.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_result = bootstrap_auc(X_train, y_train, X_test, y_test, nsamples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98647867, 0.99530752])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedded.save('pred_vowel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71  4  1  1  0  2  0  0  0]\n",
      " [ 1 70  0  0  0  1  0  0  0]\n",
      " [ 0  0 58  0  0  2  1  0  0]\n",
      " [ 0  0  0 73  0  0  0  1  0]\n",
      " [ 0  0  0  1 53  0  0  0  0]\n",
      " [ 0  0  0  0  0 64  3  0  0]\n",
      " [ 0  0  0  0  0  1 66  0  0]\n",
      " [ 0  0  0  0  0  0  0 64  1]\n",
      " [ 0  0  0  0  0  0  1  2 74]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.99      0.90      0.94        79\n",
      "           E       0.95      0.97      0.96        72\n",
      "           M       0.98      0.95      0.97        61\n",
      "           O       0.97      0.99      0.98        74\n",
      "           a       1.00      0.98      0.99        54\n",
      "           e       0.91      0.96      0.93        67\n",
      "           i       0.93      0.99      0.96        67\n",
      "           o       0.96      0.98      0.97        65\n",
      "           u       0.99      0.96      0.97        77\n",
      "\n",
      "    accuracy                           0.96       616\n",
      "   macro avg       0.96      0.96      0.96       616\n",
      "weighted avg       0.96      0.96      0.96       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = embedded.predict(X_test)\n",
    "evaluate_model(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embeded_model(23, 39)\n",
    "embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "history = embedded.fit(features,label_oe,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.save('pred_vowel_all_data.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = models.load_model('pred_vowel_all_data.hdf5')\n",
    "enc = load('onehot_pred.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 31\n",
    "- BiLSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[177  16  16   0   0   5   1   1   0]\n",
      " [  6 196   1   0   5   8   0   0   0]\n",
      " [  2   1 164   0   0  29  18   0   2]\n",
      " [  2   6   2 163  29   0   0  14   0]\n",
      " [  1  10   4  12 188   1   0   0   0]\n",
      " [  0   2   2   0   0 211   1   0   0]\n",
      " [  0   0   6   0   0  10 197   0   3]\n",
      " [ 10   2   1   7   0   5   0 145  46]\n",
      " [  4   2  20   0   0   5  15  12 158]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.88      0.82      0.85       216\n",
      "           E       0.83      0.91      0.87       216\n",
      "           M       0.76      0.76      0.76       216\n",
      "           O       0.90      0.75      0.82       216\n",
      "           a       0.85      0.87      0.86       216\n",
      "           e       0.77      0.98      0.86       216\n",
      "           i       0.85      0.91      0.88       216\n",
      "           o       0.84      0.67      0.75       216\n",
      "           u       0.76      0.73      0.74       216\n",
      "\n",
      "    accuracy                           0.82      1944\n",
      "   macro avg       0.83      0.82      0.82      1944\n",
      "weighted avg       0.83      0.82      0.82      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_31/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8255784132730615 Recall: 0.8225308641975309 AUC: 0.951728252171925\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='macro')\n",
    "recall = recall_score(class_actual, class_pred, average='macro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
