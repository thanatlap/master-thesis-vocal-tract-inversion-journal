{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained Vowel Classfication From Speech\n",
    "- created: 13 Apr 2020 </br>\n",
    "To detect the error in an inversion data because the formant cannot be used to compare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from joblib import dump, load\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil \n",
    "import argparse\n",
    "from functools import partial\n",
    "import pickle\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Reshape, GRU, InputLayer, AlphaDropout, Activation, BatchNormalization, Dropout, Flatten, Dense, Bidirectional, LSTM, Conv1D, SpatialDropout1D, Concatenate, Multiply, Add\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = partial(np.load)\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data_dir,prep_folder):\n",
    "\n",
    "    features = np.load(join(data_dir,prep_folder,'features.npy'))\n",
    "    \n",
    "    with open(join(data_dir,'syllable_name.txt')) as f:\n",
    "        label = np.array([char for line in f for word in line.split(',') for char in word.strip()])\n",
    "        \n",
    "    print('Predict Data {} {}'.format(features.shape, label.shape))\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, label):\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    label = enc.inverse_transform(label)\n",
    "#     print('Confusion Matrix')\n",
    "    print(confusion_matrix(label, y_pred))\n",
    "    print('Classification Report')\n",
    "    print(classification_report(label, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (3078, 23, 39) (3078,)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/d_records/record_total_data/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7', 'E', 'M', 'O', 'a', 'e', 'i', 'o', 'u'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3078,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=label.reshape(-1,1)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore')\n",
    "enc.fit(label)\n",
    "\n",
    "label_oe = enc.transform(label).toarray()\n",
    "\n",
    "# dump(enc, 'onehot_pred.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label_oe, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined (Between) Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHONETIC_OUTPUT = len(['7', 'E', 'M', 'O', 'a', 'e', 'i', 'o', 'u'])\n",
    "EMBEDDED_FEATURE = 64\n",
    "\n",
    "pLSTM = partial(LSTM, kernel_initializer='he_uniform', return_sequences=True)\n",
    "\n",
    "def embeded_model(input_shape_1,input_shape_2):\n",
    "    inputs = keras.Input(shape=(input_shape_1,input_shape_2))\n",
    "    x = pLSTM(EMBEDDED_FEATURE)(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = pLSTM(EMBEDDED_FEATURE, return_sequences=False)(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    outputs = Dense(PHONETIC_OUTPUT, activation='softmax', kernel_initializer='he_uniform')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 23, 39)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 23, 64)            26624     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 60,233\n",
      "Trainable params: 60,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded = embeded_model(23, 39)\n",
    "embedded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 15\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=PATIENCE, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
    "callback_list = [early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1969 samples, validate on 493 samples\n",
      "Epoch 1/200\n",
      "1969/1969 - 4s - loss: 2.1652 - accuracy: 0.2331 - val_loss: 2.0904 - val_accuracy: 0.5132\n",
      "Epoch 2/200\n",
      "1969/1969 - 0s - loss: 2.0553 - accuracy: 0.4794 - val_loss: 1.9252 - val_accuracy: 0.6795\n",
      "Epoch 3/200\n",
      "1969/1969 - 0s - loss: 1.9155 - accuracy: 0.6369 - val_loss: 1.7628 - val_accuracy: 0.7688\n",
      "Epoch 4/200\n",
      "1969/1969 - 0s - loss: 1.7694 - accuracy: 0.7669 - val_loss: 1.6248 - val_accuracy: 0.8641\n",
      "Epoch 5/200\n",
      "1969/1969 - 0s - loss: 1.6480 - accuracy: 0.8532 - val_loss: 1.5439 - val_accuracy: 0.8783\n",
      "Epoch 6/200\n",
      "1969/1969 - 0s - loss: 1.5547 - accuracy: 0.9035 - val_loss: 1.5035 - val_accuracy: 0.8945\n",
      "Epoch 7/200\n",
      "1969/1969 - 0s - loss: 1.5017 - accuracy: 0.9253 - val_loss: 1.4857 - val_accuracy: 0.9026\n",
      "Epoch 8/200\n",
      "1969/1969 - 0s - loss: 1.4768 - accuracy: 0.9375 - val_loss: 1.4724 - val_accuracy: 0.9108\n",
      "Epoch 9/200\n",
      "1969/1969 - 0s - loss: 1.4576 - accuracy: 0.9436 - val_loss: 1.4667 - val_accuracy: 0.9087\n",
      "Epoch 10/200\n",
      "1969/1969 - 0s - loss: 1.4475 - accuracy: 0.9528 - val_loss: 1.4515 - val_accuracy: 0.9249\n",
      "Epoch 11/200\n",
      "1969/1969 - 0s - loss: 1.4358 - accuracy: 0.9573 - val_loss: 1.4574 - val_accuracy: 0.9128\n",
      "Epoch 12/200\n",
      "1969/1969 - 0s - loss: 1.4235 - accuracy: 0.9665 - val_loss: 1.4421 - val_accuracy: 0.9331\n",
      "Epoch 13/200\n",
      "1969/1969 - 0s - loss: 1.4190 - accuracy: 0.9705 - val_loss: 1.4337 - val_accuracy: 0.9432\n",
      "Epoch 14/200\n",
      "1969/1969 - 0s - loss: 1.4096 - accuracy: 0.9761 - val_loss: 1.4362 - val_accuracy: 0.9412\n",
      "Epoch 15/200\n",
      "1969/1969 - 0s - loss: 1.4028 - accuracy: 0.9827 - val_loss: 1.4349 - val_accuracy: 0.9391\n",
      "Epoch 16/200\n",
      "1969/1969 - 0s - loss: 1.4024 - accuracy: 0.9797 - val_loss: 1.4328 - val_accuracy: 0.9432\n",
      "Epoch 17/200\n",
      "1969/1969 - 0s - loss: 1.4003 - accuracy: 0.9822 - val_loss: 1.4307 - val_accuracy: 0.9452\n",
      "Epoch 18/200\n",
      "1969/1969 - 0s - loss: 1.3973 - accuracy: 0.9832 - val_loss: 1.4301 - val_accuracy: 0.9412\n",
      "Epoch 19/200\n",
      "1969/1969 - 0s - loss: 1.3935 - accuracy: 0.9878 - val_loss: 1.4305 - val_accuracy: 0.9432\n",
      "Epoch 20/200\n",
      "1969/1969 - 0s - loss: 1.3929 - accuracy: 0.9868 - val_loss: 1.4269 - val_accuracy: 0.9452\n",
      "Epoch 21/200\n",
      "1969/1969 - 0s - loss: 1.3922 - accuracy: 0.9883 - val_loss: 1.4264 - val_accuracy: 0.9452\n",
      "Epoch 22/200\n",
      "1969/1969 - 0s - loss: 1.3888 - accuracy: 0.9909 - val_loss: 1.4261 - val_accuracy: 0.9473\n",
      "Epoch 23/200\n",
      "1969/1969 - 0s - loss: 1.3886 - accuracy: 0.9904 - val_loss: 1.4252 - val_accuracy: 0.9513\n",
      "Epoch 24/200\n",
      "1969/1969 - 0s - loss: 1.3871 - accuracy: 0.9898 - val_loss: 1.4269 - val_accuracy: 0.9432\n",
      "Epoch 25/200\n",
      "1969/1969 - 0s - loss: 1.3868 - accuracy: 0.9909 - val_loss: 1.4332 - val_accuracy: 0.9391\n",
      "Epoch 26/200\n",
      "1969/1969 - 0s - loss: 1.3872 - accuracy: 0.9888 - val_loss: 1.4309 - val_accuracy: 0.9391\n",
      "Epoch 27/200\n",
      "1969/1969 - 0s - loss: 1.3840 - accuracy: 0.9919 - val_loss: 1.4238 - val_accuracy: 0.9493\n",
      "Epoch 28/200\n",
      "1969/1969 - 0s - loss: 1.3848 - accuracy: 0.9914 - val_loss: 1.4197 - val_accuracy: 0.9554\n",
      "Epoch 29/200\n",
      "1969/1969 - 0s - loss: 1.3837 - accuracy: 0.9919 - val_loss: 1.4196 - val_accuracy: 0.9513\n",
      "Epoch 30/200\n",
      "1969/1969 - 0s - loss: 1.3843 - accuracy: 0.9914 - val_loss: 1.4211 - val_accuracy: 0.9513\n",
      "Epoch 31/200\n",
      "1969/1969 - 0s - loss: 1.3837 - accuracy: 0.9914 - val_loss: 1.4214 - val_accuracy: 0.9533\n",
      "Epoch 32/200\n",
      "1969/1969 - 0s - loss: 1.3832 - accuracy: 0.9914 - val_loss: 1.4207 - val_accuracy: 0.9513\n",
      "Epoch 33/200\n",
      "1969/1969 - 0s - loss: 1.3833 - accuracy: 0.9919 - val_loss: 1.4228 - val_accuracy: 0.9452\n",
      "Epoch 34/200\n",
      "1969/1969 - 0s - loss: 1.3832 - accuracy: 0.9924 - val_loss: 1.4244 - val_accuracy: 0.9473\n",
      "Epoch 35/200\n",
      "1969/1969 - 0s - loss: 1.3832 - accuracy: 0.9919 - val_loss: 1.4219 - val_accuracy: 0.9493\n",
      "Epoch 36/200\n",
      "1969/1969 - 0s - loss: 1.3820 - accuracy: 0.9929 - val_loss: 1.4184 - val_accuracy: 0.9554\n",
      "Epoch 37/200\n",
      "1969/1969 - 0s - loss: 1.3815 - accuracy: 0.9929 - val_loss: 1.4195 - val_accuracy: 0.9533\n",
      "Epoch 38/200\n",
      "1969/1969 - 0s - loss: 1.3818 - accuracy: 0.9934 - val_loss: 1.4203 - val_accuracy: 0.9533\n",
      "Epoch 39/200\n",
      "1969/1969 - 0s - loss: 1.3815 - accuracy: 0.9929 - val_loss: 1.4161 - val_accuracy: 0.9574\n",
      "Epoch 40/200\n",
      "1969/1969 - 0s - loss: 1.3807 - accuracy: 0.9934 - val_loss: 1.4133 - val_accuracy: 0.9615\n",
      "Epoch 41/200\n",
      "1969/1969 - 0s - loss: 1.3819 - accuracy: 0.9919 - val_loss: 1.4149 - val_accuracy: 0.9574\n",
      "Epoch 42/200\n",
      "1969/1969 - 0s - loss: 1.3798 - accuracy: 0.9944 - val_loss: 1.4177 - val_accuracy: 0.9574\n",
      "Epoch 43/200\n",
      "1969/1969 - 0s - loss: 1.3798 - accuracy: 0.9944 - val_loss: 1.4191 - val_accuracy: 0.9513\n",
      "Epoch 44/200\n",
      "1969/1969 - 0s - loss: 1.3801 - accuracy: 0.9939 - val_loss: 1.4181 - val_accuracy: 0.9554\n",
      "Epoch 45/200\n",
      "1969/1969 - 0s - loss: 1.3794 - accuracy: 0.9944 - val_loss: 1.4133 - val_accuracy: 0.9594\n",
      "Epoch 46/200\n",
      "1969/1969 - 0s - loss: 1.3802 - accuracy: 0.9944 - val_loss: 1.4093 - val_accuracy: 0.9635\n",
      "Epoch 47/200\n",
      "1969/1969 - 0s - loss: 1.3799 - accuracy: 0.9939 - val_loss: 1.4097 - val_accuracy: 0.9655\n",
      "Epoch 48/200\n",
      "1969/1969 - 0s - loss: 1.3795 - accuracy: 0.9939 - val_loss: 1.4112 - val_accuracy: 0.9615\n",
      "Epoch 49/200\n",
      "1969/1969 - 0s - loss: 1.3789 - accuracy: 0.9949 - val_loss: 1.4114 - val_accuracy: 0.9615\n",
      "Epoch 50/200\n",
      "1969/1969 - 0s - loss: 1.3786 - accuracy: 0.9944 - val_loss: 1.4120 - val_accuracy: 0.9594\n",
      "Epoch 51/200\n",
      "1969/1969 - 0s - loss: 1.3791 - accuracy: 0.9944 - val_loss: 1.4116 - val_accuracy: 0.9655\n",
      "Epoch 52/200\n",
      "1969/1969 - 0s - loss: 1.3796 - accuracy: 0.9939 - val_loss: 1.4137 - val_accuracy: 0.9594\n",
      "Epoch 53/200\n",
      "1969/1969 - 0s - loss: 1.3802 - accuracy: 0.9939 - val_loss: 1.4133 - val_accuracy: 0.9594\n",
      "Epoch 54/200\n",
      "1969/1969 - 0s - loss: 1.3797 - accuracy: 0.9934 - val_loss: 1.4174 - val_accuracy: 0.9574\n",
      "Epoch 55/200\n",
      "1969/1969 - 0s - loss: 1.3782 - accuracy: 0.9954 - val_loss: 1.4179 - val_accuracy: 0.9554\n",
      "Epoch 56/200\n",
      "1969/1969 - 0s - loss: 1.3779 - accuracy: 0.9954 - val_loss: 1.4181 - val_accuracy: 0.9554\n",
      "Epoch 57/200\n",
      "1969/1969 - 0s - loss: 1.3785 - accuracy: 0.9949 - val_loss: 1.4161 - val_accuracy: 0.9554\n",
      "Epoch 58/200\n",
      "1969/1969 - 0s - loss: 1.3778 - accuracy: 0.9959 - val_loss: 1.4149 - val_accuracy: 0.9574\n",
      "Epoch 59/200\n",
      "1969/1969 - 0s - loss: 1.3776 - accuracy: 0.9959 - val_loss: 1.4107 - val_accuracy: 0.9615\n",
      "Epoch 60/200\n",
      "1969/1969 - 0s - loss: 1.3783 - accuracy: 0.9949 - val_loss: 1.4138 - val_accuracy: 0.9574\n",
      "Epoch 61/200\n",
      "1969/1969 - 0s - loss: 1.3780 - accuracy: 0.9954 - val_loss: 1.4099 - val_accuracy: 0.9615\n",
      "Epoch 00061: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = embedded.fit(X_train,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedded.save('pred_vowel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71  4  1  1  0  2  0  0  0]\n",
      " [ 1 70  0  0  0  1  0  0  0]\n",
      " [ 0  0 58  0  0  2  1  0  0]\n",
      " [ 0  0  0 73  0  0  0  1  0]\n",
      " [ 0  0  0  1 53  0  0  0  0]\n",
      " [ 0  0  0  0  0 64  3  0  0]\n",
      " [ 0  0  0  0  0  1 66  0  0]\n",
      " [ 0  0  0  0  0  0  0 64  1]\n",
      " [ 0  0  0  0  0  0  1  2 74]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.99      0.90      0.94        79\n",
      "           E       0.95      0.97      0.96        72\n",
      "           M       0.98      0.95      0.97        61\n",
      "           O       0.97      0.99      0.98        74\n",
      "           a       1.00      0.98      0.99        54\n",
      "           e       0.91      0.96      0.93        67\n",
      "           i       0.93      0.99      0.96        67\n",
      "           o       0.96      0.98      0.97        65\n",
      "           u       0.99      0.96      0.97        77\n",
      "\n",
      "    accuracy                           0.96       616\n",
      "   macro avg       0.96      0.96      0.96       616\n",
      "weighted avg       0.96      0.96      0.96       616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = embedded.predict(X_test)\n",
    "evaluate_model(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embeded_model(23, 39)\n",
    "embedded.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "history = embedded.fit(features,label_oe,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.save('pred_vowel_all_data.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = models.load_model('pred_vowel_all_data.hdf5')\n",
    "enc = load('onehot_pred.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 31\n",
    "- BiLSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[177  16  16   0   0   5   1   1   0]\n",
      " [  6 196   1   0   5   8   0   0   0]\n",
      " [  2   1 164   0   0  29  18   0   2]\n",
      " [  2   6   2 163  29   0   0  14   0]\n",
      " [  1  10   4  12 188   1   0   0   0]\n",
      " [  0   2   2   0   0 211   1   0   0]\n",
      " [  0   0   6   0   0  10 197   0   3]\n",
      " [ 10   2   1   7   0   5   0 145  46]\n",
      " [  4   2  20   0   0   5  15  12 158]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.88      0.82      0.85       216\n",
      "           E       0.83      0.91      0.87       216\n",
      "           M       0.76      0.76      0.76       216\n",
      "           O       0.90      0.75      0.82       216\n",
      "           a       0.85      0.87      0.86       216\n",
      "           e       0.77      0.98      0.86       216\n",
      "           i       0.85      0.91      0.88       216\n",
      "           o       0.84      0.67      0.75       216\n",
      "           u       0.76      0.73      0.74       216\n",
      "\n",
      "    accuracy                           0.82      1944\n",
      "   macro avg       0.83      0.82      0.82      1944\n",
      "weighted avg       0.83      0.82      0.82      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_31/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8225308641975309 Recall: 0.8225308641975309 AUC: 0.951728252171925\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 86\n",
    "- BiLSTM without Speaker Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[140  36  18   5   0   6   2   8   1]\n",
      " [ 13 161   1   2  15  17   6   1   0]\n",
      " [ 12   1 144   0   0  37  18   1   3]\n",
      " [  7   5   0 142  39   0   0  22   1]\n",
      " [  3  22   2  18 169   2   0   0   0]\n",
      " [  7   4   5   0   0 192   8   0   0]\n",
      " [  1   0   5   0   0  28 181   0   1]\n",
      " [ 17  10   1  11   0   9   0 106  62]\n",
      " [ 14   1   9   0   0   9  19  20 144]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.65      0.65      0.65       216\n",
      "           E       0.67      0.75      0.71       216\n",
      "           M       0.78      0.67      0.72       216\n",
      "           O       0.80      0.66      0.72       216\n",
      "           a       0.76      0.78      0.77       216\n",
      "           e       0.64      0.89      0.74       216\n",
      "           i       0.77      0.84      0.80       216\n",
      "           o       0.67      0.49      0.57       216\n",
      "           u       0.68      0.67      0.67       216\n",
      "\n",
      "    accuracy                           0.71      1944\n",
      "   macro avg       0.71      0.71      0.71      1944\n",
      "weighted avg       0.71      0.71      0.71      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_86/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7093621399176955 Recall: 0.7093621399176955 AUC: 0.923747154111416\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 87\n",
    "- BiLSTM without Speaker Simulation and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[131  30  23   5   0  17   0   4   6]\n",
      " [ 13 138   5   4  34  21   1   0   0]\n",
      " [ 23   2 115   0   1  63   8   0   4]\n",
      " [  8  11   7 103  37   0   0  43   7]\n",
      " [ 15  37  24  25 112   3   0   0   0]\n",
      " [ 15  12   9   0   0 175   4   0   1]\n",
      " [ 10   0  22   0   0  63 115   0   6]\n",
      " [ 22  24   6  14   0   5   1  88  56]\n",
      " [ 39   1  11   0   0  17   8  26 114]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.47      0.61      0.53       216\n",
      "           E       0.54      0.64      0.59       216\n",
      "           M       0.52      0.53      0.53       216\n",
      "           O       0.68      0.48      0.56       216\n",
      "           a       0.61      0.52      0.56       216\n",
      "           e       0.48      0.81      0.60       216\n",
      "           i       0.84      0.53      0.65       216\n",
      "           o       0.55      0.41      0.47       216\n",
      "           u       0.59      0.53      0.56       216\n",
      "\n",
      "    accuracy                           0.56      1944\n",
      "   macro avg       0.59      0.56      0.56      1944\n",
      "weighted avg       0.59      0.56      0.56      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_87/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5612139917695473 Recall: 0.5612139917695473 AUC: 0.844167059613626\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 88\n",
    "- BiLSTM without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[159  19  10   6   1   9   0   5   7]\n",
      " [ 10 175   1   4  10  16   0   0   0]\n",
      " [ 17   3 143   0   0  37  13   0   3]\n",
      " [  5   3   0 114  46   0   0  37  11]\n",
      " [  6  62   4  14 126   4   0   0   0]\n",
      " [  5   4   3   0   1 190  13   0   0]\n",
      " [  2   0  13   0   0  28 171   0   2]\n",
      " [ 12  10   2   7   0   3   0 124  58]\n",
      " [ 25   0  29   1   0  16  15  18 112]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.66      0.74      0.70       216\n",
      "           E       0.63      0.81      0.71       216\n",
      "           M       0.70      0.66      0.68       216\n",
      "           O       0.78      0.53      0.63       216\n",
      "           a       0.68      0.58      0.63       216\n",
      "           e       0.63      0.88      0.73       216\n",
      "           i       0.81      0.79      0.80       216\n",
      "           o       0.67      0.57      0.62       216\n",
      "           u       0.58      0.52      0.55       216\n",
      "\n",
      "    accuracy                           0.68      1944\n",
      "   macro avg       0.68      0.68      0.67      1944\n",
      "weighted avg       0.68      0.68      0.67      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_88/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6759259259259259 Recall: 0.6759259259259259 AUC: 0.9013021428707515\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Data 10\n",
    "- LTRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[176  23   8   1   0   6   0   2   0]\n",
      " [  8 195   0   1   2  10   0   0   0]\n",
      " [ 17   2 154   0   0  23  17   0   3]\n",
      " [ 11   4   4 149  31   0   0  15   2]\n",
      " [  2  43   7  17 146   1   0   0   0]\n",
      " [  5   7   4   0   0 198   2   0   0]\n",
      " [  0   0  10   0   0  41 165   0   0]\n",
      " [ 29   0   0  17   0   2   0 120  48]\n",
      " [ 14   2  36   0   0   4  15  19 126]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.67      0.81      0.74       216\n",
      "           E       0.71      0.90      0.79       216\n",
      "           M       0.69      0.71      0.70       216\n",
      "           O       0.81      0.69      0.74       216\n",
      "           a       0.82      0.68      0.74       216\n",
      "           e       0.69      0.92      0.79       216\n",
      "           i       0.83      0.76      0.80       216\n",
      "           o       0.77      0.56      0.65       216\n",
      "           u       0.70      0.58      0.64       216\n",
      "\n",
      "    accuracy                           0.74      1944\n",
      "   macro avg       0.74      0.74      0.73      1944\n",
      "weighted avg       0.74      0.74      0.73      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_10/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7093621399176955 Recall: 0.7093621399176955 AUC: 0.923747154111416\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Data 65 \n",
    "- Retrain model Conv_bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[150  23  20   6   1  12   0   4   0]\n",
      " [ 14 187   0   2   6   6   0   1   0]\n",
      " [ 10   1 160   0   0  24  17   0   4]\n",
      " [  4  15   0 134  44   0   0  17   2]\n",
      " [  4  31   1  39 138   2   0   1   0]\n",
      " [  0   3   1   0   0 199  13   0   0]\n",
      " [  0   0   5   0   0  29 181   0   1]\n",
      " [  9   1   0   9   3   1   0 133  60]\n",
      " [  1   0  10   0   1   3  15  18 168]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.78      0.69      0.74       216\n",
      "           E       0.72      0.87      0.78       216\n",
      "           M       0.81      0.74      0.77       216\n",
      "           O       0.71      0.62      0.66       216\n",
      "           a       0.72      0.64      0.67       216\n",
      "           e       0.72      0.92      0.81       216\n",
      "           i       0.80      0.84      0.82       216\n",
      "           o       0.76      0.62      0.68       216\n",
      "           u       0.71      0.78      0.75       216\n",
      "\n",
      "    accuracy                           0.75      1944\n",
      "   macro avg       0.75      0.75      0.74      1944\n",
      "weighted avg       0.75      0.75      0.74      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_65/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7093621399176955 Recall: 0.7093621399176955 AUC: 0.923747154111416\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Data 30\n",
    "- Retrain model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[166  22  10   5   0   7   0   5   1]\n",
      " [  7 193   0   1   1  13   1   0   0]\n",
      " [ 21   0 154   0   0  21  17   1   2]\n",
      " [  4  13   0 125  51   0   0  22   1]\n",
      " [  1  45   2  17 148   3   0   0   0]\n",
      " [  1   2   5   0   0 205   3   0   0]\n",
      " [  2   0  27   0   0  18 169   0   0]\n",
      " [ 13   1   3  10   1   5   0 134  49]\n",
      " [  4   0  15   1   0   4  19  16 157]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.76      0.77      0.76       216\n",
      "           E       0.70      0.89      0.78       216\n",
      "           M       0.71      0.71      0.71       216\n",
      "           O       0.79      0.58      0.67       216\n",
      "           a       0.74      0.69      0.71       216\n",
      "           e       0.74      0.95      0.83       216\n",
      "           i       0.81      0.78      0.80       216\n",
      "           o       0.75      0.62      0.68       216\n",
      "           u       0.75      0.73      0.74       216\n",
      "\n",
      "    accuracy                           0.75      1944\n",
      "   macro avg       0.75      0.75      0.74      1944\n",
      "weighted avg       0.75      0.75      0.74      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_30/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7093621399176955 Recall: 0.7093621399176955 AUC: 0.923747154111416\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Data 8\n",
    "- Retrain model FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (1944, 23, 39) (1944,)\n",
      "[[156  20  11   6   2   9   1   5   6]\n",
      " [ 11 116   0   7  68  14   0   0   0]\n",
      " [ 17   4 145   0   0  38   8   0   4]\n",
      " [ 28  13   0  55 104   1   0  14   1]\n",
      " [  1   3   2  13 194   3   0   0   0]\n",
      " [ 15  14  11   0   0 163  12   1   0]\n",
      " [  0   0  18   0   2 129  64   0   3]\n",
      " [ 24   0   0  18   0   1   0  96  77]\n",
      " [ 29   0  14   0   1  14   3  13 142]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.56      0.72      0.63       216\n",
      "           E       0.68      0.54      0.60       216\n",
      "           M       0.72      0.67      0.70       216\n",
      "           O       0.56      0.25      0.35       216\n",
      "           a       0.52      0.90      0.66       216\n",
      "           e       0.44      0.75      0.55       216\n",
      "           i       0.73      0.30      0.42       216\n",
      "           o       0.74      0.44      0.56       216\n",
      "           u       0.61      0.66      0.63       216\n",
      "\n",
      "    accuracy                           0.58      1944\n",
      "   macro avg       0.62      0.58      0.57      1944\n",
      "weighted avg       0.62      0.58      0.57      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion/inversion_8/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7093621399176955 Recall: 0.7093621399176955 AUC: 0.923747154111416\n"
     ]
    }
   ],
   "source": [
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluated Model for Preception Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (162, 23, 39) (162,)\n",
      "Precision: 0.3148148148148148 Recall: 0.3148148148148148 AUC: 0.7066186556927296\n",
      "[[ 2  3  0  2  3  6  0  2  0]\n",
      " [ 0  0  0  4 10  0  3  1  0]\n",
      " [ 0  0  4  0  0  5  8  1  0]\n",
      " [ 0  1  0 12  4  0  0  1  0]\n",
      " [ 0  3  0  0  1 11  3  0  0]\n",
      " [ 0  0  0  0  0  0 10  5  3]\n",
      " [ 0  0  0  0  0  0 14  0  4]\n",
      " [ 0  0  0  8  1  0  0  7  2]\n",
      " [ 0  0  2  3  1  0  0  1 11]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       1.00      0.11      0.20        18\n",
      "           E       0.00      0.00      0.00        18\n",
      "           M       0.67      0.22      0.33        18\n",
      "           O       0.41      0.67      0.51        18\n",
      "           a       0.05      0.06      0.05        18\n",
      "           e       0.00      0.00      0.00        18\n",
      "           i       0.37      0.78      0.50        18\n",
      "           o       0.39      0.39      0.39        18\n",
      "           u       0.55      0.61      0.58        18\n",
      "\n",
      "    accuracy                           0.31       162\n",
      "   macro avg       0.38      0.31      0.28       162\n",
      "weighted avg       0.38      0.31      0.28       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion_perception/set_2/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (162, 23, 39) (162,)\n",
      "Precision: 0.30246913580246915 Recall: 0.30246913580246915 AUC: 0.7007887517146776\n",
      "[[ 4  4  0  1  1  3  1  4  0]\n",
      " [ 0  0  0  4 10  0  4  0  0]\n",
      " [ 2  0  0  0  0  3 11  0  2]\n",
      " [ 0  3  0 11  2  0  0  2  0]\n",
      " [ 1  4  0  1  0  8  2  2  0]\n",
      " [ 1  0  0  0  0  0  7  8  2]\n",
      " [ 0  0  0  0  0  0 15  1  2]\n",
      " [ 2  0  0  6  0  0  0  6  4]\n",
      " [ 1  0  4  0  0  0  0  0 13]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.36      0.22      0.28        18\n",
      "           E       0.00      0.00      0.00        18\n",
      "           M       0.00      0.00      0.00        18\n",
      "           O       0.48      0.61      0.54        18\n",
      "           a       0.00      0.00      0.00        18\n",
      "           e       0.00      0.00      0.00        18\n",
      "           i       0.38      0.83      0.52        18\n",
      "           o       0.26      0.33      0.29        18\n",
      "           u       0.57      0.72      0.63        18\n",
      "\n",
      "    accuracy                           0.30       162\n",
      "   macro avg       0.23      0.30      0.25       162\n",
      "weighted avg       0.23      0.30      0.25       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion_perception/set_3/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (162, 23, 39) (162,)\n",
      "Precision: 0.3765432098765432 Recall: 0.3765432098765432 AUC: 0.706275720164609\n",
      "[[ 3  9  0  1  0  5  0  0  0]\n",
      " [ 0  0  0  3 13  0  0  2  0]\n",
      " [ 0  0  0  0  0  5 12  1  0]\n",
      " [ 0  0  0 10  6  0  0  2  0]\n",
      " [ 0  1  0  0  9  6  1  1  0]\n",
      " [ 0  0  0  0  0  0  5 11  2]\n",
      " [ 0  0  0  0  0  0 15  1  2]\n",
      " [ 0  0  0  7  0  0  0  9  2]\n",
      " [ 0  0  0  3  0  0  0  0 15]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       1.00      0.17      0.29        18\n",
      "           E       0.00      0.00      0.00        18\n",
      "           M       0.00      0.00      0.00        18\n",
      "           O       0.42      0.56      0.48        18\n",
      "           a       0.32      0.50      0.39        18\n",
      "           e       0.00      0.00      0.00        18\n",
      "           i       0.45      0.83      0.59        18\n",
      "           o       0.33      0.50      0.40        18\n",
      "           u       0.71      0.83      0.77        18\n",
      "\n",
      "    accuracy                           0.38       162\n",
      "   macro avg       0.36      0.38      0.32       162\n",
      "weighted avg       0.36      0.38      0.32       162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THANATLAPTHAWAN\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion_perception/set_4/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (162, 23, 39) (162,)\n",
      "Precision: 0.32098765432098764 Recall: 0.32098765432098764 AUC: 0.7190500685871055\n",
      "[[ 2  9  0  2  0  4  0  1  0]\n",
      " [ 0  0  0  5 12  0  1  0  0]\n",
      " [ 1  0  1  0  0  6  9  0  1]\n",
      " [ 0  2  0  7  6  0  0  3  0]\n",
      " [ 0  0  0  1  6  6  5  0  0]\n",
      " [ 0  0  0  0  0  0  9  8  1]\n",
      " [ 0  0  0  0  0  0 16  0  2]\n",
      " [ 0  0  0  4  1  0  0  9  4]\n",
      " [ 1  0  2  1  1  0  0  2 11]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.50      0.11      0.18        18\n",
      "           E       0.00      0.00      0.00        18\n",
      "           M       0.33      0.06      0.10        18\n",
      "           O       0.35      0.39      0.37        18\n",
      "           a       0.23      0.33      0.27        18\n",
      "           e       0.00      0.00      0.00        18\n",
      "           i       0.40      0.89      0.55        18\n",
      "           o       0.39      0.50      0.44        18\n",
      "           u       0.58      0.61      0.59        18\n",
      "\n",
      "    accuracy                           0.32       162\n",
      "   macro avg       0.31      0.32      0.28       162\n",
      "weighted avg       0.31      0.32      0.28       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion_perception/set_5/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (162, 23, 39) (162,)\n",
      "Precision: 0.3148148148148148 Recall: 0.3148148148148148 AUC: 0.6897719478737998\n",
      "[[ 3  2  0  2  4  1  1  5  0]\n",
      " [ 0  0  0  0 16  0  2  0  0]\n",
      " [ 2  0  0  0  0  6  6  3  1]\n",
      " [ 1  1  0 10  5  0  0  1  0]\n",
      " [ 0  3  0  0  1 14  0  0  0]\n",
      " [ 1  0  0  0  0  0  9  7  1]\n",
      " [ 0  0  0  0  0  0 16  0  2]\n",
      " [ 0  0  0  8  0  0  0  8  2]\n",
      " [ 1  0  0  1  1  0  0  2 13]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.38      0.17      0.23        18\n",
      "           E       0.00      0.00      0.00        18\n",
      "           M       0.00      0.00      0.00        18\n",
      "           O       0.48      0.56      0.51        18\n",
      "           a       0.04      0.06      0.04        18\n",
      "           e       0.00      0.00      0.00        18\n",
      "           i       0.47      0.89      0.62        18\n",
      "           o       0.31      0.44      0.36        18\n",
      "           u       0.68      0.72      0.70        18\n",
      "\n",
      "    accuracy                           0.31       162\n",
      "   macro avg       0.26      0.31      0.27       162\n",
      "weighted avg       0.26      0.31      0.27       162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THANATLAPTHAWAN\\Anaconda3\\envs\\thesis_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion_perception/set_6/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Data (162, 23, 39) (162,)\n",
      "Precision: 0.3148148148148148 Recall: 0.3148148148148148 AUC: 0.7383830589849107\n",
      "[[ 2  5  0  2  0  8  0  1  0]\n",
      " [ 0  0  0  1 16  0  0  1  0]\n",
      " [ 1  0  2  0  0  7  5  3  0]\n",
      " [ 1  2  0  7  7  1  0  0  0]\n",
      " [ 0  0  0  0  3 10  3  2  0]\n",
      " [ 0  0  0  0  0  0  7 10  1]\n",
      " [ 0  0  0  0  0  0 18  0  0]\n",
      " [ 0  0  0  6  1  0  0  5  6]\n",
      " [ 0  0  1  2  0  0  0  1 14]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.50      0.11      0.18        18\n",
      "           E       0.00      0.00      0.00        18\n",
      "           M       0.67      0.11      0.19        18\n",
      "           O       0.39      0.39      0.39        18\n",
      "           a       0.11      0.17      0.13        18\n",
      "           e       0.00      0.00      0.00        18\n",
      "           i       0.55      1.00      0.71        18\n",
      "           o       0.22      0.28      0.24        18\n",
      "           u       0.67      0.78      0.72        18\n",
      "\n",
      "    accuracy                           0.31       162\n",
      "   macro avg       0.34      0.31      0.28       162\n",
      "weighted avg       0.34      0.31      0.28       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../data/inversion_perception/set_8/'\n",
    "PREP_FOLDER = 'prep_data'\n",
    "features, label = prep_data(DATA_PATH, PREP_FOLDER)\n",
    "label= label.reshape(-1,1)\n",
    "label_oe = enc.transform(label).toarray()\n",
    "pred = embedded.predict(features)\n",
    "class_pred = np.argmax(pred, axis=1)\n",
    "class_actual = np.argmax(label_oe, axis=1)\n",
    "precision = precision_score(class_actual, class_pred, average='micro')\n",
    "recall = recall_score(class_actual, class_pred, average='micro')\n",
    "auc = roc_auc_score(label_oe, pred)\n",
    "print('Precision: {} Recall: {} AUC: {}'.format(precision,recall,auc))\n",
    "evaluate_model(pred, label_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
